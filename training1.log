================================================================================
1.x
<class 'repllama.RepLLaMA'>
********************************************************************************
this
================================================================================
hf_model PeftModelForFeatureExtraction(
  (base_model): LoraModel(
    (model): LlamaModel(
      (embed_tokens): Embedding(32000, 4096)
      (layers): ModuleList(
        (0-31): 32 x LlamaDecoderLayer(
          (self_attn): LlamaSdpaAttention(
            (q_proj): lora.Linear4bit(
              (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)
              (lora_dropout): ModuleDict(
                (default): Dropout(p=0.1, inplace=False)
              )
              (lora_A): ModuleDict(
                (default): Linear(in_features=4096, out_features=8, bias=False)
              )
              (lora_B): ModuleDict(
                (default): Linear(in_features=8, out_features=4096, bias=False)
              )
              (lora_embedding_A): ParameterDict()
              (lora_embedding_B): ParameterDict()
              (lora_magnitude_vector): ModuleDict()
            )
            (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)
            (v_proj): lora.Linear4bit(
              (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)
              (lora_dropout): ModuleDict(
                (default): Dropout(p=0.1, inplace=False)
              )
              (lora_A): ModuleDict(
                (default): Linear(in_features=4096, out_features=8, bias=False)
              )
              (lora_B): ModuleDict(
                (default): Linear(in_features=8, out_features=4096, bias=False)
              )
              (lora_embedding_A): ParameterDict()
              (lora_embedding_B): ParameterDict()
              (lora_magnitude_vector): ModuleDict()
            )
            (o_proj): lora.Linear4bit(
              (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)
              (lora_dropout): ModuleDict(
                (default): Dropout(p=0.1, inplace=False)
              )
              (lora_A): ModuleDict(
                (default): Linear(in_features=4096, out_features=8, bias=False)
              )
              (lora_B): ModuleDict(
                (default): Linear(in_features=8, out_features=4096, bias=False)
              )
              (lora_embedding_A): ParameterDict()
              (lora_embedding_B): ParameterDict()
              (lora_magnitude_vector): ModuleDict()
            )
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): lora.Linear4bit(
              (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)
              (lora_dropout): ModuleDict(
                (default): Dropout(p=0.1, inplace=False)
              )
              (lora_A): ModuleDict(
                (default): Linear(in_features=4096, out_features=8, bias=False)
              )
              (lora_B): ModuleDict(
                (default): Linear(in_features=8, out_features=11008, bias=False)
              )
              (lora_embedding_A): ParameterDict()
              (lora_embedding_B): ParameterDict()
              (lora_magnitude_vector): ModuleDict()
            )
            (up_proj): lora.Linear4bit(
              (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)
              (lora_dropout): ModuleDict(
                (default): Dropout(p=0.1, inplace=False)
              )
              (lora_A): ModuleDict(
                (default): Linear(in_features=4096, out_features=8, bias=False)
              )
              (lora_B): ModuleDict(
                (default): Linear(in_features=8, out_features=11008, bias=False)
              )
              (lora_embedding_A): ParameterDict()
              (lora_embedding_B): ParameterDict()
              (lora_magnitude_vector): ModuleDict()
            )
            (down_proj): lora.Linear4bit(
              (base_layer): Linear4bit(in_features=11008, out_features=4096, bias=False)
              (lora_dropout): ModuleDict(
                (default): Dropout(p=0.1, inplace=False)
              )
              (lora_A): ModuleDict(
                (default): Linear(in_features=11008, out_features=8, bias=False)
              )
              (lora_B): ModuleDict(
                (default): Linear(in_features=8, out_features=4096, bias=False)
              )
              (lora_embedding_A): ParameterDict()
              (lora_embedding_B): ParameterDict()
              (lora_magnitude_vector): ModuleDict()
            )
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
        )
      )
      (norm): LlamaRMSNorm((4096,), eps=1e-05)
      (rotary_emb): LlamaRotaryEmbedding()
    )
  )
)
Parameter Name: base_model.model.embed_tokens.weight
 - Shape: torch.Size([32000, 4096])
 - Requires Grad: False
 - Values: tensor([[ 1.2517e-06, -1.7881e-06, -4.3511e-06,  ...,  8.9407e-07,
         -6.5565e-06,  8.9407e-07],
        [ 1.8616e-03, -3.3722e-03,  3.9864e-04,  ..., -8.3008e-03,
          2.5787e-03, -3.9368e-03],
        [ 1.0986e-02,  9.8877e-03, -5.0964e-03,  ...,  2.5177e-03,
          7.7057e-04, -5.0049e-03],
        ...,
        [-1.3977e-02, -2.7313e-03, -1.9897e-02,  ..., -1.0437e-02,
          9.5825e-03, -1.8005e-03],
        [-1.0742e-02,  9.3384e-03,  1.2939e-02,  ..., -3.3203e-02,
         -1.6357e-02,  3.3875e-03],
        [-8.3008e-03, -4.0588e-03, -1.1063e-03,  ...,  3.4790e-03,
         -1.2939e-02,  3.1948e-05]], device='cuda:0', dtype=torch.float16)

Parameter Name: base_model.model.layers.0.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[236],
        [145],
        [247],
        ...,
        [157],
        [229],
        [ 78]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.0.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0053,  0.0123,  0.0221,  ...,  0.0169, -0.0013,  0.0220],
        [-0.0379,  0.0326, -0.0023,  ..., -0.0110, -0.0193, -0.0051],
        [-0.0174,  0.0280, -0.0018,  ...,  0.0020,  0.0065, -0.0081],
        ...,
        [-0.0136,  0.0044,  0.0107,  ...,  0.0067,  0.0074,  0.0144],
        [ 0.0417, -0.0284,  0.0203,  ...,  0.0236, -0.0113, -0.0033],
        [-0.0221, -0.0156, -0.0004,  ...,  0.0028, -0.0076, -0.0282]],
       device='cuda:0')

Parameter Name: base_model.model.layers.0.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-5.3830e-03,  1.0556e-02,  1.5945e-02,  ...,  1.6752e-02,
          2.2847e-03, -1.4025e-03],
        [-1.5033e-02,  1.4257e-02,  1.2941e-02,  ...,  2.5201e-02,
         -1.3228e-02,  1.5036e-02],
        [ 1.6822e-02, -8.0473e-03, -9.9222e-03,  ..., -1.9900e-02,
          9.6993e-04, -1.9803e-02],
        ...,
        [ 1.1926e-02,  4.9692e-03,  5.7421e-05,  ..., -1.2086e-02,
         -6.9907e-03, -1.7621e-02],
        [ 4.3303e-03, -1.6770e-03,  3.3986e-03,  ..., -3.5955e-03,
          5.2444e-03,  1.1980e-02],
        [ 5.3589e-03,  8.5256e-03,  6.4875e-04,  ..., -9.1628e-03,
         -5.9233e-03, -1.7103e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.0.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[198],
        [150],
        [ 22],
        ...,
        [158],
        [145],
        [230]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.0.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 25],
        [ 23],
        [102],
        ...,
        [ 85],
        [169],
        [145]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.0.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0064,  0.0047,  0.0249,  ..., -0.0095,  0.0125, -0.0135],
        [-0.0080,  0.0009, -0.0092,  ..., -0.0066,  0.0166,  0.0152],
        [-0.0095, -0.0094, -0.0161,  ..., -0.0021,  0.0121,  0.0092],
        ...,
        [-0.0180, -0.0072,  0.0024,  ...,  0.0011,  0.0124,  0.0058],
        [ 0.0138,  0.0070, -0.0260,  ..., -0.0177,  0.0163,  0.0053],
        [-0.0110, -0.0046,  0.0016,  ...,  0.0011,  0.0004, -0.0023]],
       device='cuda:0')

Parameter Name: base_model.model.layers.0.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-1.7943e-03,  1.6286e-03, -1.0897e-03,  ...,  1.4059e-03,
          1.3333e-02, -1.2153e-02],
        [-7.1784e-03,  8.8863e-03,  2.1561e-04,  ...,  2.6567e-03,
          7.3549e-03,  3.6983e-04],
        [ 8.5397e-03,  7.1157e-03,  6.1065e-03,  ...,  1.7894e-03,
         -1.0976e-02,  1.1328e-02],
        ...,
        [ 8.7619e-03,  1.1037e-02,  1.0457e-02,  ...,  1.3196e-02,
          7.2206e-03,  8.1242e-05],
        [-1.4822e-05, -6.9271e-03, -1.0219e-02,  ..., -6.2774e-03,
         -2.5343e-03, -1.1047e-02],
        [ 2.0506e-03, -7.8604e-03, -3.9130e-03,  ..., -7.8902e-03,
         -1.4086e-03,  1.3001e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.0.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[142],
        [ 76],
        [225],
        ...,
        [ 98],
        [ 85],
        [173]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.0.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0005, -0.0019, -0.0067,  ..., -0.0012, -0.0272, -0.0005],
        [-0.0133,  0.0095,  0.0121,  ..., -0.0068, -0.0151,  0.0098],
        [-0.0064,  0.0074,  0.0125,  ..., -0.0037,  0.0033, -0.0038],
        ...,
        [-0.0036,  0.0077, -0.0036,  ..., -0.0125, -0.0093,  0.0010],
        [ 0.0075, -0.0190,  0.0112,  ...,  0.0041,  0.0048, -0.0104],
        [ 0.0244, -0.0011,  0.0017,  ..., -0.0112, -0.0021,  0.0090]],
       device='cuda:0')

Parameter Name: base_model.model.layers.0.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0079,  0.0016, -0.0042,  ..., -0.0004, -0.0050, -0.0015],
        [ 0.0030, -0.0125,  0.0019,  ...,  0.0103,  0.0068, -0.0004],
        [-0.0040, -0.0071,  0.0011,  ...,  0.0035,  0.0104, -0.0017],
        ...,
        [-0.0080, -0.0044,  0.0070,  ..., -0.0088,  0.0068,  0.0035],
        [ 0.0013,  0.0004, -0.0032,  ...,  0.0006,  0.0051,  0.0026],
        [ 0.0093, -0.0042, -0.0076,  ...,  0.0105, -0.0036, -0.0072]],
       device='cuda:0')

Parameter Name: base_model.model.layers.0.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 69],
        [ 44],
        [ 45],
        ...,
        [166],
        [161],
        [106]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.0.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-1.7212e-02,  1.9149e-02, -1.5065e-02,  ...,  1.0115e-02,
         -8.3175e-03, -2.0625e-03],
        [-6.5570e-03,  1.8461e-02,  2.5578e-04,  ...,  1.1692e-03,
          2.3135e-02, -1.9051e-02],
        [-1.8492e-02, -1.0733e-02, -1.4961e-02,  ...,  2.1758e-03,
         -9.9112e-03,  1.8422e-02],
        ...,
        [-1.5880e-02, -1.1218e-02,  1.3994e-02,  ..., -1.3090e-02,
         -2.9050e-02,  2.2222e-02],
        [-5.3423e-03,  1.7872e-02, -2.0851e-02,  ..., -1.6124e-02,
          1.1201e-02,  7.6136e-04],
        [ 2.1751e-02,  1.3515e-06,  1.8203e-03,  ..., -1.0259e-02,
          2.5147e-02, -2.1390e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.0.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-8.9641e-03, -2.5653e-03,  3.0596e-03,  ...,  2.0954e-03,
         -7.0246e-03,  1.3250e-03],
        [-3.1204e-03, -7.9848e-03,  1.1950e-02,  ...,  1.1161e-02,
         -2.1740e-03, -4.5330e-03],
        [-1.7754e-05,  1.1028e-03,  3.2281e-03,  ..., -6.6145e-03,
         -8.2631e-03,  3.1334e-03],
        ...,
        [ 3.5667e-03,  1.2989e-02, -9.9025e-03,  ..., -1.1454e-02,
          4.7707e-03,  8.8517e-03],
        [ 2.2391e-04,  1.1616e-02,  3.1974e-03,  ...,  3.1619e-03,
          2.4480e-02,  8.4612e-03],
        [ 7.8126e-03, -1.5718e-03, -1.0251e-03,  ...,  8.7267e-03,
          3.4824e-03, -1.6727e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.0.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 26],
        [ 76],
        [191],
        ...,
        [198],
        [103],
        [203]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.0.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0077,  0.0059, -0.0144,  ..., -0.0095, -0.0117, -0.0029],
        [-0.0056,  0.0032,  0.0023,  ..., -0.0150, -0.0090, -0.0221],
        [ 0.0024,  0.0145,  0.0001,  ...,  0.0082, -0.0305,  0.0009],
        ...,
        [-0.0065, -0.0017, -0.0145,  ..., -0.0075, -0.0020, -0.0191],
        [-0.0022, -0.0062,  0.0120,  ..., -0.0006, -0.0224, -0.0232],
        [ 0.0126,  0.0005, -0.0022,  ...,  0.0107, -0.0009,  0.0247]],
       device='cuda:0')

Parameter Name: base_model.model.layers.0.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0012,  0.0102,  0.0111,  ...,  0.0080,  0.0052, -0.0138],
        [ 0.0152,  0.0261,  0.0218,  ...,  0.0170,  0.0322, -0.0226],
        [ 0.0125,  0.0097,  0.0087,  ...,  0.0083,  0.0067, -0.0043],
        ...,
        [-0.0076, -0.0152, -0.0154,  ..., -0.0122, -0.0161,  0.0178],
        [-0.0089, -0.0027, -0.0026,  ..., -0.0111, -0.0035,  0.0026],
        [-0.0094, -0.0081, -0.0045,  ..., -0.0065, -0.0069, -0.0032]],
       device='cuda:0')

Parameter Name: base_model.model.layers.0.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 28],
        [111],
        [ 84],
        ...,
        [198],
        [153],
        [157]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.0.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 0.0151,  0.0198,  0.0051,  ..., -0.0038, -0.0132, -0.0069],
        [-0.0169,  0.0026, -0.0117,  ..., -0.0045,  0.0080, -0.0144],
        [-0.0210, -0.0085, -0.0133,  ..., -0.0171,  0.0198, -0.0181],
        ...,
        [ 0.0225, -0.0006, -0.0002,  ..., -0.0010, -0.0077,  0.0249],
        [ 0.0064,  0.0112,  0.0186,  ..., -0.0026,  0.0014,  0.0107],
        [ 0.0022,  0.0043,  0.0251,  ...,  0.0050, -0.0055,  0.0054]],
       device='cuda:0')

Parameter Name: base_model.model.layers.0.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0069,  0.0041,  0.0036,  ..., -0.0076, -0.0003, -0.0073],
        [-0.0050,  0.0027,  0.0013,  ..., -0.0024, -0.0046, -0.0024],
        [ 0.0155,  0.0044, -0.0118,  ...,  0.0128,  0.0098,  0.0158],
        ...,
        [-0.0053, -0.0005,  0.0110,  ..., -0.0018, -0.0112, -0.0167],
        [-0.0007,  0.0036, -0.0021,  ...,  0.0070,  0.0055,  0.0116],
        [ 0.0018,  0.0167,  0.0080,  ..., -0.0095, -0.0017,  0.0034]],
       device='cuda:0')

Parameter Name: base_model.model.layers.0.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.0297, 0.0136, 0.0020,  ..., 0.0103, 0.0110, 0.0061], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.0.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.0503, 0.0525, 0.0500,  ..., 0.0525, 0.0535, 0.0491], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.1.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[230],
        [214],
        [100],
        ...,
        [249],
        [108],
        [157]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.1.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-7.6191e-03,  6.9262e-03,  6.3217e-03,  ..., -6.4441e-03,
         -2.3883e-02, -6.7136e-04],
        [ 8.8120e-03, -1.1404e-02,  1.3937e-03,  ...,  6.8544e-03,
          8.8092e-03,  4.0988e-03],
        [-1.7009e-02,  7.9693e-03, -1.0870e-02,  ...,  6.5043e-03,
         -1.2177e-02, -9.9701e-03],
        ...,
        [-2.0429e-03, -4.0793e-05,  4.2613e-03,  ..., -2.0538e-02,
         -5.8148e-03, -2.1489e-03],
        [-3.9124e-02, -3.5315e-04,  1.4025e-02,  ...,  5.9439e-03,
          1.0572e-02, -1.1176e-02],
        [-1.3739e-02, -5.3418e-03, -2.7206e-03,  ..., -5.8745e-03,
         -1.2317e-02,  7.5699e-05]], device='cuda:0')

Parameter Name: base_model.model.layers.1.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0075,  0.0042,  0.0133,  ..., -0.0105, -0.0279,  0.0197],
        [ 0.0208,  0.0078,  0.0080,  ...,  0.0143,  0.0116, -0.0204],
        [ 0.0049,  0.0046,  0.0099,  ...,  0.0004, -0.0190,  0.0034],
        ...,
        [ 0.0031, -0.0122,  0.0065,  ..., -0.0018,  0.0079,  0.0155],
        [-0.0029,  0.0124, -0.0063,  ...,  0.0018, -0.0077, -0.0155],
        [ 0.0031, -0.0120,  0.0062,  ..., -0.0018,  0.0089,  0.0157]],
       device='cuda:0')

Parameter Name: base_model.model.layers.1.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[217],
        [ 47],
        [249],
        ...,
        [ 92],
        [215],
        [148]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.1.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[110],
        [150],
        [103],
        ...,
        [ 44],
        [246],
        [194]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.1.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-8.6096e-03,  1.5212e-02,  1.4752e-03,  ...,  9.2358e-03,
          7.1192e-03, -1.7227e-02],
        [-3.4670e-03,  8.8924e-03,  8.1547e-03,  ..., -8.5166e-03,
          7.2937e-03,  2.2728e-03],
        [ 2.9422e-03,  9.1296e-03, -3.1358e-03,  ...,  1.0443e-02,
          4.1634e-03, -1.1303e-03],
        ...,
        [-8.2523e-04,  5.1538e-03,  2.0842e-02,  ...,  3.4878e-03,
         -1.3493e-02,  5.6663e-03],
        [-3.1209e-03,  8.2435e-05,  2.4358e-02,  ..., -2.3068e-02,
          6.2182e-03, -1.0402e-02],
        [-6.3603e-03, -2.7361e-03,  8.1518e-03,  ..., -2.9306e-02,
         -6.0352e-03, -2.3648e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.1.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 9.5422e-03, -2.2151e-03,  1.4585e-03,  ...,  8.5900e-03,
          7.5382e-03,  4.2761e-03],
        [-5.9023e-03, -2.2048e-03,  7.6025e-03,  ..., -3.2141e-03,
         -5.7488e-03,  2.5372e-03],
        [-1.9620e-03, -4.0678e-03, -2.9796e-03,  ...,  5.9754e-05,
          3.8359e-03, -1.3271e-03],
        ...,
        [-2.2240e-03, -2.4294e-02,  9.8841e-03,  ...,  4.6154e-03,
         -1.5162e-03,  2.1070e-02],
        [-5.5395e-04,  4.0911e-03, -7.6922e-03,  ...,  9.9839e-03,
         -1.0085e-02, -5.1534e-03],
        [ 1.2065e-03, -1.3746e-03,  2.5712e-03,  ..., -1.2456e-02,
          6.9680e-03,  1.3420e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.1.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[106],
        [ 94],
        [ 94],
        ...,
        [249],
        [ 86],
        [215]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.1.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 2.2499e-02,  8.9379e-03, -1.0435e-02,  ..., -3.2290e-03,
          1.2282e-02,  1.7915e-02],
        [ 1.6176e-02,  3.9927e-03, -2.9174e-03,  ...,  2.2254e-03,
         -7.7921e-05, -6.3591e-03],
        [-9.4414e-04,  5.3777e-03,  1.7568e-02,  ..., -2.1723e-02,
          8.1524e-03, -3.7740e-03],
        ...,
        [ 9.9873e-03,  1.5516e-02, -1.5348e-02,  ...,  1.2273e-02,
          9.2129e-04, -1.9072e-02],
        [ 3.5825e-03, -1.5037e-02, -5.6255e-03,  ..., -2.4898e-03,
          2.8325e-02,  1.0443e-02],
        [-5.7341e-03,  5.3018e-03, -2.3342e-02,  ..., -1.2963e-02,
          3.7641e-03, -5.0534e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.1.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0029, -0.0086, -0.0251,  ...,  0.0024, -0.0116,  0.0045],
        [-0.0016,  0.0059, -0.0048,  ..., -0.0037,  0.0032,  0.0116],
        [ 0.0030, -0.0022,  0.0025,  ...,  0.0207,  0.0066, -0.0129],
        ...,
        [ 0.0098,  0.0050,  0.0058,  ..., -0.0207,  0.0053,  0.0122],
        [ 0.0093,  0.0200,  0.0072,  ..., -0.0076,  0.0151,  0.0049],
        [-0.0077,  0.0246, -0.0149,  ..., -0.0077,  0.0138,  0.0009]],
       device='cuda:0')

Parameter Name: base_model.model.layers.1.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 47],
        [ 57],
        [125],
        ...,
        [102],
        [243],
        [122]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.1.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0131, -0.0021, -0.0113,  ...,  0.0254,  0.0130, -0.0050],
        [-0.0014, -0.0025,  0.0240,  ...,  0.0136, -0.0025,  0.0075],
        [ 0.0069,  0.0012, -0.0030,  ..., -0.0173, -0.0178,  0.0164],
        ...,
        [ 0.0118, -0.0031,  0.0105,  ..., -0.0169, -0.0122, -0.0041],
        [-0.0023,  0.0176, -0.0105,  ...,  0.0148,  0.0009,  0.0062],
        [-0.0311,  0.0050,  0.0064,  ...,  0.0165, -0.0135,  0.0132]],
       device='cuda:0')

Parameter Name: base_model.model.layers.1.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 1.1811e-02,  8.8235e-04,  2.9450e-03,  ...,  5.0060e-03,
          1.5089e-02,  3.5073e-03],
        [ 7.6454e-03, -2.8997e-02,  2.4996e-02,  ...,  1.3717e-02,
          8.9645e-03,  1.7642e-02],
        [ 6.0875e-03, -1.6084e-02,  4.8248e-03,  ...,  9.1700e-03,
          1.7664e-02,  4.1541e-03],
        ...,
        [ 4.1531e-03,  7.5646e-03,  2.7389e-03,  ...,  6.8278e-03,
         -8.8738e-03, -9.4146e-03],
        [ 7.8765e-03, -1.6675e-03,  1.5692e-02,  ...,  1.1443e-02,
         -3.0833e-04,  1.8265e-02],
        [-1.3696e-05,  1.6736e-02, -1.5774e-02,  ..., -6.1483e-03,
         -4.3986e-03, -8.5136e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.1.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 19],
        [213],
        [110],
        ...,
        [151],
        [173],
        [229]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.1.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0019, -0.0212,  0.0009,  ..., -0.0151,  0.0140,  0.0080],
        [ 0.0026, -0.0151, -0.0044,  ...,  0.0094, -0.0082, -0.0230],
        [ 0.0123, -0.0006,  0.0082,  ...,  0.0222, -0.0047,  0.0053],
        ...,
        [-0.0081,  0.0049, -0.0105,  ..., -0.0133,  0.0077,  0.0127],
        [-0.0094, -0.0081,  0.0138,  ..., -0.0066, -0.0138, -0.0011],
        [-0.0092,  0.0054, -0.0075,  ...,  0.0139,  0.0021,  0.0202]],
       device='cuda:0')

Parameter Name: base_model.model.layers.1.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-3.4987e-03, -1.0945e-02, -5.7446e-03,  ...,  2.8820e-03,
          3.1905e-03,  1.8876e-04],
        [ 2.7817e-02,  1.5096e-02,  1.7499e-02,  ..., -1.5471e-03,
          5.0766e-03,  3.3987e-02],
        [-1.0371e-02, -2.2051e-02, -8.3344e-03,  ...,  1.0002e-02,
          9.4205e-03, -2.1088e-02],
        ...,
        [-2.1737e-03, -1.0150e-02, -1.2251e-02,  ..., -1.4667e-03,
          9.3315e-03,  6.3424e-03],
        [ 6.0666e-03,  1.1936e-03, -3.9503e-03,  ...,  3.0475e-03,
         -3.8588e-04, -6.0768e-05],
        [ 9.6703e-04, -1.9745e-03,  5.8303e-03,  ..., -9.9431e-03,
          5.5147e-04,  6.5149e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.1.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[102],
        [ 49],
        [ 71],
        ...,
        [206],
        [108],
        [195]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.1.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[-0.0116, -0.0175,  0.0038,  ...,  0.0127,  0.0105,  0.0136],
        [-0.0049, -0.0006,  0.0034,  ..., -0.0007, -0.0082,  0.0103],
        [ 0.0072,  0.0078,  0.0063,  ..., -0.0008,  0.0042, -0.0047],
        ...,
        [-0.0009, -0.0019, -0.0019,  ..., -0.0012,  0.0052,  0.0003],
        [-0.0061, -0.0015,  0.0010,  ...,  0.0110,  0.0053,  0.0106],
        [-0.0089,  0.0022, -0.0044,  ...,  0.0175,  0.0081,  0.0104]],
       device='cuda:0')

Parameter Name: base_model.model.layers.1.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0114, -0.0070,  0.0133,  ...,  0.0144, -0.0101, -0.0095],
        [ 0.0101,  0.0063, -0.0090,  ..., -0.0097,  0.0088,  0.0073],
        [-0.0057, -0.0056,  0.0026,  ...,  0.0046, -0.0042, -0.0048],
        ...,
        [ 0.0003,  0.0004, -0.0012,  ..., -0.0018,  0.0042,  0.0003],
        [ 0.0164,  0.0239, -0.0136,  ..., -0.0175,  0.0141,  0.0234],
        [ 0.0029,  0.0046, -0.0016,  ..., -0.0037,  0.0071,  0.0002]],
       device='cuda:0')

Parameter Name: base_model.model.layers.1.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.1138, 0.1099, 0.1006,  ..., 0.0630, 0.0942, 0.0742], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.1.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.0996, 0.1006, 0.0962,  ..., 0.1074, 0.0996, 0.1016], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.2.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[172],
        [117],
        [ 45],
        ...,
        [ 89],
        [194],
        [161]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.2.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0296, -0.0050, -0.0104,  ..., -0.0035,  0.0110, -0.0088],
        [ 0.0047,  0.0043,  0.0049,  ..., -0.0159, -0.0128, -0.0192],
        [-0.0001, -0.0231, -0.0122,  ..., -0.0184, -0.0008,  0.0004],
        ...,
        [-0.0045, -0.0057, -0.0204,  ..., -0.0092,  0.0035,  0.0057],
        [-0.0002, -0.0011,  0.0007,  ..., -0.0138,  0.0003,  0.0089],
        [ 0.0115, -0.0122,  0.0072,  ..., -0.0219,  0.0116, -0.0069]],
       device='cuda:0')

Parameter Name: base_model.model.layers.2.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0053, -0.0110,  0.0035,  ...,  0.0025,  0.0066,  0.0011],
        [ 0.0012,  0.0103, -0.0053,  ..., -0.0005, -0.0065, -0.0013],
        [ 0.0043,  0.0060, -0.0051,  ...,  0.0005, -0.0081, -0.0169],
        ...,
        [-0.0070,  0.0082,  0.0054,  ..., -0.0038, -0.0034, -0.0174],
        [-0.0212, -0.0002,  0.0073,  ...,  0.0038, -0.0132, -0.0196],
        [-0.0099,  0.0048, -0.0040,  ...,  0.0028, -0.0126, -0.0136]],
       device='cuda:0')

Parameter Name: base_model.model.layers.2.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[148],
        [197],
        [244],
        ...,
        [130],
        [ 91],
        [195]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.2.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[225],
        [ 41],
        [111],
        ...,
        [102],
        [126],
        [ 95]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.2.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 7.7897e-03, -8.4447e-03,  1.4440e-02,  ...,  4.3595e-03,
         -3.5564e-03, -6.3834e-05],
        [-1.9358e-03, -6.1674e-03, -1.6729e-02,  ..., -1.3235e-02,
          5.1882e-03,  2.0578e-02],
        [-2.2427e-02,  6.7201e-03,  1.8938e-02,  ..., -1.2074e-02,
         -2.1511e-02,  4.1947e-03],
        ...,
        [-9.8042e-04,  7.0425e-03,  8.8259e-03,  ...,  9.6885e-03,
          5.5069e-03,  3.0865e-02],
        [-1.2879e-03, -1.0779e-02,  8.9219e-03,  ..., -1.0176e-02,
         -4.3764e-03, -1.6209e-02],
        [-1.2357e-02, -1.2838e-02, -1.6163e-02,  ..., -4.8917e-03,
          7.7688e-03, -2.1968e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.2.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0044,  0.0118,  0.0048,  ...,  0.0013, -0.0071,  0.0057],
        [-0.0085, -0.0021,  0.0023,  ...,  0.0057,  0.0032, -0.0032],
        [-0.0101, -0.0075,  0.0136,  ..., -0.0006,  0.0090,  0.0062],
        ...,
        [ 0.0074,  0.0135,  0.0013,  ...,  0.0074, -0.0164, -0.0077],
        [-0.0023,  0.0049, -0.0231,  ...,  0.0040,  0.0046,  0.0078],
        [-0.0016, -0.0227,  0.0016,  ..., -0.0025,  0.0099,  0.0078]],
       device='cuda:0')

Parameter Name: base_model.model.layers.2.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[148],
        [100],
        [217],
        ...,
        [ 17],
        [159],
        [ 77]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.2.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0002, -0.0103,  0.0298,  ..., -0.0172, -0.0132,  0.0208],
        [ 0.0233,  0.0226,  0.0064,  ...,  0.0083,  0.0128,  0.0084],
        [-0.0215,  0.0072,  0.0105,  ...,  0.0198, -0.0188, -0.0095],
        ...,
        [-0.0005, -0.0059,  0.0060,  ..., -0.0105,  0.0156, -0.0054],
        [-0.0043, -0.0325, -0.0173,  ..., -0.0203, -0.0232, -0.0030],
        [ 0.0078,  0.0059,  0.0105,  ...,  0.0229, -0.0097, -0.0205]],
       device='cuda:0')

Parameter Name: base_model.model.layers.2.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0068, -0.0006, -0.0015,  ..., -0.0024,  0.0010, -0.0088],
        [ 0.0133, -0.0229,  0.0207,  ..., -0.0233,  0.0114, -0.0100],
        [ 0.0072,  0.0262, -0.0101,  ..., -0.0059, -0.0014,  0.0158],
        ...,
        [ 0.0177,  0.0110,  0.0029,  ..., -0.0040,  0.0073, -0.0228],
        [-0.0148,  0.0091, -0.0076,  ..., -0.0021, -0.0145,  0.0020],
        [-0.0093,  0.0059, -0.0072,  ...,  0.0042, -0.0052,  0.0083]],
       device='cuda:0')

Parameter Name: base_model.model.layers.2.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[100],
        [230],
        [230],
        ...,
        [148],
        [ 60],
        [166]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.2.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0056,  0.0035, -0.0042,  ..., -0.0010, -0.0073,  0.0093],
        [ 0.0125,  0.0049, -0.0045,  ..., -0.0033,  0.0052,  0.0192],
        [-0.0112, -0.0056, -0.0123,  ...,  0.0131,  0.0077,  0.0121],
        ...,
        [-0.0090, -0.0172, -0.0128,  ..., -0.0003, -0.0076, -0.0075],
        [ 0.0006,  0.0131,  0.0206,  ..., -0.0176,  0.0053, -0.0063],
        [-0.0113,  0.0125,  0.0209,  ...,  0.0007, -0.0220,  0.0174]],
       device='cuda:0')

Parameter Name: base_model.model.layers.2.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0103, -0.0060, -0.0021,  ..., -0.0017,  0.0057,  0.0114],
        [ 0.0016,  0.0030,  0.0175,  ...,  0.0069, -0.0106,  0.0050],
        [ 0.0026,  0.0133,  0.0008,  ..., -0.0047, -0.0109, -0.0037],
        ...,
        [-0.0018, -0.0028, -0.0101,  ...,  0.0026, -0.0038, -0.0031],
        [-0.0031, -0.0034, -0.0106,  ..., -0.0053, -0.0023,  0.0056],
        [-0.0020,  0.0085, -0.0063,  ...,  0.0162, -0.0027, -0.0167]],
       device='cuda:0')

Parameter Name: base_model.model.layers.2.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 25],
        [102],
        [ 20],
        ...,
        [113],
        [254],
        [ 30]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.2.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0127, -0.0074, -0.0036,  ..., -0.0070, -0.0070, -0.0278],
        [ 0.0157,  0.0164,  0.0066,  ..., -0.0068, -0.0190, -0.0038],
        [ 0.0189, -0.0039, -0.0052,  ...,  0.0078,  0.0061,  0.0052],
        ...,
        [ 0.0085, -0.0006, -0.0105,  ...,  0.0187,  0.0193, -0.0090],
        [ 0.0035,  0.0046,  0.0037,  ..., -0.0118, -0.0033, -0.0026],
        [ 0.0087,  0.0042,  0.0174,  ..., -0.0084, -0.0108, -0.0187]],
       device='cuda:0')

Parameter Name: base_model.model.layers.2.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0045, -0.0144, -0.0121,  ..., -0.0016,  0.0043,  0.0081],
        [ 0.0066,  0.0110, -0.0102,  ...,  0.0066, -0.0041,  0.0052],
        [ 0.0023, -0.0053, -0.0085,  ..., -0.0036,  0.0034, -0.0104],
        ...,
        [-0.0035,  0.0066,  0.0036,  ..., -0.0089, -0.0101, -0.0139],
        [-0.0093,  0.0309, -0.0115,  ...,  0.0046,  0.0095,  0.0276],
        [-0.0028, -0.0196,  0.0064,  ..., -0.0047, -0.0165, -0.0102]],
       device='cuda:0')

Parameter Name: base_model.model.layers.2.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[103],
        [ 47],
        [229],
        ...,
        [ 91],
        [146],
        [190]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.2.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[-0.0060, -0.0082,  0.0042,  ...,  0.0142,  0.0112, -0.0192],
        [-0.0022, -0.0105,  0.0076,  ...,  0.0021,  0.0113, -0.0133],
        [-0.0081,  0.0135, -0.0011,  ..., -0.0173,  0.0177,  0.0063],
        ...,
        [ 0.0028,  0.0117,  0.0073,  ..., -0.0117,  0.0001,  0.0056],
        [ 0.0165,  0.0022,  0.0065,  ...,  0.0084, -0.0315,  0.0032],
        [-0.0066,  0.0077,  0.0110,  ...,  0.0063,  0.0034, -0.0238]],
       device='cuda:0')

Parameter Name: base_model.model.layers.2.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 1.4195e-02,  6.4351e-03, -2.3562e-02,  ...,  1.1207e-02,
          1.3805e-04, -2.0755e-02],
        [-5.1140e-03, -5.8562e-04, -3.3574e-03,  ..., -2.8281e-03,
         -1.0568e-02, -9.1879e-03],
        [ 2.3103e-03, -1.2557e-02, -7.2807e-04,  ..., -8.4766e-03,
          4.5051e-05, -1.4111e-02],
        ...,
        [ 1.5898e-02, -1.4430e-02,  3.8690e-03,  ..., -1.5150e-02,
          9.9380e-03,  7.6315e-03],
        [-5.9532e-03, -9.3769e-03,  5.8927e-03,  ..., -2.4773e-03,
         -2.6720e-03,  4.3557e-03],
        [ 1.0189e-02,  2.2706e-03,  1.4280e-02,  ..., -1.4039e-02,
          2.4732e-03,  6.0973e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.2.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.1738, 0.1777, 0.1738,  ..., 0.1768, 0.1709, 0.1748], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.2.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.1338, 0.1367, 0.1357,  ..., 0.1357, 0.1387, 0.1357], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.3.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[116],
        [ 28],
        [ 62],
        ...,
        [230],
        [ 78],
        [158]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.3.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0097,  0.0172,  0.0286,  ...,  0.0355,  0.0039,  0.0311],
        [-0.0206,  0.0115,  0.0099,  ..., -0.0137,  0.0017,  0.0013],
        [ 0.0085,  0.0031, -0.0095,  ..., -0.0202,  0.0137, -0.0173],
        ...,
        [ 0.0173,  0.0144,  0.0083,  ...,  0.0230, -0.0044,  0.0098],
        [-0.0097,  0.0087,  0.0108,  ...,  0.0235,  0.0081, -0.0125],
        [-0.0154,  0.0135, -0.0072,  ..., -0.0096,  0.0165,  0.0178]],
       device='cuda:0')

Parameter Name: base_model.model.layers.3.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0009, -0.0072, -0.0216,  ...,  0.0129,  0.0077, -0.0128],
        [-0.0008, -0.0158,  0.0134,  ..., -0.0196, -0.0062,  0.0075],
        [-0.0032,  0.0041,  0.0026,  ..., -0.0135,  0.0021,  0.0107],
        ...,
        [ 0.0041,  0.0067,  0.0056,  ...,  0.0048, -0.0027, -0.0055],
        [-0.0004, -0.0106, -0.0057,  ..., -0.0024,  0.0065,  0.0142],
        [ 0.0114, -0.0119, -0.0142,  ...,  0.0039,  0.0128,  0.0091]],
       device='cuda:0')

Parameter Name: base_model.model.layers.3.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[110],
        [234],
        [114],
        ...,
        [230],
        [110],
        [ 25]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.3.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[148],
        [230],
        [245],
        ...,
        [230],
        [201],
        [ 98]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.3.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0009,  0.0097, -0.0259,  ..., -0.0268, -0.0014, -0.0227],
        [-0.0094, -0.0161,  0.0073,  ..., -0.0131,  0.0042, -0.0039],
        [ 0.0276,  0.0141, -0.0013,  ..., -0.0114, -0.0061, -0.0010],
        ...,
        [-0.0047, -0.0090,  0.0155,  ...,  0.0037, -0.0046,  0.0258],
        [-0.0121, -0.0046,  0.0202,  ...,  0.0118, -0.0199,  0.0191],
        [ 0.0002,  0.0186, -0.0110,  ..., -0.0187, -0.0140, -0.0062]],
       device='cuda:0')

Parameter Name: base_model.model.layers.3.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0010, -0.0029, -0.0192,  ...,  0.0003,  0.0005, -0.0076],
        [-0.0164, -0.0255,  0.0041,  ...,  0.0200,  0.0362, -0.0253],
        [-0.0028, -0.0030,  0.0064,  ..., -0.0024, -0.0040, -0.0024],
        ...,
        [-0.0042, -0.0168, -0.0013,  ...,  0.0092,  0.0145, -0.0030],
        [-0.0056,  0.0083, -0.0152,  ..., -0.0091, -0.0075,  0.0037],
        [-0.0102,  0.0064,  0.0040,  ..., -0.0074,  0.0153, -0.0056]],
       device='cuda:0')

Parameter Name: base_model.model.layers.3.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[166],
        [222],
        [238],
        ...,
        [ 28],
        [ 70],
        [101]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.3.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0020,  0.0072,  0.0157,  ...,  0.0067,  0.0030,  0.0101],
        [ 0.0031,  0.0069, -0.0071,  ..., -0.0167,  0.0031,  0.0055],
        [ 0.0225,  0.0094, -0.0128,  ...,  0.0110,  0.0145,  0.0013],
        ...,
        [-0.0104, -0.0084, -0.0064,  ...,  0.0245,  0.0061, -0.0014],
        [ 0.0077, -0.0083, -0.0129,  ..., -0.0117,  0.0157, -0.0228],
        [ 0.0295,  0.0310, -0.0054,  ...,  0.0068, -0.0067, -0.0116]],
       device='cuda:0')

Parameter Name: base_model.model.layers.3.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0145,  0.0073,  0.0124,  ..., -0.0191,  0.0017,  0.0078],
        [ 0.0142, -0.0155, -0.0050,  ...,  0.0121,  0.0034, -0.0015],
        [-0.0188, -0.0044,  0.0062,  ..., -0.0119,  0.0106,  0.0064],
        ...,
        [-0.0045, -0.0097, -0.0030,  ...,  0.0070, -0.0025, -0.0046],
        [ 0.0003, -0.0098, -0.0026,  ...,  0.0046,  0.0053,  0.0012],
        [-0.0009, -0.0082,  0.0037,  ..., -0.0029,  0.0098,  0.0157]],
       device='cuda:0')

Parameter Name: base_model.model.layers.3.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[158],
        [255],
        [ 20],
        ...,
        [ 35],
        [117],
        [167]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.3.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-2.6021e-03, -9.5855e-03,  1.7850e-02,  ...,  9.1325e-03,
         -9.8568e-03,  1.6287e-02],
        [ 1.4791e-02,  1.9865e-02,  2.3552e-02,  ...,  2.2599e-02,
          1.6646e-02, -2.8929e-03],
        [ 3.2625e-03,  1.4972e-02,  1.0150e-02,  ..., -5.7780e-03,
          1.8743e-02,  8.1844e-04],
        ...,
        [-1.7351e-02,  1.9815e-03,  3.4603e-03,  ...,  8.4175e-03,
          6.9398e-03,  8.9328e-03],
        [ 3.5422e-05,  2.7103e-03, -2.2865e-02,  ...,  1.5831e-02,
          1.3310e-02, -1.6276e-04],
        [-1.4171e-02,  3.1214e-03,  3.0453e-03,  ..., -1.2252e-02,
          8.0472e-03, -8.2843e-04]], device='cuda:0')

Parameter Name: base_model.model.layers.3.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 1.0319e-02,  5.7082e-03,  4.1812e-05,  ..., -3.1590e-03,
          4.6801e-03,  6.5276e-03],
        [ 1.3219e-02, -3.2292e-03,  1.1065e-02,  ..., -7.2136e-03,
         -1.5092e-02,  9.1536e-03],
        [-6.7234e-03,  5.4366e-03, -2.2857e-02,  ...,  1.1811e-03,
         -2.4573e-02, -2.2326e-03],
        ...,
        [ 1.4509e-02, -1.7497e-02,  8.0713e-04,  ..., -8.8316e-03,
          3.3660e-03,  2.0680e-02],
        [-7.0450e-04, -1.1671e-02,  5.9705e-03,  ..., -6.1521e-03,
         -8.6562e-03,  9.5491e-03],
        [ 2.7409e-03,  5.6369e-03,  1.0160e-02,  ..., -1.2118e-02,
          1.4586e-03,  7.5402e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.3.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[196],
        [ 98],
        [149],
        ...,
        [196],
        [ 98],
        [ 97]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.3.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0015,  0.0034,  0.0112,  ..., -0.0102,  0.0311,  0.0005],
        [ 0.0041, -0.0235, -0.0008,  ...,  0.0042, -0.0132, -0.0044],
        [ 0.0067,  0.0211, -0.0120,  ...,  0.0109, -0.0161, -0.0220],
        ...,
        [ 0.0152, -0.0183,  0.0009,  ..., -0.0114, -0.0021, -0.0070],
        [ 0.0108, -0.0099, -0.0237,  ..., -0.0055,  0.0019,  0.0106],
        [-0.0126, -0.0063, -0.0176,  ...,  0.0014, -0.0029, -0.0116]],
       device='cuda:0')

Parameter Name: base_model.model.layers.3.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 2.0604e-03,  8.9491e-03,  6.3826e-03,  ...,  5.6546e-03,
          1.5687e-03, -5.5900e-03],
        [ 3.8409e-03,  6.4021e-03, -1.9544e-02,  ...,  1.2374e-02,
          3.0192e-03,  3.9471e-05],
        [ 6.4058e-03, -9.2111e-03,  3.0098e-03,  ..., -1.2121e-02,
         -8.4803e-03,  8.3050e-05],
        ...,
        [-1.1443e-02,  4.9516e-03, -6.3694e-03,  ..., -4.5386e-03,
          2.6474e-04, -4.9015e-03],
        [ 5.0086e-04, -5.1711e-03, -1.3909e-02,  ..., -5.9013e-03,
          3.5019e-04,  4.5517e-03],
        [-2.7689e-02, -2.7923e-03,  8.3444e-03,  ..., -8.6326e-03,
          1.7395e-03,  9.9992e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.3.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[158],
        [110],
        [212],
        ...,
        [241],
        [121],
        [102]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.3.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[-0.0280,  0.0091, -0.0188,  ...,  0.0190,  0.0014,  0.0010],
        [ 0.0189,  0.0003,  0.0164,  ..., -0.0032,  0.0031,  0.0102],
        [-0.0024, -0.0002,  0.0106,  ..., -0.0055,  0.0018, -0.0111],
        ...,
        [ 0.0124, -0.0147,  0.0176,  ..., -0.0019,  0.0064, -0.0104],
        [-0.0041, -0.0075, -0.0214,  ...,  0.0025, -0.0118,  0.0065],
        [-0.0040, -0.0029,  0.0013,  ...,  0.0017, -0.0301, -0.0036]],
       device='cuda:0')

Parameter Name: base_model.model.layers.3.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0202,  0.0005,  0.0265,  ...,  0.0053, -0.0136, -0.0174],
        [ 0.0065, -0.0051, -0.0084,  ..., -0.0018, -0.0036,  0.0091],
        [-0.0144,  0.0024,  0.0233,  ...,  0.0105, -0.0080,  0.0006],
        ...,
        [ 0.0053,  0.0147, -0.0097,  ..., -0.0001,  0.0250,  0.0106],
        [ 0.0051,  0.0033, -0.0013,  ..., -0.0045,  0.0103, -0.0001],
        [ 0.0051, -0.0070, -0.0095,  ..., -0.0219, -0.0008,  0.0219]],
       device='cuda:0')

Parameter Name: base_model.model.layers.3.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.2832, 0.2832, 0.2812,  ..., 0.2793, 0.2891, 0.2910], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.3.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.1748, 0.1748, 0.1699,  ..., 0.1738, 0.1709, 0.1748], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.4.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[214],
        [158],
        [238],
        ...,
        [ 76],
        [ 98],
        [ 93]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.4.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0024,  0.0223,  0.0194,  ...,  0.0082, -0.0151, -0.0132],
        [ 0.0092, -0.0033,  0.0041,  ...,  0.0123,  0.0308, -0.0074],
        [-0.0080,  0.0295,  0.0068,  ..., -0.0088, -0.0027, -0.0096],
        ...,
        [ 0.0006,  0.0138,  0.0129,  ..., -0.0024,  0.0267,  0.0159],
        [ 0.0179, -0.0044,  0.0176,  ...,  0.0022, -0.0259, -0.0334],
        [ 0.0353,  0.0013,  0.0056,  ...,  0.0234, -0.0082,  0.0025]],
       device='cuda:0')

Parameter Name: base_model.model.layers.4.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 1.6956e-02, -2.3933e-02, -4.0463e-03,  ..., -1.9340e-02,
          3.1312e-03, -4.4992e-03],
        [-1.3493e-03, -3.1386e-03, -7.3869e-03,  ..., -1.7289e-02,
         -1.6153e-02, -1.5804e-02],
        [-1.5695e-02,  2.2928e-02, -2.0602e-02,  ..., -9.2003e-03,
         -2.1098e-03, -3.2175e-03],
        ...,
        [ 6.2294e-03, -4.3380e-03, -6.2701e-03,  ...,  3.7201e-03,
         -7.2665e-03,  2.9656e-03],
        [-6.4927e-03, -6.0577e-05,  2.1722e-02,  ...,  1.4482e-02,
         -1.8261e-02,  4.0927e-03],
        [ 9.2297e-03, -2.6986e-03,  9.4454e-03,  ...,  5.0051e-03,
         -9.4825e-03, -4.3269e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.4.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[244],
        [198],
        [119],
        ...,
        [ 25],
        [105],
        [ 78]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.4.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 25],
        [246],
        [108],
        ...,
        [236],
        [198],
        [148]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.4.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0237, -0.0102, -0.0177,  ...,  0.0081,  0.0185,  0.0058],
        [-0.0105,  0.0050, -0.0239,  ..., -0.0141, -0.0035, -0.0155],
        [-0.0171,  0.0053, -0.0269,  ..., -0.0153, -0.0035, -0.0165],
        ...,
        [ 0.0223,  0.0092,  0.0219,  ...,  0.0162, -0.0127, -0.0036],
        [-0.0199, -0.0015, -0.0047,  ..., -0.0204,  0.0248,  0.0017],
        [-0.0253, -0.0034, -0.0064,  ..., -0.0204,  0.0172, -0.0053]],
       device='cuda:0')

Parameter Name: base_model.model.layers.4.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0050,  0.0092,  0.0020,  ...,  0.0072,  0.0017, -0.0052],
        [-0.0052, -0.0001, -0.0104,  ...,  0.0045, -0.0046,  0.0069],
        [-0.0057, -0.0085,  0.0035,  ..., -0.0080, -0.0048, -0.0073],
        ...,
        [ 0.0106,  0.0101, -0.0016,  ..., -0.0097,  0.0013,  0.0085],
        [-0.0012,  0.0015,  0.0139,  ..., -0.0035,  0.0034,  0.0061],
        [-0.0009, -0.0107, -0.0100,  ...,  0.0077, -0.0086, -0.0121]],
       device='cuda:0')

Parameter Name: base_model.model.layers.4.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 55],
        [150],
        [220],
        ...,
        [ 78],
        [158],
        [ 80]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.4.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0038, -0.0213, -0.0042,  ...,  0.0072, -0.0130, -0.0170],
        [-0.0244, -0.0060, -0.0291,  ..., -0.0046,  0.0052, -0.0060],
        [ 0.0154, -0.0193, -0.0128,  ..., -0.0178, -0.0118,  0.0131],
        ...,
        [ 0.0039, -0.0208, -0.0210,  ..., -0.0216,  0.0063,  0.0177],
        [-0.0162, -0.0221, -0.0025,  ..., -0.0090, -0.0091,  0.0044],
        [-0.0109, -0.0002,  0.0007,  ...,  0.0125,  0.0160,  0.0065]],
       device='cuda:0')

Parameter Name: base_model.model.layers.4.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0232,  0.0281,  0.0255,  ...,  0.0252,  0.0257, -0.0206],
        [ 0.0075,  0.0139,  0.0042,  ...,  0.0061,  0.0152, -0.0129],
        [-0.0020, -0.0002,  0.0069,  ...,  0.0183, -0.0006, -0.0163],
        ...,
        [ 0.0157,  0.0109,  0.0040,  ...,  0.0166,  0.0199, -0.0121],
        [-0.0130, -0.0144, -0.0211,  ..., -0.0167, -0.0126,  0.0071],
        [ 0.0023,  0.0004, -0.0008,  ...,  0.0275,  0.0062, -0.0068]],
       device='cuda:0')

Parameter Name: base_model.model.layers.4.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[150],
        [246],
        [ 20],
        ...,
        [204],
        [255],
        [ 68]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.4.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0072,  0.0013, -0.0112,  ..., -0.0021,  0.0074, -0.0394],
        [ 0.0070,  0.0111, -0.0040,  ..., -0.0015, -0.0183,  0.0164],
        [-0.0034, -0.0062,  0.0125,  ...,  0.0243,  0.0104,  0.0040],
        ...,
        [ 0.0319, -0.0135,  0.0082,  ...,  0.0237,  0.0098,  0.0420],
        [ 0.0028, -0.0151,  0.0108,  ..., -0.0081,  0.0105, -0.0304],
        [ 0.0234,  0.0005, -0.0193,  ...,  0.0019, -0.0124,  0.0164]],
       device='cuda:0')

Parameter Name: base_model.model.layers.4.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0019, -0.0023, -0.0138,  ..., -0.0080,  0.0029, -0.0019],
        [-0.0036,  0.0229,  0.0169,  ..., -0.0100, -0.0150,  0.0041],
        [ 0.0076,  0.0150,  0.0087,  ...,  0.0069,  0.0033,  0.0027],
        ...,
        [ 0.0018,  0.0123,  0.0011,  ..., -0.0043, -0.0043, -0.0057],
        [-0.0030,  0.0064,  0.0036,  ..., -0.0051, -0.0020, -0.0020],
        [ 0.0112,  0.0052, -0.0167,  ...,  0.0075, -0.0049,  0.0150]],
       device='cuda:0')

Parameter Name: base_model.model.layers.4.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[254],
        [190],
        [229],
        ...,
        [201],
        [ 65],
        [153]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.4.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0041,  0.0127,  0.0165,  ..., -0.0131,  0.0041, -0.0215],
        [ 0.0064,  0.0201,  0.0077,  ..., -0.0220, -0.0373,  0.0037],
        [ 0.0096, -0.0049,  0.0088,  ...,  0.0236, -0.0060,  0.0006],
        ...,
        [-0.0248,  0.0008,  0.0186,  ..., -0.0062,  0.0087,  0.0081],
        [-0.0179, -0.0086, -0.0066,  ..., -0.0134, -0.0228, -0.0083],
        [-0.0029,  0.0064,  0.0132,  ..., -0.0135,  0.0041, -0.0055]],
       device='cuda:0')

Parameter Name: base_model.model.layers.4.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0139,  0.0164, -0.0166,  ...,  0.0100,  0.0098, -0.0013],
        [-0.0137, -0.0106, -0.0068,  ..., -0.0073,  0.0053,  0.0109],
        [ 0.0174,  0.0108, -0.0086,  ...,  0.0029, -0.0106,  0.0058],
        ...,
        [ 0.0078,  0.0159, -0.0111,  ..., -0.0028,  0.0105, -0.0106],
        [-0.0125,  0.0051,  0.0022,  ..., -0.0086,  0.0044,  0.0144],
        [ 0.0024, -0.0020,  0.0061,  ..., -0.0013,  0.0144,  0.0009]],
       device='cuda:0')

Parameter Name: base_model.model.layers.4.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 41],
        [ 45],
        [ 44],
        ...,
        [ 68],
        [ 41],
        [189]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.4.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[-0.0161,  0.0080, -0.0084,  ...,  0.0036,  0.0167, -0.0108],
        [ 0.0027, -0.0008, -0.0127,  ..., -0.0062,  0.0098,  0.0016],
        [-0.0051,  0.0223,  0.0078,  ...,  0.0043,  0.0107,  0.0187],
        ...,
        [ 0.0010,  0.0036,  0.0008,  ..., -0.0002,  0.0003, -0.0055],
        [-0.0106,  0.0083,  0.0135,  ..., -0.0068,  0.0021,  0.0026],
        [ 0.0119,  0.0008,  0.0073,  ..., -0.0018, -0.0010, -0.0040]],
       device='cuda:0')

Parameter Name: base_model.model.layers.4.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-3.3149e-03,  1.4889e-02, -9.4762e-03,  ..., -1.8832e-03,
         -7.4025e-03, -4.5970e-03],
        [-6.9791e-05, -1.8384e-03,  5.4018e-03,  ...,  4.4802e-04,
         -4.0368e-03, -4.2429e-04],
        [ 2.2262e-03, -5.0574e-03, -1.7100e-02,  ...,  2.6550e-03,
         -9.8755e-03, -6.0588e-03],
        ...,
        [-5.4750e-04,  2.6926e-03,  7.0363e-03,  ...,  4.7934e-03,
          1.3776e-02, -8.0369e-03],
        [ 3.0743e-03, -7.2769e-03, -1.7854e-03,  ..., -8.6727e-03,
          8.3909e-03, -1.4141e-03],
        [ 4.5975e-03, -2.9929e-03, -6.3086e-03,  ..., -1.3289e-02,
         -8.5561e-03, -7.3494e-04]], device='cuda:0')

Parameter Name: base_model.model.layers.4.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.2617, 0.2578, 0.2598,  ..., 0.2559, 0.2637, 0.2715], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.4.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.1885, 0.1865, 0.1816,  ..., 0.1885, 0.1865, 0.1855], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.5.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[238],
        [214],
        [127],
        ...,
        [ 68],
        [ 77],
        [241]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.5.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0117, -0.0275, -0.0176,  ...,  0.0045,  0.0158, -0.0195],
        [ 0.0126, -0.0097,  0.0105,  ...,  0.0204, -0.0001, -0.0158],
        [ 0.0064, -0.0292,  0.0027,  ..., -0.0171,  0.0212,  0.0009],
        ...,
        [ 0.0019,  0.0120, -0.0066,  ..., -0.0090, -0.0006,  0.0161],
        [ 0.0185,  0.0024,  0.0233,  ..., -0.0230, -0.0113, -0.0155],
        [ 0.0042, -0.0051, -0.0053,  ..., -0.0095, -0.0032, -0.0104]],
       device='cuda:0')

Parameter Name: base_model.model.layers.5.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0001,  0.0133,  0.0198,  ..., -0.0158, -0.0082,  0.0050],
        [-0.0082, -0.0133, -0.0107,  ...,  0.0045,  0.0064, -0.0162],
        [ 0.0126, -0.0105, -0.0151,  ...,  0.0136,  0.0089, -0.0171],
        ...,
        [-0.0015,  0.0047,  0.0046,  ..., -0.0065, -0.0151,  0.0042],
        [-0.0107, -0.0001,  0.0007,  ...,  0.0069, -0.0081, -0.0084],
        [ 0.0045, -0.0080, -0.0016,  ...,  0.0011, -0.0022, -0.0017]],
       device='cuda:0')

Parameter Name: base_model.model.layers.5.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[211],
        [101],
        [229],
        ...,
        [ 77],
        [238],
        [198]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.5.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[182],
        [ 73],
        [246],
        ...,
        [ 89],
        [ 95],
        [234]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.5.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0091, -0.0004,  0.0020,  ...,  0.0146, -0.0040, -0.0030],
        [ 0.0274,  0.0029, -0.0024,  ..., -0.0027,  0.0070, -0.0253],
        [ 0.0171, -0.0199,  0.0064,  ...,  0.0217,  0.0087, -0.0185],
        ...,
        [-0.0082, -0.0097, -0.0030,  ..., -0.0096,  0.0149,  0.0149],
        [-0.0126, -0.0057,  0.0224,  ...,  0.0125,  0.0097,  0.0030],
        [-0.0125,  0.0085, -0.0044,  ..., -0.0188, -0.0186,  0.0259]],
       device='cuda:0')

Parameter Name: base_model.model.layers.5.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-2.1748e-03,  4.7526e-03, -1.7480e-02,  ..., -8.3150e-04,
         -9.9252e-03, -1.6537e-03],
        [-1.5807e-02,  5.6229e-03, -5.2680e-03,  ..., -4.9434e-04,
          1.8110e-03, -1.6111e-03],
        [-8.1038e-03,  4.7389e-05,  3.4832e-03,  ...,  1.1977e-03,
         -2.0027e-02,  1.0068e-02],
        ...,
        [ 1.6246e-02, -1.6965e-02,  4.3665e-03,  ...,  1.5358e-02,
          2.1398e-02,  3.6193e-03],
        [-6.7931e-03, -3.1185e-04,  1.0253e-02,  ..., -4.3667e-03,
          1.7630e-02,  9.2437e-03],
        [ 7.6884e-03, -6.1816e-03, -8.2300e-04,  ...,  2.8355e-03,
          1.4240e-02,  6.4702e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.5.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[223],
        [ 97],
        [239],
        ...,
        [239],
        [230],
        [237]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.5.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0017, -0.0126, -0.0053,  ..., -0.0206, -0.0063, -0.0061],
        [-0.0175, -0.0012, -0.0047,  ...,  0.0065,  0.0032,  0.0150],
        [-0.0185,  0.0062,  0.0031,  ..., -0.0077,  0.0108, -0.0286],
        ...,
        [-0.0073,  0.0058,  0.0058,  ...,  0.0122,  0.0004, -0.0253],
        [-0.0124,  0.0080, -0.0030,  ...,  0.0069, -0.0248,  0.0139],
        [ 0.0131, -0.0137,  0.0046,  ..., -0.0131, -0.0013,  0.0138]],
       device='cuda:0')

Parameter Name: base_model.model.layers.5.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0053, -0.0188,  0.0057,  ..., -0.0011, -0.0029,  0.0051],
        [ 0.0180, -0.0165,  0.0065,  ...,  0.0141, -0.0051,  0.0012],
        [ 0.0039, -0.0037,  0.0074,  ...,  0.0174,  0.0033, -0.0135],
        ...,
        [-0.0043, -0.0184,  0.0196,  ...,  0.0040, -0.0152,  0.0133],
        [-0.0119,  0.0106, -0.0177,  ..., -0.0054,  0.0032,  0.0137],
        [-0.0195,  0.0170, -0.0024,  ...,  0.0053,  0.0108,  0.0002]],
       device='cuda:0')

Parameter Name: base_model.model.layers.5.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 17],
        [164],
        [202],
        ...,
        [167],
        [233],
        [154]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.5.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0045, -0.0208,  0.0082,  ..., -0.0122, -0.0180,  0.0028],
        [ 0.0057,  0.0022, -0.0182,  ...,  0.0230, -0.0106, -0.0081],
        [ 0.0131, -0.0083, -0.0144,  ..., -0.0020,  0.0055,  0.0075],
        ...,
        [-0.0050, -0.0096,  0.0128,  ...,  0.0105, -0.0108,  0.0086],
        [-0.0209, -0.0140, -0.0085,  ..., -0.0103,  0.0031, -0.0046],
        [-0.0135,  0.0049,  0.0282,  ..., -0.0115, -0.0178,  0.0047]],
       device='cuda:0')

Parameter Name: base_model.model.layers.5.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0046,  0.0013,  0.0100,  ...,  0.0069, -0.0061, -0.0072],
        [-0.0018,  0.0077, -0.0127,  ..., -0.0154, -0.0056,  0.0105],
        [-0.0026,  0.0052, -0.0054,  ..., -0.0027, -0.0023,  0.0010],
        ...,
        [ 0.0124,  0.0058,  0.0028,  ...,  0.0094, -0.0021,  0.0014],
        [-0.0007, -0.0108,  0.0045,  ...,  0.0078, -0.0046,  0.0017],
        [-0.0125,  0.0011,  0.0053,  ...,  0.0004,  0.0113,  0.0009]],
       device='cuda:0')

Parameter Name: base_model.model.layers.5.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[159],
        [151],
        [119],
        ...,
        [218],
        [191],
        [237]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.5.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0012, -0.0084, -0.0281,  ...,  0.0068,  0.0002,  0.0229],
        [-0.0065,  0.0033, -0.0072,  ...,  0.0134, -0.0041, -0.0209],
        [ 0.0032,  0.0050,  0.0033,  ...,  0.0002, -0.0145, -0.0082],
        ...,
        [ 0.0039, -0.0349,  0.0116,  ...,  0.0004, -0.0219,  0.0158],
        [ 0.0004,  0.0075, -0.0250,  ...,  0.0333,  0.0035,  0.0079],
        [-0.0079,  0.0007, -0.0098,  ..., -0.0130,  0.0188, -0.0167]],
       device='cuda:0')

Parameter Name: base_model.model.layers.5.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0118, -0.0082,  0.0145,  ..., -0.0074, -0.0025, -0.0152],
        [ 0.0020,  0.0033,  0.0048,  ...,  0.0123,  0.0128,  0.0094],
        [-0.0090,  0.0004, -0.0170,  ...,  0.0193,  0.0146, -0.0141],
        ...,
        [-0.0046, -0.0097,  0.0053,  ..., -0.0055, -0.0089,  0.0049],
        [-0.0173,  0.0070, -0.0014,  ...,  0.0012, -0.0176, -0.0089],
        [-0.0080,  0.0052,  0.0137,  ..., -0.0046, -0.0190,  0.0002]],
       device='cuda:0')

Parameter Name: base_model.model.layers.5.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[234],
        [150],
        [150],
        ...,
        [217],
        [ 18],
        [108]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.5.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 0.0014, -0.0075,  0.0132,  ..., -0.0016, -0.0035,  0.0123],
        [-0.0084, -0.0187,  0.0193,  ..., -0.0025,  0.0223,  0.0135],
        [-0.0135,  0.0224,  0.0036,  ..., -0.0164,  0.0124,  0.0150],
        ...,
        [-0.0149, -0.0209,  0.0050,  ..., -0.0145,  0.0097,  0.0127],
        [-0.0162,  0.0107, -0.0055,  ...,  0.0107,  0.0222, -0.0186],
        [-0.0041, -0.0077, -0.0133,  ..., -0.0059, -0.0002,  0.0240]],
       device='cuda:0')

Parameter Name: base_model.model.layers.5.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0119, -0.0208, -0.0146,  ..., -0.0035, -0.0138, -0.0179],
        [-0.0014,  0.0038,  0.0018,  ..., -0.0062,  0.0093,  0.0108],
        [-0.0283,  0.0051,  0.0108,  ...,  0.0180, -0.0026,  0.0041],
        ...,
        [ 0.0195, -0.0049, -0.0163,  ...,  0.0044, -0.0184, -0.0048],
        [ 0.0098, -0.0142,  0.0040,  ..., -0.0125, -0.0063, -0.0025],
        [ 0.0079, -0.0219,  0.0034,  ..., -0.0050, -0.0059, -0.0176]],
       device='cuda:0')

Parameter Name: base_model.model.layers.5.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.2637, 0.2637, 0.2598,  ..., 0.2520, 0.2676, 0.2695], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.5.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.2041, 0.1934, 0.1895,  ..., 0.2051, 0.1992, 0.2031], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.6.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[233],
        [ 18],
        [234],
        ...,
        [198],
        [ 22],
        [ 22]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.6.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 5.2582e-03, -8.1264e-03,  5.3494e-05,  ..., -1.7863e-02,
         -2.0965e-03, -1.6583e-02],
        [ 2.0955e-02, -1.0167e-02, -1.0610e-02,  ...,  1.9119e-02,
          4.0866e-03,  1.8428e-02],
        [-6.5371e-03,  5.7390e-03,  2.1917e-03,  ..., -1.1676e-03,
         -2.1944e-02, -8.2092e-03],
        ...,
        [-2.1362e-02, -2.2423e-03, -1.5021e-02,  ..., -1.8631e-02,
          1.1031e-02, -1.6104e-02],
        [-2.2695e-03, -5.0211e-03, -1.8616e-02,  ...,  2.1852e-02,
          1.1525e-02, -3.4735e-03],
        [-2.5651e-05, -5.2500e-03,  2.3540e-03,  ...,  9.0133e-03,
          8.0877e-03, -3.9008e-04]], device='cuda:0')

Parameter Name: base_model.model.layers.6.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0074, -0.0116, -0.0009,  ..., -0.0082,  0.0112, -0.0078],
        [ 0.0036,  0.0045,  0.0006,  ..., -0.0046,  0.0047,  0.0014],
        [-0.0070,  0.0074,  0.0093,  ..., -0.0057,  0.0065,  0.0041],
        ...,
        [ 0.0024,  0.0059, -0.0056,  ..., -0.0090, -0.0018, -0.0004],
        [-0.0014,  0.0011,  0.0060,  ...,  0.0066,  0.0098, -0.0004],
        [ 0.0092, -0.0010,  0.0029,  ..., -0.0096, -0.0093, -0.0058]],
       device='cuda:0')

Parameter Name: base_model.model.layers.6.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[126],
        [122],
        [ 97],
        ...,
        [160],
        [247],
        [172]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.6.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 67],
        [103],
        [ 67],
        ...,
        [ 73],
        [ 61],
        [137]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.6.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0218,  0.0056,  0.0026,  ...,  0.0127, -0.0008,  0.0040],
        [ 0.0236, -0.0099, -0.0229,  ...,  0.0070,  0.0018,  0.0044],
        [ 0.0202,  0.0157,  0.0060,  ..., -0.0081,  0.0105,  0.0067],
        ...,
        [-0.0173,  0.0141, -0.0143,  ..., -0.0132, -0.0026, -0.0069],
        [ 0.0024,  0.0151, -0.0325,  ..., -0.0153, -0.0042, -0.0108],
        [-0.0223, -0.0142, -0.0100,  ..., -0.0177, -0.0073, -0.0118]],
       device='cuda:0')

Parameter Name: base_model.model.layers.6.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0005, -0.0061, -0.0093,  ..., -0.0027,  0.0028,  0.0071],
        [-0.0173,  0.0122,  0.0148,  ...,  0.0155,  0.0045, -0.0130],
        [ 0.0210, -0.0193, -0.0277,  ..., -0.0115, -0.0047,  0.0181],
        ...,
        [-0.0100,  0.0121,  0.0109,  ...,  0.0080, -0.0036, -0.0127],
        [ 0.0127,  0.0013, -0.0053,  ..., -0.0055, -0.0105, -0.0049],
        [ 0.0270, -0.0230, -0.0376,  ..., -0.0341, -0.0313,  0.0163]],
       device='cuda:0')

Parameter Name: base_model.model.layers.6.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 76],
        [182],
        [153],
        ...,
        [173],
        [ 92],
        [103]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.6.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0172, -0.0046, -0.0024,  ..., -0.0130,  0.0059,  0.0044],
        [ 0.0069, -0.0130, -0.0043,  ..., -0.0237,  0.0164, -0.0114],
        [-0.0151, -0.0137, -0.0139,  ...,  0.0351, -0.0120, -0.0177],
        ...,
        [-0.0158, -0.0154,  0.0160,  ...,  0.0094, -0.0021,  0.0240],
        [ 0.0039,  0.0111, -0.0035,  ..., -0.0348,  0.0103, -0.0044],
        [-0.0198,  0.0098, -0.0156,  ..., -0.0058,  0.0197,  0.0131]],
       device='cuda:0')

Parameter Name: base_model.model.layers.6.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 4.1027e-03,  1.2705e-03, -9.8952e-03,  ..., -1.0909e-02,
          3.4468e-03, -6.3020e-03],
        [ 7.6477e-04,  1.8822e-02, -8.9776e-03,  ..., -7.2987e-03,
         -2.6392e-03,  1.7809e-02],
        [-3.4634e-03, -4.5746e-03, -2.5177e-03,  ..., -7.1683e-03,
         -6.4851e-04,  2.8565e-03],
        ...,
        [ 2.4086e-03,  7.7766e-03, -8.0651e-03,  ..., -1.4050e-02,
          2.1579e-03,  9.5485e-03],
        [-2.3183e-05, -1.9299e-02, -1.0575e-03,  ...,  1.4518e-02,
          2.4346e-04, -1.1858e-02],
        [-9.1386e-03,  1.9027e-02, -1.8308e-03,  ..., -1.3276e-02,
          6.8033e-03,  4.4884e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.6.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 82],
        [201],
        [ 41],
        ...,
        [122],
        [ 42],
        [ 20]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.6.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0122, -0.0238,  0.0196,  ...,  0.0096, -0.0075, -0.0052],
        [-0.0159, -0.0206,  0.0229,  ..., -0.0043,  0.0177,  0.0086],
        [-0.0218, -0.0064,  0.0089,  ...,  0.0268, -0.0225, -0.0056],
        ...,
        [-0.0034, -0.0008, -0.0091,  ..., -0.0098, -0.0145, -0.0035],
        [ 0.0010,  0.0163,  0.0201,  ...,  0.0007,  0.0392,  0.0177],
        [-0.0030, -0.0375,  0.0050,  ..., -0.0051,  0.0344, -0.0203]],
       device='cuda:0')

Parameter Name: base_model.model.layers.6.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-7.2786e-03,  6.0143e-03,  7.5913e-03,  ...,  1.3735e-03,
         -4.7694e-03, -8.2186e-03],
        [-5.1848e-03, -4.8336e-03, -5.4662e-03,  ..., -7.3314e-03,
         -2.0314e-02, -2.2764e-02],
        [ 2.2252e-02,  1.3607e-03,  5.9378e-03,  ...,  5.6135e-03,
         -5.7771e-03, -2.5542e-03],
        ...,
        [-1.8225e-02,  6.6486e-03, -1.8829e-02,  ..., -1.0348e-02,
         -1.6366e-02,  1.1556e-02],
        [-3.9759e-03,  6.3219e-03,  1.1572e-02,  ...,  4.7492e-03,
         -6.6993e-03, -6.2836e-03],
        [-1.8328e-03,  3.3619e-05,  1.3765e-02,  ...,  7.9282e-03,
         -1.5608e-02, -1.9716e-06]], device='cuda:0')

Parameter Name: base_model.model.layers.6.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[238],
        [246],
        [246],
        ...,
        [ 55],
        [ 70],
        [203]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.6.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0034, -0.0285,  0.0092,  ...,  0.0042, -0.0120,  0.0254],
        [ 0.0164,  0.0241, -0.0085,  ..., -0.0204,  0.0118, -0.0079],
        [ 0.0209,  0.0068,  0.0076,  ..., -0.0248, -0.0043,  0.0182],
        ...,
        [-0.0111, -0.0055, -0.0048,  ...,  0.0218,  0.0087,  0.0196],
        [ 0.0071, -0.0191,  0.0322,  ...,  0.0183,  0.0104,  0.0198],
        [ 0.0173,  0.0254, -0.0069,  ..., -0.0199,  0.0120, -0.0143]],
       device='cuda:0')

Parameter Name: base_model.model.layers.6.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0035, -0.0116, -0.0133,  ..., -0.0166,  0.0105, -0.0084],
        [-0.0055,  0.0006,  0.0068,  ...,  0.0004,  0.0182, -0.0148],
        [-0.0020,  0.0057, -0.0096,  ..., -0.0145,  0.0101,  0.0002],
        ...,
        [-0.0077,  0.0019,  0.0170,  ...,  0.0052, -0.0054,  0.0085],
        [ 0.0187, -0.0082,  0.0079,  ..., -0.0181,  0.0054, -0.0128],
        [-0.0015, -0.0099,  0.0066,  ..., -0.0069,  0.0004, -0.0117]],
       device='cuda:0')

Parameter Name: base_model.model.layers.6.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[229],
        [150],
        [ 75],
        ...,
        [ 45],
        [115],
        [230]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.6.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 0.0033,  0.0092, -0.0102,  ..., -0.0045,  0.0114,  0.0183],
        [-0.0143, -0.0052,  0.0234,  ..., -0.0149,  0.0199,  0.0052],
        [-0.0109, -0.0059,  0.0123,  ..., -0.0215,  0.0050, -0.0030],
        ...,
        [-0.0049, -0.0066, -0.0082,  ..., -0.0168,  0.0188,  0.0099],
        [-0.0200,  0.0047,  0.0038,  ...,  0.0033,  0.0188,  0.0130],
        [-0.0007,  0.0166, -0.0008,  ...,  0.0072, -0.0280, -0.0165]],
       device='cuda:0')

Parameter Name: base_model.model.layers.6.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0081, -0.0034,  0.0030,  ..., -0.0003,  0.0053, -0.0052],
        [-0.0035, -0.0004,  0.0028,  ...,  0.0010, -0.0107, -0.0230],
        [-0.0107,  0.0080,  0.0196,  ..., -0.0103, -0.0090,  0.0116],
        ...,
        [ 0.0021, -0.0119, -0.0166,  ...,  0.0032,  0.0057,  0.0005],
        [-0.0086, -0.0176, -0.0117,  ...,  0.0045, -0.0040, -0.0050],
        [ 0.0001, -0.0140,  0.0045,  ...,  0.0004, -0.0175, -0.0011]],
       device='cuda:0')

Parameter Name: base_model.model.layers.6.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.3184, 0.3555, 0.3281,  ..., 0.3164, 0.3359, 0.3203], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.6.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.2168, 0.2061, 0.2041,  ..., 0.2178, 0.2109, 0.2129], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.7.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[113],
        [108],
        [218],
        ...,
        [ 33],
        [ 99],
        [ 73]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.7.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0061, -0.0152,  0.0054,  ..., -0.0147, -0.0165,  0.0131],
        [-0.0211,  0.0298,  0.0078,  ...,  0.0185,  0.0155,  0.0101],
        [ 0.0154,  0.0190, -0.0174,  ...,  0.0118, -0.0137,  0.0288],
        ...,
        [ 0.0133,  0.0088,  0.0153,  ...,  0.0242,  0.0122,  0.0223],
        [-0.0135,  0.0114, -0.0273,  ..., -0.0048,  0.0241,  0.0020],
        [ 0.0056,  0.0063, -0.0288,  ...,  0.0106, -0.0122, -0.0127]],
       device='cuda:0')

Parameter Name: base_model.model.layers.7.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0152, -0.0098, -0.0039,  ..., -0.0034, -0.0149, -0.0185],
        [ 0.0145, -0.0355, -0.0121,  ..., -0.0020, -0.0066,  0.0040],
        [ 0.0085,  0.0132,  0.0085,  ...,  0.0159,  0.0031,  0.0082],
        ...,
        [ 0.0016,  0.0069, -0.0078,  ...,  0.0033,  0.0008, -0.0064],
        [-0.0082, -0.0119,  0.0111,  ...,  0.0087, -0.0190,  0.0085],
        [-0.0042,  0.0071,  0.0143,  ..., -0.0057,  0.0028,  0.0059]],
       device='cuda:0')

Parameter Name: base_model.model.layers.7.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[238],
        [223],
        [153],
        ...,
        [ 78],
        [ 70],
        [ 28]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.7.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[193],
        [ 86],
        [199],
        ...,
        [149],
        [210],
        [116]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.7.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0007,  0.0132,  0.0038,  ..., -0.0286, -0.0231, -0.0200],
        [-0.0156, -0.0111, -0.0063,  ..., -0.0136,  0.0063, -0.0202],
        [ 0.0028,  0.0211,  0.0108,  ..., -0.0063, -0.0166, -0.0130],
        ...,
        [-0.0044,  0.0002,  0.0007,  ...,  0.0064, -0.0217, -0.0009],
        [-0.0124,  0.0221,  0.0105,  ...,  0.0088,  0.0161,  0.0183],
        [-0.0071,  0.0179, -0.0074,  ...,  0.0143, -0.0014, -0.0032]],
       device='cuda:0')

Parameter Name: base_model.model.layers.7.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0026, -0.0074,  0.0021,  ..., -0.0127,  0.0092,  0.0012],
        [-0.0090,  0.0064, -0.0043,  ..., -0.0192, -0.0018, -0.0281],
        [-0.0066, -0.0004, -0.0053,  ..., -0.0046, -0.0026, -0.0028],
        ...,
        [-0.0106, -0.0018, -0.0097,  ..., -0.0099, -0.0025,  0.0086],
        [ 0.0029,  0.0056, -0.0029,  ..., -0.0005, -0.0050,  0.0130],
        [ 0.0105,  0.0079,  0.0036,  ..., -0.0037, -0.0157, -0.0173]],
       device='cuda:0')

Parameter Name: base_model.model.layers.7.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 76],
        [238],
        [110],
        ...,
        [174],
        [199],
        [214]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.7.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-1.0596e-03,  2.3620e-03,  3.3819e-03,  ...,  6.1111e-03,
         -1.2150e-03, -9.7750e-03],
        [ 1.0035e-02,  1.5726e-02,  7.8223e-03,  ..., -2.3075e-02,
          1.6186e-02,  2.6469e-02],
        [-4.8253e-03, -8.5810e-03, -9.1972e-03,  ...,  1.0145e-02,
         -2.3133e-02,  1.1378e-02],
        ...,
        [-6.8995e-03, -1.3681e-03,  1.2460e-02,  ...,  1.8931e-02,
          1.9207e-03,  1.9406e-02],
        [-2.4092e-02, -1.8766e-03,  1.7340e-02,  ...,  4.3841e-05,
         -1.4686e-02, -1.8517e-02],
        [-2.6358e-03,  1.0109e-02, -4.7393e-03,  ...,  9.2880e-03,
          1.1076e-02,  2.2765e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.7.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-7.8401e-04, -1.3039e-02, -1.9713e-03,  ..., -1.3550e-02,
          1.6272e-02, -3.2455e-03],
        [ 4.4477e-03, -1.1441e-02,  4.5560e-03,  ..., -6.3800e-03,
         -5.5454e-03, -3.5070e-03],
        [-1.7831e-02, -2.2865e-02,  1.5556e-02,  ..., -6.8781e-03,
         -8.2965e-03, -9.4544e-03],
        ...,
        [ 2.0211e-02,  1.1382e-02, -2.8152e-03,  ..., -1.1693e-02,
         -1.8152e-02,  2.8826e-02],
        [-8.4650e-03,  9.4112e-04,  8.5656e-03,  ..., -1.2090e-02,
          1.0061e-02, -1.0611e-02],
        [ 6.0581e-03, -7.6061e-03,  3.1704e-04,  ..., -7.8009e-05,
         -1.3723e-02, -3.2134e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.7.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[105],
        [198],
        [ 74],
        ...,
        [ 30],
        [196],
        [ 89]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.7.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0019,  0.0039, -0.0062,  ..., -0.0180,  0.0285,  0.0061],
        [-0.0258,  0.0111,  0.0299,  ..., -0.0249,  0.0162,  0.0130],
        [-0.0092,  0.0009,  0.0103,  ...,  0.0008,  0.0309, -0.0216],
        ...,
        [ 0.0169, -0.0024,  0.0200,  ..., -0.0192,  0.0061,  0.0016],
        [-0.0058, -0.0039, -0.0090,  ...,  0.0007,  0.0039, -0.0001],
        [ 0.0027,  0.0115, -0.0185,  ..., -0.0013, -0.0048, -0.0051]],
       device='cuda:0')

Parameter Name: base_model.model.layers.7.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0013,  0.0009, -0.0009,  ...,  0.0073,  0.0016,  0.0100],
        [ 0.0163,  0.0171,  0.0019,  ..., -0.0104,  0.0046,  0.0034],
        [ 0.0053, -0.0029, -0.0076,  ..., -0.0019,  0.0006,  0.0038],
        ...,
        [-0.0065, -0.0125, -0.0055,  ...,  0.0097,  0.0104,  0.0145],
        [-0.0126, -0.0115, -0.0133,  ..., -0.0129, -0.0009, -0.0029],
        [ 0.0026, -0.0113,  0.0053,  ..., -0.0081,  0.0054, -0.0090]],
       device='cuda:0')

Parameter Name: base_model.model.layers.7.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 33],
        [154],
        [205],
        ...,
        [ 55],
        [116],
        [118]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.7.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0208,  0.0188,  0.0095,  ...,  0.0089,  0.0011,  0.0102],
        [ 0.0124,  0.0115, -0.0015,  ...,  0.0305, -0.0022,  0.0182],
        [-0.0057, -0.0048, -0.0054,  ..., -0.0128,  0.0168,  0.0027],
        ...,
        [ 0.0191,  0.0013, -0.0100,  ...,  0.0072, -0.0016,  0.0159],
        [ 0.0165, -0.0249, -0.0066,  ..., -0.0274,  0.0124,  0.0040],
        [-0.0002,  0.0102, -0.0069,  ...,  0.0230,  0.0111, -0.0108]],
       device='cuda:0')

Parameter Name: base_model.model.layers.7.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0027,  0.0043, -0.0077,  ..., -0.0017, -0.0059,  0.0012],
        [ 0.0097, -0.0068, -0.0112,  ..., -0.0148,  0.0070, -0.0002],
        [ 0.0020,  0.0061, -0.0042,  ...,  0.0119, -0.0128,  0.0102],
        ...,
        [ 0.0055,  0.0112, -0.0213,  ...,  0.0049, -0.0122,  0.0059],
        [-0.0170, -0.0119,  0.0117,  ..., -0.0046,  0.0142, -0.0130],
        [ 0.0097, -0.0042,  0.0081,  ..., -0.0257,  0.0069,  0.0104]],
       device='cuda:0')

Parameter Name: base_model.model.layers.7.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[239],
        [ 20],
        [230],
        ...,
        [130],
        [ 17],
        [200]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.7.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 0.0004, -0.0065, -0.0075,  ...,  0.0091,  0.0054, -0.0110],
        [-0.0082,  0.0081, -0.0062,  ...,  0.0052,  0.0282,  0.0024],
        [-0.0193,  0.0080, -0.0220,  ..., -0.0051,  0.0263,  0.0098],
        ...,
        [ 0.0059, -0.0008,  0.0122,  ..., -0.0012, -0.0250, -0.0092],
        [-0.0039,  0.0036, -0.0053,  ..., -0.0015, -0.0011,  0.0094],
        [-0.0116, -0.0037, -0.0152,  ...,  0.0079,  0.0292, -0.0114]],
       device='cuda:0')

Parameter Name: base_model.model.layers.7.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0151, -0.0029, -0.0120,  ...,  0.0030, -0.0215,  0.0030],
        [-0.0024,  0.0059, -0.0013,  ...,  0.0098, -0.0002, -0.0036],
        [ 0.0203,  0.0036, -0.0002,  ...,  0.0030, -0.0064,  0.0084],
        ...,
        [-0.0068, -0.0050,  0.0112,  ..., -0.0100,  0.0021, -0.0032],
        [-0.0115, -0.0152,  0.0199,  ..., -0.0215, -0.0018, -0.0093],
        [-0.0168, -0.0089,  0.0084,  ..., -0.0007,  0.0139, -0.0165]],
       device='cuda:0')

Parameter Name: base_model.model.layers.7.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.3223, 0.3652, 0.3379,  ..., 0.3242, 0.3574, 0.3301], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.7.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.2314, 0.2158, 0.2178,  ..., 0.2256, 0.2246, 0.2236], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.8.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[111],
        [173],
        [118],
        ...,
        [206],
        [109],
        [ 78]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.8.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0102,  0.0195, -0.0086,  ..., -0.0134, -0.0107,  0.0014],
        [-0.0055, -0.0079, -0.0261,  ...,  0.0010, -0.0041,  0.0006],
        [-0.0098, -0.0246,  0.0133,  ...,  0.0118, -0.0127, -0.0149],
        ...,
        [ 0.0137, -0.0299, -0.0329,  ...,  0.0123,  0.0070, -0.0013],
        [-0.0060, -0.0081,  0.0248,  ...,  0.0046,  0.0330, -0.0263],
        [ 0.0044,  0.0299, -0.0119,  ..., -0.0109, -0.0116,  0.0200]],
       device='cuda:0')

Parameter Name: base_model.model.layers.8.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0002, -0.0072,  0.0117,  ..., -0.0021, -0.0007,  0.0108],
        [ 0.0100,  0.0076,  0.0124,  ...,  0.0018, -0.0052,  0.0061],
        [-0.0024,  0.0030, -0.0070,  ...,  0.0074, -0.0063,  0.0045],
        ...,
        [-0.0123, -0.0038, -0.0141,  ...,  0.0110,  0.0101,  0.0158],
        [ 0.0160,  0.0090,  0.0125,  ..., -0.0098, -0.0004, -0.0163],
        [-0.0159,  0.0003, -0.0175,  ...,  0.0021, -0.0045,  0.0167]],
       device='cuda:0')

Parameter Name: base_model.model.layers.8.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[230],
        [226],
        [ 78],
        ...,
        [223],
        [167],
        [110]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.8.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[172],
        [110],
        [ 29],
        ...,
        [ 29],
        [217],
        [111]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.8.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0124,  0.0125,  0.0032,  ...,  0.0085,  0.0180,  0.0032],
        [ 0.0030, -0.0068,  0.0210,  ...,  0.0015, -0.0128, -0.0183],
        [-0.0134, -0.0170, -0.0074,  ..., -0.0003, -0.0277, -0.0148],
        ...,
        [ 0.0042, -0.0025,  0.0100,  ..., -0.0116, -0.0228, -0.0095],
        [-0.0058,  0.0130, -0.0009,  ...,  0.0042,  0.0192,  0.0054],
        [-0.0007, -0.0148,  0.0031,  ...,  0.0018, -0.0209, -0.0173]],
       device='cuda:0')

Parameter Name: base_model.model.layers.8.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 3.9423e-04, -1.3384e-02, -1.1536e-02,  ...,  1.7963e-03,
          1.8339e-02,  2.8627e-03],
        [ 1.0338e-03, -5.0181e-03, -9.6987e-03,  ..., -9.2389e-03,
          4.1056e-03,  6.9660e-03],
        [ 6.0765e-03,  3.7493e-03, -4.2990e-03,  ..., -5.2730e-03,
          1.9190e-03, -7.2260e-03],
        ...,
        [-1.0925e-02,  1.6993e-04,  1.6406e-02,  ...,  8.1440e-03,
         -1.4483e-02, -6.3227e-05],
        [-8.3169e-03,  6.3153e-03,  9.7533e-03,  ...,  7.2354e-03,
         -2.7330e-03, -5.0089e-03],
        [-8.5838e-03,  2.2759e-03,  5.4903e-03,  ..., -1.3661e-03,
         -1.3241e-02,  6.3785e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.8.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 85],
        [213],
        [ 77],
        ...,
        [150],
        [ 19],
        [206]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.8.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0058, -0.0105, -0.0190,  ..., -0.0155,  0.0111, -0.0090],
        [-0.0104, -0.0202,  0.0128,  ...,  0.0072,  0.0022,  0.0034],
        [-0.0080, -0.0063,  0.0114,  ...,  0.0100, -0.0150,  0.0065],
        ...,
        [-0.0203, -0.0111,  0.0187,  ..., -0.0154, -0.0021, -0.0043],
        [-0.0056, -0.0186, -0.0039,  ...,  0.0209,  0.0019,  0.0001],
        [ 0.0174, -0.0074, -0.0245,  ...,  0.0127, -0.0095,  0.0047]],
       device='cuda:0')

Parameter Name: base_model.model.layers.8.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0078,  0.0143,  0.0099,  ...,  0.0020, -0.0048, -0.0009],
        [-0.0051, -0.0043,  0.0035,  ..., -0.0077, -0.0022,  0.0112],
        [ 0.0096, -0.0016, -0.0005,  ...,  0.0063,  0.0053, -0.0070],
        ...,
        [-0.0071,  0.0044,  0.0036,  ..., -0.0032,  0.0020,  0.0018],
        [ 0.0019,  0.0049,  0.0131,  ...,  0.0106,  0.0145, -0.0066],
        [ 0.0055,  0.0100,  0.0109,  ...,  0.0021,  0.0067, -0.0052]],
       device='cuda:0')

Parameter Name: base_model.model.layers.8.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 97],
        [213],
        [102],
        ...,
        [223],
        [236],
        [ 73]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.8.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0131,  0.0135,  0.0032,  ..., -0.0156,  0.0390,  0.0106],
        [-0.0003,  0.0026, -0.0004,  ...,  0.0115,  0.0187,  0.0095],
        [ 0.0034, -0.0045,  0.0044,  ..., -0.0058, -0.0038,  0.0231],
        ...,
        [ 0.0057,  0.0248,  0.0132,  ..., -0.0070,  0.0082, -0.0020],
        [ 0.0148,  0.0019,  0.0057,  ..., -0.0113,  0.0109, -0.0109],
        [-0.0045, -0.0275, -0.0147,  ..., -0.0118,  0.0014,  0.0118]],
       device='cuda:0')

Parameter Name: base_model.model.layers.8.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0107, -0.0071, -0.0078,  ..., -0.0073,  0.0144,  0.0105],
        [ 0.0035,  0.0062, -0.0157,  ...,  0.0081,  0.0092, -0.0014],
        [ 0.0005,  0.0107, -0.0046,  ...,  0.0096,  0.0087,  0.0025],
        ...,
        [-0.0104, -0.0114,  0.0092,  ..., -0.0059, -0.0121, -0.0018],
        [-0.0290, -0.0044,  0.0076,  ..., -0.0038, -0.0205,  0.0028],
        [ 0.0102, -0.0052, -0.0062,  ..., -0.0013, -0.0035,  0.0094]],
       device='cuda:0')

Parameter Name: base_model.model.layers.8.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[228],
        [249],
        [ 34],
        ...,
        [206],
        [108],
        [ 17]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.8.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0045,  0.0007, -0.0257,  ..., -0.0018, -0.0010, -0.0071],
        [ 0.0079, -0.0207,  0.0172,  ..., -0.0150,  0.0248, -0.0046],
        [ 0.0144, -0.0095, -0.0205,  ...,  0.0078, -0.0059, -0.0079],
        ...,
        [-0.0105,  0.0088, -0.0072,  ..., -0.0055, -0.0266,  0.0074],
        [ 0.0056, -0.0147,  0.0372,  ..., -0.0032, -0.0036,  0.0117],
        [ 0.0135,  0.0030,  0.0148,  ..., -0.0111, -0.0093,  0.0066]],
       device='cuda:0')

Parameter Name: base_model.model.layers.8.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0049,  0.0100,  0.0172,  ..., -0.0124,  0.0047, -0.0034],
        [ 0.0094, -0.0249,  0.0014,  ..., -0.0194,  0.0032,  0.0014],
        [-0.0302,  0.0075,  0.0061,  ..., -0.0089,  0.0148, -0.0116],
        ...,
        [-0.0147,  0.0153, -0.0022,  ..., -0.0075,  0.0003, -0.0079],
        [ 0.0017, -0.0052, -0.0094,  ..., -0.0064,  0.0002, -0.0021],
        [ 0.0096, -0.0103,  0.0073,  ..., -0.0085,  0.0133, -0.0022]],
       device='cuda:0')

Parameter Name: base_model.model.layers.8.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[238],
        [ 65],
        [113],
        ...,
        [108],
        [113],
        [ 17]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.8.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 0.0019,  0.0057,  0.0087,  ...,  0.0163,  0.0008, -0.0012],
        [ 0.0109, -0.0072, -0.0069,  ..., -0.0045,  0.0082, -0.0011],
        [ 0.0140,  0.0298,  0.0144,  ...,  0.0033, -0.0168, -0.0065],
        ...,
        [-0.0098,  0.0032,  0.0106,  ...,  0.0040,  0.0111, -0.0127],
        [-0.0111,  0.0126,  0.0107,  ...,  0.0058, -0.0271, -0.0131],
        [-0.0052,  0.0039, -0.0072,  ...,  0.0175, -0.0068,  0.0035]],
       device='cuda:0')

Parameter Name: base_model.model.layers.8.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0073,  0.0043, -0.0006,  ..., -0.0014,  0.0003, -0.0108],
        [-0.0066,  0.0166, -0.0020,  ...,  0.0022,  0.0052, -0.0045],
        [ 0.0089,  0.0101, -0.0115,  ...,  0.0125, -0.0193, -0.0049],
        ...,
        [-0.0023,  0.0021,  0.0089,  ..., -0.0038,  0.0023,  0.0026],
        [-0.0015, -0.0051,  0.0220,  ..., -0.0160,  0.0054, -0.0072],
        [-0.0030,  0.0002, -0.0112,  ..., -0.0158, -0.0050,  0.0052]],
       device='cuda:0')

Parameter Name: base_model.model.layers.8.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.3320, 0.3457, 0.3301,  ..., 0.3203, 0.3438, 0.3223], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.8.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.2383, 0.2236, 0.2178,  ..., 0.2363, 0.2285, 0.2256], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.9.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[209],
        [ 71],
        [ 77],
        ...,
        [170],
        [106],
        [ 89]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.9.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-8.1421e-03, -1.8166e-02, -1.7573e-02,  ...,  1.0766e-02,
          1.2305e-02, -1.3868e-02],
        [-9.4449e-06, -1.2087e-03,  2.4280e-02,  ...,  1.9668e-02,
         -5.3349e-03,  3.5104e-03],
        [-2.1348e-03, -8.4304e-03, -7.7978e-03,  ...,  8.9845e-05,
          2.5608e-02, -9.8286e-03],
        ...,
        [-2.6858e-02, -1.0818e-02,  2.1984e-03,  ..., -2.7304e-02,
          7.8225e-03,  1.0500e-02],
        [ 8.0095e-04,  1.7296e-02, -9.4488e-03,  ...,  1.1873e-02,
         -2.1689e-02, -8.2944e-03],
        [ 1.0312e-03,  1.5239e-02, -2.6779e-02,  ...,  1.9811e-02,
         -8.4882e-03,  1.6078e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.9.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0014, -0.0009,  0.0060,  ..., -0.0057, -0.0007,  0.0017],
        [-0.0004,  0.0112,  0.0180,  ..., -0.0078, -0.0028,  0.0108],
        [-0.0081,  0.0112,  0.0058,  ..., -0.0047, -0.0034, -0.0002],
        ...,
        [ 0.0110,  0.0064,  0.0132,  ...,  0.0082, -0.0128, -0.0037],
        [ 0.0006,  0.0190, -0.0029,  ...,  0.0165,  0.0015, -0.0097],
        [-0.0129, -0.0090, -0.0088,  ...,  0.0092, -0.0087, -0.0088]],
       device='cuda:0')

Parameter Name: base_model.model.layers.9.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[183],
        [215],
        [237],
        ...,
        [199],
        [214],
        [ 76]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.9.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[150],
        [150],
        [207],
        ...,
        [113],
        [108],
        [238]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.9.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0128,  0.0096,  0.0091,  ...,  0.0123,  0.0123, -0.0033],
        [-0.0112, -0.0020, -0.0065,  ..., -0.0039, -0.0167, -0.0077],
        [ 0.0236,  0.0067, -0.0014,  ...,  0.0134, -0.0103,  0.0057],
        ...,
        [-0.0109, -0.0014,  0.0091,  ..., -0.0196,  0.0130,  0.0018],
        [-0.0106,  0.0045, -0.0145,  ...,  0.0110,  0.0006, -0.0037],
        [-0.0069,  0.0145,  0.0026,  ..., -0.0090,  0.0200, -0.0043]],
       device='cuda:0')

Parameter Name: base_model.model.layers.9.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 6.4482e-03,  3.7293e-03, -6.0058e-03,  ..., -6.5372e-03,
          1.2319e-02,  2.2188e-03],
        [ 3.1937e-03, -9.0392e-03,  1.3836e-02,  ...,  8.7271e-04,
         -7.0800e-03,  6.3078e-03],
        [ 1.2959e-02,  1.6520e-02, -1.7079e-02,  ..., -1.2905e-02,
          2.0536e-02, -6.4084e-03],
        ...,
        [ 4.9853e-03, -5.9925e-03, -2.5558e-05,  ...,  3.4857e-03,
         -3.4706e-04,  6.0866e-03],
        [-1.7601e-02,  3.3662e-03, -5.0245e-03,  ...,  1.8464e-02,
          2.5383e-03, -1.3938e-02],
        [ 3.6691e-03, -5.5217e-04,  1.7477e-03,  ..., -6.7715e-03,
         -8.3105e-03,  3.4416e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.9.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[119],
        [106],
        [101],
        ...,
        [ 81],
        [ 46],
        [119]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.9.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0045, -0.0028,  0.0145,  ..., -0.0141,  0.0093,  0.0020],
        [-0.0107,  0.0033,  0.0071,  ..., -0.0021,  0.0100, -0.0126],
        [-0.0033,  0.0105,  0.0056,  ..., -0.0156,  0.0224, -0.0081],
        ...,
        [-0.0008, -0.0183,  0.0262,  ...,  0.0036,  0.0081, -0.0189],
        [ 0.0150, -0.0074, -0.0163,  ..., -0.0059, -0.0078, -0.0171],
        [ 0.0190,  0.0038, -0.0071,  ...,  0.0041, -0.0197, -0.0164]],
       device='cuda:0')

Parameter Name: base_model.model.layers.9.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0076, -0.0049,  0.0033,  ...,  0.0027,  0.0022, -0.0057],
        [ 0.0027, -0.0064,  0.0054,  ...,  0.0086,  0.0062,  0.0086],
        [-0.0012,  0.0088, -0.0019,  ...,  0.0003, -0.0129, -0.0085],
        ...,
        [ 0.0056, -0.0077, -0.0124,  ..., -0.0039,  0.0009,  0.0034],
        [-0.0031,  0.0006, -0.0150,  ..., -0.0082, -0.0019, -0.0037],
        [ 0.0097, -0.0091, -0.0048,  ...,  0.0151,  0.0024, -0.0036]],
       device='cuda:0')

Parameter Name: base_model.model.layers.9.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[229],
        [230],
        [ 63],
        ...,
        [239],
        [199],
        [246]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.9.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0067,  0.0232, -0.0148,  ..., -0.0202, -0.0019, -0.0061],
        [ 0.0056, -0.0135,  0.0057,  ...,  0.0033, -0.0162,  0.0354],
        [ 0.0018, -0.0104,  0.0144,  ...,  0.0254, -0.0074,  0.0127],
        ...,
        [-0.0039,  0.0104, -0.0193,  ..., -0.0059, -0.0122, -0.0238],
        [ 0.0054, -0.0033, -0.0160,  ...,  0.0276, -0.0213, -0.0063],
        [-0.0066,  0.0170,  0.0039,  ...,  0.0047,  0.0116,  0.0102]],
       device='cuda:0')

Parameter Name: base_model.model.layers.9.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0076, -0.0029,  0.0008,  ...,  0.0123,  0.0019, -0.0003],
        [ 0.0164, -0.0081, -0.0156,  ...,  0.0154,  0.0029, -0.0078],
        [ 0.0072, -0.0130, -0.0075,  ...,  0.0166, -0.0157,  0.0020],
        ...,
        [ 0.0062, -0.0137, -0.0035,  ...,  0.0029,  0.0056,  0.0143],
        [ 0.0095, -0.0075, -0.0060,  ...,  0.0028, -0.0098, -0.0175],
        [ 0.0073, -0.0031, -0.0016,  ...,  0.0237,  0.0066, -0.0003]],
       device='cuda:0')

Parameter Name: base_model.model.layers.9.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[247],
        [113],
        [ 14],
        ...,
        [204],
        [ 76],
        [ 41]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.9.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0044, -0.0194,  0.0103,  ...,  0.0035, -0.0017,  0.0153],
        [-0.0060,  0.0136, -0.0249,  ..., -0.0187,  0.0105, -0.0154],
        [-0.0261, -0.0210, -0.0026,  ...,  0.0148, -0.0107,  0.0122],
        ...,
        [ 0.0202, -0.0165, -0.0270,  ..., -0.0157,  0.0026, -0.0031],
        [-0.0131, -0.0011,  0.0207,  ...,  0.0205, -0.0272,  0.0232],
        [-0.0183,  0.0074,  0.0178,  ..., -0.0056, -0.0082,  0.0175]],
       device='cuda:0')

Parameter Name: base_model.model.layers.9.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0186, -0.0050, -0.0023,  ..., -0.0232,  0.0249,  0.0209],
        [ 0.0080, -0.0026, -0.0130,  ..., -0.0017,  0.0101,  0.0070],
        [-0.0187,  0.0191,  0.0019,  ...,  0.0176, -0.0190, -0.0188],
        ...,
        [ 0.0083, -0.0060, -0.0004,  ..., -0.0169,  0.0116,  0.0131],
        [ 0.0007, -0.0160, -0.0037,  ..., -0.0190,  0.0121,  0.0177],
        [-0.0057,  0.0067,  0.0048,  ..., -0.0063,  0.0029, -0.0007]],
       device='cuda:0')

Parameter Name: base_model.model.layers.9.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[226],
        [191],
        [ 41],
        ...,
        [126],
        [114],
        [ 68]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.9.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 0.0072,  0.0394,  0.0185,  ...,  0.0055, -0.0035,  0.0169],
        [ 0.0025, -0.0191, -0.0317,  ..., -0.0083,  0.0188, -0.0062],
        [ 0.0093,  0.0358,  0.0183,  ...,  0.0201, -0.0246, -0.0061],
        ...,
        [ 0.0047,  0.0071,  0.0156,  ...,  0.0010, -0.0139, -0.0079],
        [ 0.0048, -0.0233, -0.0190,  ..., -0.0007, -0.0146, -0.0257],
        [-0.0127,  0.0273,  0.0110,  ...,  0.0066,  0.0128,  0.0210]],
       device='cuda:0')

Parameter Name: base_model.model.layers.9.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0100, -0.0058,  0.0126,  ...,  0.0171, -0.0121,  0.0066],
        [-0.0215,  0.0087, -0.0090,  ..., -0.0032,  0.0068, -0.0042],
        [ 0.0027, -0.0042,  0.0058,  ..., -0.0054, -0.0077,  0.0069],
        ...,
        [ 0.0123,  0.0042,  0.0036,  ..., -0.0100, -0.0080,  0.0088],
        [ 0.0068, -0.0043,  0.0105,  ...,  0.0025, -0.0005, -0.0008],
        [-0.0148,  0.0002, -0.0040,  ...,  0.0054,  0.0090, -0.0203]],
       device='cuda:0')

Parameter Name: base_model.model.layers.9.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.3516, 0.3594, 0.3223,  ..., 0.3496, 0.3457, 0.3398], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.9.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.2422, 0.2305, 0.2217,  ..., 0.2373, 0.2363, 0.2324], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.10.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[150],
        [153],
        [ 38],
        ...,
        [ 94],
        [126],
        [223]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.10.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0147, -0.0161, -0.0062,  ...,  0.0063,  0.0151, -0.0099],
        [ 0.0080, -0.0051,  0.0060,  ..., -0.0185, -0.0153,  0.0226],
        [-0.0192, -0.0082,  0.0003,  ...,  0.0100, -0.0198, -0.0353],
        ...,
        [-0.0030, -0.0033,  0.0104,  ..., -0.0031, -0.0024,  0.0006],
        [-0.0298,  0.0119, -0.0027,  ...,  0.0110,  0.0002,  0.0247],
        [ 0.0100, -0.0094,  0.0014,  ...,  0.0057, -0.0004,  0.0079]],
       device='cuda:0')

Parameter Name: base_model.model.layers.10.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0049, -0.0014,  0.0053,  ..., -0.0009, -0.0160,  0.0031],
        [-0.0099,  0.0011, -0.0009,  ...,  0.0116, -0.0055, -0.0115],
        [-0.0044, -0.0080, -0.0008,  ..., -0.0018,  0.0154, -0.0048],
        ...,
        [-0.0027,  0.0076, -0.0007,  ...,  0.0010,  0.0282, -0.0039],
        [-0.0022, -0.0149, -0.0033,  ..., -0.0067, -0.0145,  0.0105],
        [-0.0018, -0.0052, -0.0037,  ..., -0.0104,  0.0080,  0.0079]],
       device='cuda:0')

Parameter Name: base_model.model.layers.10.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[180],
        [247],
        [151],
        ...,
        [175],
        [215],
        [ 46]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.10.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[161],
        [228],
        [ 81],
        ...,
        [198],
        [ 78],
        [194]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.10.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0032,  0.0079, -0.0080,  ...,  0.0242, -0.0008, -0.0077],
        [ 0.0046,  0.0191, -0.0049,  ...,  0.0263, -0.0154,  0.0187],
        [ 0.0167,  0.0196, -0.0158,  ...,  0.0121, -0.0004, -0.0030],
        ...,
        [-0.0260, -0.0381, -0.0138,  ..., -0.0197,  0.0032, -0.0051],
        [ 0.0136,  0.0016, -0.0028,  ...,  0.0081,  0.0275, -0.0161],
        [ 0.0209, -0.0010,  0.0102,  ...,  0.0176,  0.0127,  0.0011]],
       device='cuda:0')

Parameter Name: base_model.model.layers.10.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-6.5182e-03, -4.9838e-03, -7.9641e-03,  ...,  4.2622e-03,
         -1.0968e-04, -2.0566e-03],
        [-8.6515e-03,  1.0160e-03, -1.2926e-02,  ...,  8.1239e-03,
         -1.2343e-02, -2.5401e-03],
        [-2.5946e-03,  5.8172e-03, -9.0313e-03,  ..., -6.1694e-03,
         -1.5715e-03,  4.7331e-03],
        ...,
        [ 5.5721e-04, -4.8360e-05,  1.1271e-02,  ..., -2.7782e-03,
          1.1431e-02, -8.1947e-06],
        [ 3.7951e-03,  5.1752e-03, -5.4918e-03,  ..., -4.4931e-03,
         -5.3561e-03,  5.2897e-03],
        [-1.0385e-03, -5.0802e-03, -8.6380e-04,  ...,  8.6836e-03,
         -1.0187e-02, -7.8210e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.10.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[145],
        [162],
        [193],
        ...,
        [ 75],
        [103],
        [145]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.10.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 2.3294e-02, -9.3152e-03,  1.4080e-02,  ...,  1.2762e-02,
          1.3729e-02,  7.6497e-03],
        [ 3.8462e-03, -1.7387e-02, -7.5409e-03,  ...,  3.9579e-03,
          7.4196e-03, -1.1936e-02],
        [ 1.6657e-02, -8.8079e-03, -7.8406e-03,  ..., -1.2494e-02,
         -1.2620e-02, -2.8429e-03],
        ...,
        [ 3.1418e-03, -5.5745e-03, -4.5233e-03,  ...,  1.3636e-02,
          3.2196e-02, -1.1811e-02],
        [ 2.6065e-03, -1.6078e-02, -6.4709e-05,  ...,  1.9413e-02,
          1.7907e-02,  2.6041e-03],
        [-3.1364e-02, -2.1568e-02,  4.1812e-03,  ..., -3.6555e-03,
          1.1693e-02,  1.2108e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.10.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-1.3745e-02, -5.6141e-03,  4.8217e-04,  ..., -2.3772e-03,
         -8.5020e-03,  5.7513e-03],
        [-6.4954e-04, -1.3341e-04, -3.4530e-03,  ...,  5.8153e-03,
         -4.9107e-03,  1.2338e-02],
        [-2.3028e-03,  5.3954e-05,  7.2091e-03,  ..., -6.6791e-03,
         -3.5377e-03, -8.2636e-03],
        ...,
        [ 7.4898e-03,  2.7439e-03,  6.1950e-03,  ...,  3.7422e-03,
         -2.0820e-04,  6.2205e-03],
        [-8.8024e-03,  1.0935e-02, -5.8211e-03,  ...,  5.8327e-03,
          5.2494e-03,  9.8419e-03],
        [-9.3841e-03,  1.7632e-03,  1.4886e-02,  ..., -9.9248e-03,
         -7.1042e-03,  3.6268e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.10.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[171],
        [166],
        [229],
        ...,
        [109],
        [ 79],
        [ 31]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.10.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 2.0527e-02, -7.9777e-03, -8.3964e-03,  ...,  8.6060e-03,
         -4.7710e-03, -1.7288e-05],
        [ 8.9967e-03, -3.7231e-03, -1.1778e-02,  ...,  1.0022e-02,
          9.2791e-03, -6.4138e-03],
        [-4.4626e-03, -1.4627e-03,  9.5530e-03,  ...,  5.1841e-03,
          1.2273e-02,  6.9356e-03],
        ...,
        [ 4.3734e-03, -1.5883e-02,  4.7637e-03,  ..., -1.0145e-02,
          1.9076e-03,  1.3473e-02],
        [-6.0043e-04, -1.1924e-02, -5.9111e-03,  ...,  2.6611e-02,
         -2.0976e-02, -1.5498e-02],
        [-5.9742e-03,  1.3056e-02, -1.8516e-02,  ...,  2.8677e-02,
         -7.3732e-03, -1.4953e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.10.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0082,  0.0107, -0.0123,  ..., -0.0123,  0.0124,  0.0164],
        [ 0.0038,  0.0066, -0.0087,  ...,  0.0001,  0.0034,  0.0029],
        [-0.0038,  0.0148, -0.0049,  ..., -0.0073,  0.0090,  0.0077],
        ...,
        [ 0.0096,  0.0008, -0.0037,  ...,  0.0019, -0.0026, -0.0002],
        [ 0.0078,  0.0110, -0.0057,  ..., -0.0027,  0.0031,  0.0035],
        [ 0.0032, -0.0036,  0.0081,  ...,  0.0044, -0.0090, -0.0038]],
       device='cuda:0')

Parameter Name: base_model.model.layers.10.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[169],
        [175],
        [233],
        ...,
        [188],
        [ 33],
        [100]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.10.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0104, -0.0048,  0.0022,  ...,  0.0360, -0.0002, -0.0259],
        [ 0.0085, -0.0020,  0.0012,  ...,  0.0210, -0.0013, -0.0165],
        [-0.0027, -0.0184,  0.0009,  ..., -0.0355, -0.0084,  0.0004],
        ...,
        [ 0.0175,  0.0183, -0.0090,  ...,  0.0034,  0.0165, -0.0287],
        [ 0.0002, -0.0186,  0.0296,  ..., -0.0100, -0.0153,  0.0038],
        [ 0.0175,  0.0146, -0.0100,  ...,  0.0133,  0.0035,  0.0165]],
       device='cuda:0')

Parameter Name: base_model.model.layers.10.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0104, -0.0002, -0.0123,  ..., -0.0051,  0.0018,  0.0089],
        [-0.0016,  0.0038,  0.0056,  ..., -0.0003,  0.0204, -0.0058],
        [ 0.0131,  0.0186,  0.0048,  ...,  0.0152,  0.0106,  0.0072],
        ...,
        [-0.0004,  0.0053, -0.0016,  ...,  0.0116,  0.0130, -0.0006],
        [-0.0074, -0.0077,  0.0054,  ...,  0.0028,  0.0110, -0.0009],
        [-0.0028,  0.0007,  0.0037,  ..., -0.0004,  0.0046, -0.0054]],
       device='cuda:0')

Parameter Name: base_model.model.layers.10.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[237],
        [146],
        [110],
        ...,
        [196],
        [ 76],
        [246]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.10.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 1.4627e-02,  2.2578e-02,  2.9117e-03,  ...,  1.5711e-02,
         -7.4050e-03,  2.5039e-03],
        [-5.9272e-03,  3.4302e-03,  2.0534e-02,  ..., -6.3842e-03,
         -9.0845e-03,  8.7471e-04],
        [-9.5405e-03, -1.6147e-02, -9.7512e-03,  ..., -9.7672e-04,
          4.1252e-03,  9.9605e-03],
        ...,
        [ 9.5378e-04,  1.0705e-02,  1.9655e-02,  ...,  4.4874e-05,
         -3.4580e-03,  5.2151e-03],
        [-7.0629e-03, -2.4611e-02, -1.4721e-02,  ...,  6.6826e-04,
         -1.4626e-02,  4.9722e-03],
        [ 1.1703e-02,  2.3945e-02,  2.5102e-02,  ..., -1.9323e-03,
         -2.5901e-03, -1.4698e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.10.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0012, -0.0046, -0.0042,  ..., -0.0031, -0.0065,  0.0112],
        [ 0.0067,  0.0061, -0.0023,  ..., -0.0039, -0.0106,  0.0095],
        [ 0.0004, -0.0052, -0.0012,  ...,  0.0012, -0.0042,  0.0003],
        ...,
        [ 0.0110,  0.0166, -0.0136,  ...,  0.0115, -0.0192,  0.0101],
        [ 0.0023,  0.0047,  0.0094,  ...,  0.0110,  0.0073, -0.0039],
        [-0.0030, -0.0157,  0.0133,  ..., -0.0167,  0.0113, -0.0040]],
       device='cuda:0')

Parameter Name: base_model.model.layers.10.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.3633, 0.3594, 0.3203,  ..., 0.3398, 0.3477, 0.3359], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.10.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.2461, 0.2324, 0.2236,  ..., 0.2402, 0.2373, 0.2373], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.11.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 85],
        [253],
        [221],
        ...,
        [101],
        [ 63],
        [ 34]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.11.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0058,  0.0157, -0.0417,  ..., -0.0189,  0.0116,  0.0014],
        [-0.0399, -0.0206,  0.0077,  ..., -0.0046, -0.0087, -0.0189],
        [ 0.0308,  0.0111, -0.0228,  ...,  0.0259, -0.0005, -0.0228],
        ...,
        [ 0.0258,  0.0204, -0.0338,  ...,  0.0050,  0.0041, -0.0288],
        [ 0.0174,  0.0011, -0.0187,  ...,  0.0129,  0.0153, -0.0183],
        [ 0.0292, -0.0079,  0.0087,  ...,  0.0386, -0.0179, -0.0196]],
       device='cuda:0')

Parameter Name: base_model.model.layers.11.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0024, -0.0024,  0.0108,  ...,  0.0015,  0.0170,  0.0105],
        [-0.0131,  0.0082,  0.0111,  ...,  0.0046,  0.0058, -0.0038],
        [-0.0199, -0.0042, -0.0024,  ...,  0.0017, -0.0016, -0.0128],
        ...,
        [-0.0121,  0.0012, -0.0191,  ..., -0.0161, -0.0220, -0.0150],
        [ 0.0023, -0.0135,  0.0092,  ...,  0.0053,  0.0096, -0.0092],
        [ 0.0028,  0.0208, -0.0166,  ..., -0.0207, -0.0271, -0.0121]],
       device='cuda:0')

Parameter Name: base_model.model.layers.11.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[100],
        [159],
        [100],
        ...,
        [ 68],
        [105],
        [ 52]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.11.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 97],
        [239],
        [110],
        ...,
        [233],
        [107],
        [236]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.11.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-4.6269e-03,  9.0139e-04, -5.8500e-03,  ..., -2.9790e-03,
          2.7374e-03, -4.8178e-03],
        [-1.5910e-02, -1.2340e-03,  5.5386e-05,  ...,  1.8654e-03,
          1.7705e-02, -2.5358e-03],
        [-9.6974e-03, -9.1290e-03,  2.3380e-02,  ...,  1.4055e-02,
          8.5325e-03,  4.4867e-03],
        ...,
        [ 7.8022e-03,  4.3372e-03, -1.5344e-02,  ..., -1.9277e-02,
         -1.7719e-02, -1.0248e-02],
        [-9.7539e-03,  7.0980e-03, -5.4627e-03,  ...,  1.5515e-02,
          5.3397e-03,  1.9173e-02],
        [-1.6969e-02,  3.6782e-03,  9.4541e-03,  ...,  1.4639e-02,
          6.7872e-03,  3.5097e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.11.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0171,  0.0069,  0.0019,  ..., -0.0158,  0.0203,  0.0051],
        [ 0.0213,  0.0098,  0.0093,  ..., -0.0120,  0.0160,  0.0100],
        [ 0.0062,  0.0138,  0.0176,  ..., -0.0124,  0.0097,  0.0159],
        ...,
        [ 0.0019,  0.0032, -0.0022,  ..., -0.0052,  0.0061,  0.0108],
        [-0.0069,  0.0002, -0.0039,  ...,  0.0034, -0.0005, -0.0027],
        [-0.0149, -0.0116, -0.0153,  ...,  0.0087, -0.0149, -0.0123]],
       device='cuda:0')

Parameter Name: base_model.model.layers.11.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[169],
        [123],
        [187],
        ...,
        [ 90],
        [254],
        [ 28]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.11.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0192, -0.0010, -0.0054,  ...,  0.0115, -0.0040, -0.0023],
        [ 0.0053,  0.0094, -0.0310,  ..., -0.0154, -0.0199,  0.0060],
        [ 0.0007, -0.0047, -0.0153,  ...,  0.0101, -0.0018,  0.0019],
        ...,
        [ 0.0087,  0.0036,  0.0153,  ...,  0.0098,  0.0096, -0.0150],
        [ 0.0074,  0.0076,  0.0140,  ..., -0.0132,  0.0019, -0.0081],
        [-0.0128,  0.0122, -0.0123,  ...,  0.0037, -0.0139,  0.0139]],
       device='cuda:0')

Parameter Name: base_model.model.layers.11.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0120,  0.0105, -0.0001,  ..., -0.0009,  0.0050, -0.0015],
        [ 0.0015,  0.0137,  0.0096,  ...,  0.0002, -0.0013, -0.0195],
        [-0.0110, -0.0087,  0.0026,  ...,  0.0175,  0.0192, -0.0055],
        ...,
        [ 0.0023,  0.0090, -0.0029,  ...,  0.0001,  0.0024,  0.0055],
        [-0.0053, -0.0066,  0.0032,  ...,  0.0080,  0.0017, -0.0081],
        [-0.0053,  0.0137, -0.0005,  ..., -0.0021, -0.0091,  0.0169]],
       device='cuda:0')

Parameter Name: base_model.model.layers.11.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[190],
        [ 24],
        [118],
        ...,
        [246],
        [101],
        [156]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.11.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0195, -0.0140, -0.0040,  ..., -0.0176, -0.0161, -0.0351],
        [-0.0050, -0.0087,  0.0050,  ..., -0.0029,  0.0035,  0.0097],
        [-0.0088, -0.0026, -0.0148,  ...,  0.0056, -0.0100, -0.0324],
        ...,
        [-0.0001,  0.0181,  0.0170,  ...,  0.0086, -0.0121,  0.0103],
        [ 0.0088, -0.0039, -0.0043,  ..., -0.0184, -0.0041, -0.0258],
        [ 0.0181, -0.0241,  0.0024,  ...,  0.0084, -0.0056, -0.0043]],
       device='cuda:0')

Parameter Name: base_model.model.layers.11.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-8.1797e-03,  7.2558e-03, -6.6269e-03,  ...,  8.5944e-03,
         -8.0395e-03,  1.0650e-02],
        [ 4.8837e-03, -7.3102e-03,  4.3262e-03,  ..., -8.6138e-03,
          8.2627e-03, -5.8979e-03],
        [ 1.3320e-02, -3.0795e-03,  7.3552e-03,  ..., -1.3635e-02,
          7.8024e-03, -1.5657e-05],
        ...,
        [-1.3764e-02,  8.0757e-03, -1.1054e-02,  ...,  1.1494e-02,
         -9.5183e-03,  5.1758e-03],
        [-1.1699e-02,  2.7506e-02, -2.5356e-02,  ...,  8.2115e-03,
         -1.9656e-02,  2.7910e-02],
        [-6.9016e-03,  5.0221e-03, -6.4665e-04,  ..., -4.1692e-04,
         -1.2991e-02,  7.8550e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.11.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[233],
        [213],
        [214],
        ...,
        [ 68],
        [204],
        [ 98]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.11.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 1.4349e-02, -1.2442e-02,  1.6792e-02,  ..., -2.2215e-02,
         -2.2228e-02, -1.9593e-04],
        [-7.3934e-04, -2.3465e-02, -1.8394e-02,  ...,  3.3150e-02,
          1.4965e-02, -2.8392e-03],
        [ 9.7171e-03, -8.8166e-03,  1.4655e-02,  ..., -1.1105e-02,
          6.4680e-03,  2.4234e-03],
        ...,
        [ 2.2377e-02, -1.7887e-02,  6.7663e-03,  ..., -5.9012e-03,
         -1.7248e-02,  6.4594e-03],
        [ 6.8952e-03, -9.4161e-03,  3.1370e-03,  ...,  1.0463e-02,
         -3.9242e-03,  4.0835e-04],
        [ 3.4565e-03,  7.2573e-03,  2.7800e-02,  ...,  6.5725e-05,
         -7.5688e-03,  1.5502e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.11.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0042, -0.0022, -0.0038,  ...,  0.0049,  0.0023, -0.0053],
        [ 0.0129,  0.0013, -0.0106,  ...,  0.0100, -0.0058,  0.0050],
        [ 0.0005,  0.0064, -0.0098,  ...,  0.0027,  0.0009, -0.0054],
        ...,
        [-0.0043,  0.0008,  0.0088,  ..., -0.0058,  0.0081, -0.0038],
        [ 0.0194, -0.0250,  0.0153,  ...,  0.0173, -0.0188,  0.0258],
        [ 0.0010, -0.0007, -0.0024,  ...,  0.0047, -0.0065,  0.0116]],
       device='cuda:0')

Parameter Name: base_model.model.layers.11.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[211],
        [ 65],
        [126],
        ...,
        [ 78],
        [177],
        [243]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.11.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 2.2624e-03,  1.5261e-03,  2.1754e-02,  ...,  3.9150e-02,
          5.3568e-03,  1.2667e-02],
        [ 3.7508e-03,  7.8189e-03, -1.5338e-02,  ..., -2.9458e-02,
         -5.5838e-03, -2.2451e-03],
        [-1.5381e-02, -7.8759e-03,  1.0355e-02,  ...,  1.5445e-02,
          1.4220e-02,  1.0929e-02],
        ...,
        [-9.9240e-03, -1.5820e-02, -8.2609e-05,  ...,  2.6916e-02,
          8.2494e-03,  1.2376e-02],
        [-4.0755e-03, -4.1829e-03,  5.0825e-03,  ..., -4.4621e-03,
          7.1989e-03,  7.3897e-03],
        [ 1.2841e-02,  5.1970e-03, -2.7646e-03,  ..., -8.7235e-03,
         -6.2584e-03, -1.1266e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.11.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0076,  0.0081, -0.0023,  ...,  0.0053,  0.0029, -0.0037],
        [-0.0186,  0.0131, -0.0056,  ..., -0.0064,  0.0002,  0.0092],
        [ 0.0061, -0.0030,  0.0062,  ...,  0.0065,  0.0049, -0.0059],
        ...,
        [-0.0044,  0.0080, -0.0048,  ..., -0.0052, -0.0040,  0.0065],
        [ 0.0011,  0.0066, -0.0015,  ...,  0.0006,  0.0036, -0.0053],
        [-0.0076,  0.0131, -0.0162,  ..., -0.0074,  0.0177,  0.0181]],
       device='cuda:0')

Parameter Name: base_model.model.layers.11.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.3945, 0.3926, 0.3594,  ..., 0.3828, 0.3770, 0.3672], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.11.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.2539, 0.2363, 0.2334,  ..., 0.2500, 0.2490, 0.2451], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.12.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[234],
        [ 70],
        [ 92],
        ...,
        [111],
        [156],
        [ 69]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.12.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-4.7167e-03, -4.5979e-03, -4.2598e-03,  ..., -1.2979e-02,
         -1.4373e-02, -2.2583e-04],
        [-3.9369e-03,  4.0060e-03,  1.5847e-03,  ..., -1.7398e-03,
          1.1972e-02,  5.6358e-03],
        [ 8.4546e-03, -4.8665e-03,  1.5883e-02,  ..., -5.8243e-03,
          5.8452e-03,  1.6134e-02],
        ...,
        [ 2.7467e-02,  5.4793e-03, -2.7327e-03,  ...,  5.5596e-03,
         -1.3748e-02,  9.4710e-03],
        [-2.8639e-02,  5.2589e-03, -1.0391e-02,  ...,  7.3451e-03,
          1.1106e-02, -2.1484e-03],
        [ 7.6946e-05, -9.3728e-03,  7.3629e-03,  ..., -3.5967e-03,
          8.4754e-03,  1.0397e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.12.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 4.6600e-03,  5.6027e-03,  3.4973e-05,  ..., -1.4337e-02,
          6.8696e-03, -4.9570e-04],
        [ 2.0199e-03,  3.1962e-04,  3.5997e-03,  ...,  6.9188e-04,
         -8.4013e-04,  1.1562e-03],
        [ 1.0672e-03, -9.2228e-03,  2.0464e-03,  ...,  1.0323e-02,
          1.6511e-04, -2.4454e-03],
        ...,
        [-5.9383e-03, -9.3669e-03,  9.2177e-03,  ...,  3.8714e-03,
          4.2958e-03,  4.5119e-03],
        [ 2.6845e-03, -9.0425e-03,  9.4973e-03,  ...,  1.9282e-03,
         -2.5289e-04, -6.1180e-03],
        [ 3.9333e-03, -5.0619e-03, -5.0481e-03,  ...,  4.7923e-03,
          1.2021e-03,  9.5812e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.12.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 78],
        [153],
        [251],
        ...,
        [118],
        [150],
        [173]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.12.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[102],
        [102],
        [158],
        ...,
        [ 87],
        [245],
        [108]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.12.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0060, -0.0036,  0.0050,  ...,  0.0146,  0.0199,  0.0207],
        [-0.0208, -0.0239, -0.0100,  ...,  0.0131,  0.0063,  0.0119],
        [ 0.0195, -0.0012, -0.0023,  ..., -0.0123, -0.0109, -0.0329],
        ...,
        [ 0.0122,  0.0053, -0.0053,  ..., -0.0043, -0.0078, -0.0237],
        [-0.0046, -0.0021, -0.0078,  ..., -0.0106,  0.0195,  0.0218],
        [ 0.0007,  0.0134,  0.0235,  ...,  0.0017, -0.0028, -0.0112]],
       device='cuda:0')

Parameter Name: base_model.model.layers.12.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0077, -0.0009,  0.0131,  ...,  0.0021,  0.0058,  0.0019],
        [-0.0077, -0.0049, -0.0107,  ...,  0.0075, -0.0059, -0.0016],
        [-0.0062, -0.0004,  0.0053,  ..., -0.0057,  0.0029,  0.0048],
        ...,
        [ 0.0046,  0.0074, -0.0179,  ..., -0.0074,  0.0065,  0.0107],
        [-0.0092, -0.0046,  0.0233,  ...,  0.0065,  0.0041, -0.0106],
        [-0.0028, -0.0047,  0.0113,  ...,  0.0051, -0.0071,  0.0003]],
       device='cuda:0')

Parameter Name: base_model.model.layers.12.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 38],
        [159],
        [ 39],
        ...,
        [ 79],
        [ 34],
        [205]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.12.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 3.8958e-04,  2.8653e-02,  1.0322e-02,  ..., -1.3716e-02,
         -1.7581e-03, -3.1456e-02],
        [ 1.1457e-02,  1.2015e-02,  7.1732e-03,  ..., -1.2771e-02,
         -1.3957e-02, -8.1685e-05],
        [ 1.6994e-02,  1.6003e-02, -9.5020e-03,  ..., -8.7520e-03,
          1.4923e-02, -1.0445e-02],
        ...,
        [ 2.2139e-02, -3.7516e-03,  2.8730e-03,  ...,  1.7562e-02,
         -1.1659e-02, -2.3365e-02],
        [-2.2523e-03, -3.7675e-03, -1.3025e-02,  ...,  7.6518e-03,
         -9.8760e-04,  3.2615e-03],
        [-5.2946e-03,  9.7583e-04,  6.7322e-03,  ...,  1.0311e-02,
          2.7785e-02, -2.2906e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.12.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0075, -0.0021,  0.0036,  ...,  0.0014, -0.0031, -0.0020],
        [-0.0031, -0.0040, -0.0015,  ...,  0.0042,  0.0072, -0.0047],
        [-0.0042,  0.0043, -0.0085,  ..., -0.0023,  0.0036, -0.0065],
        ...,
        [-0.0065, -0.0143,  0.0112,  ...,  0.0059,  0.0056, -0.0144],
        [-0.0064, -0.0107,  0.0058,  ..., -0.0028,  0.0069,  0.0019],
        [ 0.0172,  0.0021, -0.0007,  ..., -0.0066, -0.0190,  0.0023]],
       device='cuda:0')

Parameter Name: base_model.model.layers.12.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[109],
        [108],
        [ 77],
        ...,
        [239],
        [ 89],
        [236]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.12.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0079, -0.0047, -0.0125,  ..., -0.0104,  0.0229,  0.0233],
        [-0.0323, -0.0003,  0.0157,  ...,  0.0202,  0.0054, -0.0042],
        [ 0.0011, -0.0226, -0.0118,  ...,  0.0191, -0.0242,  0.0248],
        ...,
        [-0.0040, -0.0099,  0.0038,  ..., -0.0047,  0.0100, -0.0177],
        [ 0.0130,  0.0008, -0.0105,  ...,  0.0139, -0.0117, -0.0021],
        [ 0.0006,  0.0200,  0.0081,  ...,  0.0038,  0.0187, -0.0064]],
       device='cuda:0')

Parameter Name: base_model.model.layers.12.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-1.5453e-03, -8.0858e-03, -4.1265e-03,  ..., -3.1589e-02,
          1.7414e-02, -1.1885e-02],
        [-4.0563e-03, -1.7348e-02,  7.6526e-04,  ...,  1.2514e-02,
         -4.4593e-03,  2.7615e-04],
        [-1.1984e-03,  6.0812e-03,  6.2172e-03,  ...,  5.3737e-03,
         -1.7369e-03,  3.0726e-03],
        ...,
        [-4.7388e-03,  1.0812e-04, -1.4493e-02,  ...,  1.8220e-04,
         -3.4072e-03,  1.0245e-02],
        [-7.2950e-03,  9.2250e-03,  1.7058e-03,  ...,  1.3563e-02,
         -6.5562e-03, -2.3342e-03],
        [-2.5209e-02, -4.7746e-05, -2.6759e-02,  ...,  1.5185e-02,
         -1.8184e-02, -6.1657e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.12.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 20],
        [103],
        [102],
        ...,
        [228],
        [242],
        [234]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.12.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0127, -0.0283,  0.0222,  ...,  0.0193, -0.0165, -0.0246],
        [-0.0083,  0.0094,  0.0063,  ...,  0.0048, -0.0112, -0.0030],
        [-0.0173, -0.0136,  0.0113,  ...,  0.0153, -0.0207, -0.0038],
        ...,
        [ 0.0074, -0.0131, -0.0057,  ...,  0.0225, -0.0091, -0.0139],
        [-0.0092,  0.0063, -0.0006,  ...,  0.0153,  0.0068, -0.0165],
        [ 0.0065,  0.0003, -0.0050,  ...,  0.0059,  0.0031,  0.0014]],
       device='cuda:0')

Parameter Name: base_model.model.layers.12.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-7.8796e-04, -2.3478e-03,  2.1186e-02,  ..., -1.2289e-02,
         -1.2228e-02, -3.8457e-03],
        [ 2.0309e-03, -1.4495e-02,  2.1035e-02,  ..., -4.4711e-03,
         -4.6099e-03,  6.3235e-04],
        [-9.8602e-03, -1.1193e-02, -1.6660e-02,  ..., -1.6357e-02,
         -3.2868e-03,  6.6029e-03],
        ...,
        [ 3.8553e-03,  7.7942e-03, -5.6277e-03,  ...,  4.0177e-03,
          6.7530e-03, -8.4180e-05],
        [-1.6785e-02,  3.6200e-04,  4.6006e-03,  ..., -5.3623e-03,
         -7.7764e-03, -1.4785e-02],
        [-1.4714e-02, -9.4059e-03,  1.3932e-03,  ..., -8.8276e-03,
         -1.1901e-02, -2.3954e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.12.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[110],
        [167],
        [ 20],
        ...,
        [ 87],
        [251],
        [ 89]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.12.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 5.6761e-03, -9.9088e-03,  2.0000e-02,  ...,  4.0488e-03,
         -3.2749e-03, -1.2795e-02],
        [-1.5919e-03,  9.2184e-03, -9.0300e-03,  ..., -8.7265e-03,
          1.1514e-02,  1.1094e-02],
        [-5.7258e-03, -1.5592e-02,  9.6508e-03,  ..., -6.3884e-06,
          1.5153e-02,  2.4967e-02],
        ...,
        [ 3.4492e-03,  2.2858e-03,  1.3037e-02,  ...,  1.0578e-02,
          2.2029e-02, -6.6621e-03],
        [ 1.8372e-02, -1.7371e-03, -7.2149e-03,  ...,  4.6095e-03,
         -3.0177e-02,  1.6124e-03],
        [-1.5938e-02, -2.7266e-02,  1.5650e-02,  ...,  6.5660e-03,
         -9.2026e-03, -1.6400e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.12.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0024, -0.0099, -0.0058,  ...,  0.0008, -0.0002,  0.0086],
        [-0.0090,  0.0088, -0.0092,  ...,  0.0061, -0.0065, -0.0125],
        [-0.0088,  0.0047,  0.0010,  ..., -0.0046,  0.0002,  0.0007],
        ...,
        [ 0.0027, -0.0060, -0.0097,  ...,  0.0056, -0.0063,  0.0018],
        [-0.0167,  0.0009, -0.0025,  ...,  0.0048, -0.0047, -0.0015],
        [-0.0153,  0.0018,  0.0073,  ...,  0.0141, -0.0156, -0.0117]],
       device='cuda:0')

Parameter Name: base_model.model.layers.12.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4023, 0.3984, 0.3652,  ..., 0.3789, 0.3828, 0.3848], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.12.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.2578, 0.2441, 0.2373,  ..., 0.2559, 0.2539, 0.2539], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.13.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[158],
        [195],
        [ 75],
        ...,
        [126],
        [ 30],
        [ 78]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.13.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 9.6029e-03,  5.7893e-03,  2.1708e-03,  ...,  6.2967e-03,
         -1.0071e-02, -1.3593e-02],
        [-2.8293e-03,  1.3795e-02, -5.8224e-05,  ...,  1.0940e-04,
          2.2975e-03,  1.3569e-02],
        [ 1.3782e-02,  3.1591e-03, -1.6049e-02,  ...,  1.5821e-02,
         -2.0524e-03,  1.5650e-02],
        ...,
        [-1.1802e-02,  2.9332e-03,  9.2115e-03,  ...,  1.3987e-02,
         -1.4310e-02, -1.7399e-03],
        [ 5.6795e-03,  5.1353e-03, -1.0462e-02,  ...,  5.7982e-03,
          2.2549e-05, -9.7239e-03],
        [ 1.1252e-02,  1.0203e-02,  2.5992e-03,  ..., -1.4438e-03,
          4.0158e-03, -8.3789e-04]], device='cuda:0')

Parameter Name: base_model.model.layers.13.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-6.3437e-04,  5.9221e-03, -1.8698e-03,  ..., -1.7307e-03,
         -5.8516e-03,  6.0003e-03],
        [-1.8848e-02, -1.9185e-02, -1.7796e-02,  ..., -1.5206e-02,
         -1.9185e-02,  1.6612e-02],
        [-1.4803e-02,  9.0710e-03, -1.6981e-03,  ..., -3.9714e-04,
         -6.1951e-03, -6.9499e-05],
        ...,
        [ 1.1686e-02, -1.0408e-02,  1.2603e-02,  ...,  1.2513e-02,
          1.4750e-02, -1.4670e-02],
        [-2.0968e-03,  5.7838e-03,  5.1631e-03,  ...,  1.9340e-03,
          1.3697e-03, -4.0109e-04],
        [-6.8695e-03,  1.6712e-03, -8.9493e-03,  ..., -5.7783e-03,
         -6.7067e-03,  7.2804e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.13.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 70],
        [228],
        [231],
        ...,
        [ 97],
        [239],
        [241]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.13.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 81],
        [197],
        [238],
        ...,
        [169],
        [244],
        [146]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.13.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0055,  0.0051,  0.0290,  ..., -0.0083,  0.0082, -0.0070],
        [ 0.0065,  0.0102, -0.0184,  ..., -0.0216, -0.0009, -0.0050],
        [-0.0251, -0.0008,  0.0282,  ..., -0.0061,  0.0135, -0.0006],
        ...,
        [ 0.0096,  0.0159,  0.0007,  ..., -0.0099,  0.0026,  0.0004],
        [ 0.0288, -0.0038, -0.0231,  ..., -0.0095, -0.0044,  0.0033],
        [-0.0320, -0.0221,  0.0417,  ...,  0.0066, -0.0051,  0.0209]],
       device='cuda:0')

Parameter Name: base_model.model.layers.13.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-1.8755e-02,  4.5687e-03, -1.3671e-02,  ...,  2.8217e-05,
          1.0986e-02, -1.4759e-02],
        [-7.7646e-03,  9.1977e-03, -5.9897e-05,  ...,  2.5393e-03,
          8.2228e-03, -5.3833e-03],
        [-9.7368e-03,  2.1275e-02, -2.5111e-03,  ...,  1.6916e-02,
          1.2841e-02, -1.3877e-02],
        ...,
        [-8.1316e-03,  4.4526e-03, -3.8871e-03,  ...,  4.3617e-03,
          5.4722e-03, -7.1272e-03],
        [ 7.1370e-04, -4.3013e-03, -2.3171e-04,  ..., -1.4457e-02,
         -3.9022e-03,  1.4348e-03],
        [ 1.4999e-02, -4.0202e-03,  1.6441e-02,  ..., -1.9454e-03,
         -1.7304e-02,  9.7922e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.13.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[225],
        [237],
        [254],
        ...,
        [198],
        [149],
        [202]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.13.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0133, -0.0027, -0.0200,  ...,  0.0034, -0.0127,  0.0117],
        [-0.0050, -0.0087, -0.0051,  ..., -0.0226,  0.0133, -0.0146],
        [ 0.0221, -0.0046, -0.0227,  ...,  0.0057,  0.0018, -0.0041],
        ...,
        [ 0.0200, -0.0104,  0.0156,  ...,  0.0130,  0.0120, -0.0102],
        [ 0.0113, -0.0076,  0.0153,  ..., -0.0085,  0.0201, -0.0009],
        [-0.0055,  0.0132, -0.0016,  ..., -0.0245, -0.0226, -0.0057]],
       device='cuda:0')

Parameter Name: base_model.model.layers.13.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0021,  0.0086, -0.0130,  ..., -0.0111,  0.0045, -0.0140],
        [-0.0016,  0.0095,  0.0039,  ...,  0.0017,  0.0089,  0.0023],
        [ 0.0104, -0.0065,  0.0105,  ..., -0.0035, -0.0082, -0.0100],
        ...,
        [ 0.0089, -0.0053,  0.0105,  ..., -0.0045, -0.0039, -0.0004],
        [-0.0036,  0.0016,  0.0025,  ...,  0.0032,  0.0059,  0.0018],
        [-0.0041,  0.0012,  0.0025,  ..., -0.0163, -0.0093,  0.0090]],
       device='cuda:0')

Parameter Name: base_model.model.layers.13.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 39],
        [239],
        [198],
        ...,
        [ 73],
        [174],
        [ 82]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.13.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-3.1904e-03, -1.4923e-02,  6.2593e-03,  ...,  8.0918e-04,
         -2.5887e-03, -4.3256e-03],
        [-1.6623e-02,  3.0626e-03, -1.4738e-02,  ..., -1.3979e-02,
         -6.5687e-03,  2.0679e-02],
        [-1.2818e-02, -1.9524e-05, -6.6618e-03,  ...,  1.7073e-02,
          2.3595e-04,  1.6386e-02],
        ...,
        [-1.6078e-02,  4.1203e-03, -2.7773e-02,  ...,  1.5155e-02,
         -1.7009e-02,  7.4757e-03],
        [ 1.4832e-03,  6.1931e-04, -1.3784e-03,  ...,  6.2027e-03,
          7.2299e-03, -1.3556e-03],
        [-1.0823e-02, -9.2236e-03, -3.1824e-02,  ...,  1.1486e-02,
         -3.9247e-03, -1.3789e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.13.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-1.3296e-02, -1.7619e-02, -1.6727e-02,  ..., -2.1586e-02,
          9.4980e-03, -1.3295e-02],
        [-8.1192e-03, -1.6479e-02, -2.4095e-02,  ..., -2.3262e-02,
          7.0959e-03, -1.1507e-02],
        [-1.0759e-02, -1.2617e-02,  1.1091e-02,  ...,  6.1840e-03,
         -8.5864e-03,  1.2248e-02],
        ...,
        [-1.0107e-02, -5.3524e-03,  5.7550e-03,  ...,  1.3567e-02,
         -1.3314e-02,  2.8948e-03],
        [-7.3838e-03, -7.0035e-03,  1.2450e-02,  ...,  1.5223e-02,
         -5.6969e-03,  8.6693e-03],
        [ 1.3076e-03,  1.8603e-05,  2.7680e-04,  ..., -2.0150e-03,
          3.0882e-03, -3.6878e-04]], device='cuda:0')

Parameter Name: base_model.model.layers.13.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[181],
        [238],
        [217],
        ...,
        [188],
        [156],
        [148]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.13.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0112,  0.0065, -0.0010,  ..., -0.0236, -0.0198,  0.0013],
        [ 0.0249, -0.0194, -0.0046,  ...,  0.0121, -0.0042, -0.0221],
        [ 0.0015, -0.0111,  0.0043,  ..., -0.0020,  0.0087, -0.0124],
        ...,
        [-0.0040, -0.0116, -0.0004,  ..., -0.0055,  0.0173, -0.0050],
        [ 0.0049, -0.0061,  0.0048,  ...,  0.0212, -0.0032, -0.0198],
        [ 0.0060, -0.0100, -0.0222,  ..., -0.0162, -0.0234, -0.0001]],
       device='cuda:0')

Parameter Name: base_model.model.layers.13.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0119, -0.0206, -0.0129,  ..., -0.0142, -0.0066,  0.0110],
        [-0.0013,  0.0147,  0.0077,  ...,  0.0096,  0.0155, -0.0088],
        [-0.0198,  0.0277,  0.0170,  ...,  0.0212,  0.0229, -0.0260],
        ...,
        [-0.0078,  0.0133,  0.0105,  ...,  0.0099,  0.0016, -0.0038],
        [ 0.0134, -0.0089, -0.0011,  ..., -0.0091, -0.0126,  0.0082],
        [-0.0147,  0.0213,  0.0136,  ...,  0.0171,  0.0158, -0.0103]],
       device='cuda:0')

Parameter Name: base_model.model.layers.13.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[233],
        [230],
        [ 98],
        ...,
        [238],
        [102],
        [ 98]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.13.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 0.0026, -0.0016,  0.0125,  ..., -0.0070,  0.0102,  0.0175],
        [-0.0020,  0.0102,  0.0096,  ...,  0.0124, -0.0005,  0.0114],
        [-0.0212,  0.0147, -0.0110,  ...,  0.0140,  0.0088, -0.0073],
        ...,
        [-0.0148,  0.0162,  0.0046,  ...,  0.0035,  0.0118,  0.0033],
        [-0.0200,  0.0057,  0.0033,  ...,  0.0187,  0.0026,  0.0022],
        [-0.0147,  0.0098, -0.0113,  ...,  0.0198,  0.0064, -0.0021]],
       device='cuda:0')

Parameter Name: base_model.model.layers.13.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 2.1600e-03,  1.1080e-02,  1.1855e-03,  ...,  3.2217e-03,
          7.1901e-05,  3.2812e-03],
        [-8.2589e-03,  7.3004e-04,  1.2491e-02,  ..., -1.8797e-03,
          1.0835e-03,  7.0186e-03],
        [ 4.8529e-03, -1.1505e-04,  7.1313e-03,  ...,  3.8116e-03,
          5.5969e-03,  9.1199e-03],
        ...,
        [ 1.1405e-02,  5.7578e-03, -7.7884e-03,  ..., -1.2849e-02,
         -1.3435e-02, -7.6802e-03],
        [ 1.2040e-03, -9.1114e-03,  1.1156e-03,  ..., -2.0712e-03,
         -5.0999e-03, -4.1624e-03],
        [ 5.4178e-03,  1.7232e-02,  8.4586e-03,  ..., -5.3601e-04,
          1.9264e-03,  7.2688e-04]], device='cuda:0')

Parameter Name: base_model.model.layers.13.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4141, 0.4043, 0.3711,  ..., 0.3867, 0.3809, 0.3906], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.13.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.2637, 0.2520, 0.2451,  ..., 0.2637, 0.2656, 0.2598], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.14.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[225],
        [ 94],
        [234],
        ...,
        [ 21],
        [ 70],
        [106]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.14.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-2.5393e-02, -7.1524e-03, -2.2982e-02,  ...,  3.5481e-02,
          2.2631e-03,  5.3791e-03],
        [-1.2777e-02, -1.0766e-02, -5.7725e-03,  ...,  5.0403e-03,
          1.6655e-02,  4.5112e-03],
        [-2.4654e-02, -1.5408e-02, -1.7626e-02,  ...,  8.9639e-03,
          4.4005e-03,  9.1823e-05],
        ...,
        [ 2.9198e-02,  1.3575e-02,  1.9530e-02,  ..., -9.2580e-03,
          5.4962e-03, -1.6851e-02],
        [-1.7621e-02, -6.3594e-04, -1.1036e-02,  ...,  1.6708e-02,
         -1.4595e-02,  1.1336e-02],
        [ 7.8811e-03, -6.6696e-03,  1.3679e-02,  ..., -2.7902e-02,
          1.5363e-02, -1.4349e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.14.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0003, -0.0038,  0.0257,  ...,  0.0102,  0.0182, -0.0151],
        [ 0.0049,  0.0020,  0.0021,  ..., -0.0002,  0.0025, -0.0051],
        [-0.0080, -0.0061, -0.0050,  ...,  0.0092, -0.0055,  0.0032],
        ...,
        [-0.0046, -0.0028, -0.0050,  ...,  0.0049, -0.0044,  0.0048],
        [-0.0018, -0.0015, -0.0130,  ..., -0.0012, -0.0076,  0.0073],
        [-0.0028, -0.0037, -0.0020,  ...,  0.0020, -0.0030,  0.0034]],
       device='cuda:0')

Parameter Name: base_model.model.layers.14.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[249],
        [ 97],
        [247],
        ...,
        [225],
        [115],
        [109]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.14.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[118],
        [190],
        [225],
        ...,
        [126],
        [158],
        [228]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.14.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-3.7438e-03,  2.1882e-02,  2.4826e-02,  ..., -6.1524e-03,
          7.3461e-04, -8.9882e-03],
        [ 5.5158e-04,  5.5318e-03, -1.2132e-02,  ...,  2.3726e-02,
         -4.1387e-03,  2.2208e-03],
        [ 2.4012e-03,  5.1602e-03, -6.1688e-03,  ...,  2.3552e-02,
          1.8703e-02,  5.5369e-03],
        ...,
        [-1.4288e-02,  1.5968e-03, -6.6274e-04,  ...,  7.4975e-03,
          1.5641e-02,  1.9873e-03],
        [-1.1690e-02,  9.6625e-03,  1.2644e-02,  ..., -1.9753e-02,
         -2.2377e-02, -1.5405e-05],
        [-6.6042e-03,  1.0396e-02, -2.2069e-02,  ..., -1.2127e-02,
         -1.4475e-02,  2.4521e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.14.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0071, -0.0010,  0.0076,  ...,  0.0034,  0.0018, -0.0020],
        [-0.0031,  0.0130, -0.0138,  ...,  0.0124, -0.0027, -0.0005],
        [-0.0001,  0.0013,  0.0056,  ...,  0.0037, -0.0118, -0.0108],
        ...,
        [-0.0126, -0.0040, -0.0095,  ..., -0.0099,  0.0135,  0.0213],
        [-0.0071, -0.0141, -0.0061,  ..., -0.0161,  0.0079,  0.0080],
        [ 0.0113,  0.0073,  0.0199,  ...,  0.0053,  0.0073, -0.0166]],
       device='cuda:0')

Parameter Name: base_model.model.layers.14.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[198],
        [175],
        [100],
        ...,
        [213],
        [ 78],
        [ 97]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.14.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0127,  0.0304,  0.0242,  ..., -0.0035, -0.0075, -0.0071],
        [-0.0064,  0.0186,  0.0037,  ...,  0.0096,  0.0102,  0.0078],
        [-0.0003, -0.0139, -0.0082,  ...,  0.0184, -0.0179,  0.0033],
        ...,
        [-0.0202, -0.0034, -0.0060,  ...,  0.0014, -0.0058, -0.0107],
        [ 0.0112, -0.0035, -0.0285,  ...,  0.0190,  0.0072, -0.0118],
        [ 0.0087,  0.0028, -0.0252,  ...,  0.0076,  0.0046, -0.0125]],
       device='cuda:0')

Parameter Name: base_model.model.layers.14.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0019, -0.0059,  0.0229,  ...,  0.0129, -0.0019,  0.0138],
        [-0.0093, -0.0103, -0.0068,  ..., -0.0047,  0.0099,  0.0116],
        [-0.0105, -0.0073,  0.0063,  ...,  0.0067,  0.0040,  0.0082],
        ...,
        [-0.0065, -0.0067,  0.0168,  ...,  0.0098, -0.0068,  0.0041],
        [ 0.0080,  0.0168, -0.0002,  ...,  0.0005, -0.0131, -0.0166],
        [-0.0017,  0.0037, -0.0133,  ..., -0.0028, -0.0052,  0.0050]],
       device='cuda:0')

Parameter Name: base_model.model.layers.14.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[215],
        [241],
        [172],
        ...,
        [206],
        [222],
        [162]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.14.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0077,  0.0090,  0.0030,  ..., -0.0043,  0.0006, -0.0003],
        [ 0.0019,  0.0058,  0.0156,  ...,  0.0137, -0.0138, -0.0066],
        [-0.0112, -0.0038, -0.0061,  ..., -0.0068, -0.0430,  0.0070],
        ...,
        [-0.0021, -0.0038, -0.0003,  ..., -0.0053,  0.0127, -0.0172],
        [ 0.0115,  0.0066,  0.0243,  ...,  0.0051,  0.0144, -0.0272],
        [-0.0041, -0.0104, -0.0008,  ...,  0.0058, -0.0287,  0.0134]],
       device='cuda:0')

Parameter Name: base_model.model.layers.14.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 2.3128e-02, -1.6593e-02, -2.9413e-03,  ..., -1.5756e-02,
          8.8657e-03, -9.0213e-03],
        [ 2.5944e-06, -1.6297e-03, -1.1881e-03,  ...,  1.7676e-03,
          1.5740e-02, -7.6798e-03],
        [ 4.3209e-03, -7.4725e-03, -1.5431e-02,  ...,  2.6559e-02,
          2.2584e-02, -1.6676e-02],
        ...,
        [-1.3557e-03,  4.4012e-03, -2.2387e-03,  ...,  3.1905e-03,
          1.2031e-02, -7.2330e-03],
        [-4.4012e-03,  4.1942e-03,  9.6082e-03,  ..., -7.0508e-03,
         -7.6234e-03,  9.1451e-03],
        [ 6.4773e-03, -6.5033e-04,  8.2984e-03,  ..., -7.5747e-03,
         -1.2976e-02,  7.9742e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.14.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 22],
        [113],
        [225],
        ...,
        [221],
        [228],
        [198]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.14.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0074,  0.0285,  0.0086,  ..., -0.0118,  0.0053, -0.0218],
        [ 0.0190,  0.0354,  0.0135,  ..., -0.0079, -0.0132,  0.0018],
        [-0.0178, -0.0076, -0.0109,  ..., -0.0077, -0.0074,  0.0051],
        ...,
        [-0.0081,  0.0176,  0.0104,  ..., -0.0172, -0.0076, -0.0127],
        [-0.0035, -0.0168, -0.0086,  ..., -0.0113, -0.0039,  0.0159],
        [ 0.0121, -0.0248, -0.0039,  ..., -0.0082, -0.0137,  0.0233]],
       device='cuda:0')

Parameter Name: base_model.model.layers.14.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 4.4001e-03,  1.3809e-02, -4.8522e-03,  ...,  5.6807e-03,
         -1.0158e-02, -1.8144e-05],
        [ 7.6507e-03, -9.2535e-03,  4.3785e-03,  ..., -1.2250e-02,
          6.9331e-03, -6.2137e-03],
        [ 4.0397e-03, -6.2175e-03,  7.2067e-03,  ..., -3.4458e-03,
          5.6571e-03, -5.3169e-03],
        ...,
        [-1.4787e-02,  1.4899e-03,  1.4907e-02,  ...,  6.6054e-03,
          1.2615e-02,  1.6389e-02],
        [ 8.2635e-03, -1.3492e-03, -6.0377e-03,  ...,  6.7009e-03,
         -1.7933e-03, -4.5093e-03],
        [-9.5983e-03,  3.2438e-03,  8.5512e-03,  ...,  9.0032e-03,
          1.0421e-02,  7.7407e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.14.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[100],
        [110],
        [ 86],
        ...,
        [186],
        [250],
        [117]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.14.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 0.0089, -0.0030,  0.0184,  ..., -0.0022,  0.0058, -0.0158],
        [-0.0101, -0.0005, -0.0249,  ...,  0.0067,  0.0044,  0.0183],
        [-0.0175, -0.0091, -0.0378,  ..., -0.0091,  0.0040,  0.0169],
        ...,
        [ 0.0085, -0.0012,  0.0253,  ...,  0.0065,  0.0115, -0.0350],
        [-0.0084,  0.0044, -0.0262,  ...,  0.0048, -0.0054,  0.0087],
        [ 0.0020,  0.0070,  0.0067,  ..., -0.0147, -0.0057,  0.0040]],
       device='cuda:0')

Parameter Name: base_model.model.layers.14.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-1.4479e-03, -3.3851e-03,  2.0895e-03,  ..., -3.7642e-03,
         -8.9591e-03,  7.5888e-03],
        [ 9.3559e-05,  9.0765e-04,  3.9840e-03,  ...,  1.0605e-03,
          1.2796e-02,  2.5030e-02],
        [ 6.2415e-03, -8.9964e-03, -3.8291e-03,  ...,  1.0771e-02,
          2.7779e-03,  1.7244e-02],
        ...,
        [-3.6942e-03, -2.4842e-03,  1.9220e-03,  ...,  8.5566e-05,
          4.4003e-03,  1.0025e-02],
        [-1.2182e-02,  1.5005e-02,  1.4493e-02,  ..., -1.2192e-02,
         -4.3390e-03, -8.7922e-03],
        [-4.2074e-03,  6.9705e-03,  9.2873e-03,  ..., -1.6456e-02,
         -1.2480e-02,  1.6481e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.14.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4160, 0.4258, 0.3750,  ..., 0.4062, 0.3984, 0.3887], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.14.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.2734, 0.2617, 0.2598,  ..., 0.2773, 0.2734, 0.2695], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.15.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[237],
        [225],
        [ 45],
        ...,
        [226],
        [113],
        [254]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.15.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0105,  0.0047, -0.0033,  ...,  0.0188,  0.0011,  0.0236],
        [ 0.0095,  0.0119, -0.0120,  ...,  0.0242,  0.0102,  0.0300],
        [ 0.0081,  0.0018, -0.0034,  ..., -0.0051,  0.0030, -0.0141],
        ...,
        [-0.0013,  0.0133, -0.0007,  ..., -0.0219,  0.0136, -0.0235],
        [ 0.0155, -0.0095,  0.0033,  ..., -0.0135, -0.0031, -0.0163],
        [-0.0141, -0.0053,  0.0087,  ...,  0.0337, -0.0149,  0.0082]],
       device='cuda:0')

Parameter Name: base_model.model.layers.15.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0067,  0.0053, -0.0064,  ..., -0.0067, -0.0063,  0.0035],
        [ 0.0043,  0.0061, -0.0032,  ..., -0.0048, -0.0077,  0.0086],
        [ 0.0020,  0.0045, -0.0024,  ..., -0.0021, -0.0028,  0.0032],
        ...,
        [ 0.0049,  0.0036, -0.0029,  ..., -0.0053, -0.0013,  0.0019],
        [ 0.0124,  0.0132, -0.0135,  ..., -0.0111, -0.0135,  0.0122],
        [-0.0143, -0.0114,  0.0108,  ...,  0.0090,  0.0096, -0.0044]],
       device='cuda:0')

Parameter Name: base_model.model.layers.15.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 94],
        [243],
        [ 63],
        ...,
        [150],
        [217],
        [233]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.15.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[105],
        [110],
        [ 98],
        ...,
        [ 81],
        [ 77],
        [ 22]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.15.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0121, -0.0010,  0.0028,  ...,  0.0203, -0.0129,  0.0183],
        [ 0.0020,  0.0182, -0.0053,  ..., -0.0026, -0.0111,  0.0090],
        [-0.0097, -0.0151, -0.0097,  ...,  0.0065,  0.0285, -0.0013],
        ...,
        [ 0.0065,  0.0083,  0.0098,  ..., -0.0083,  0.0085, -0.0077],
        [-0.0053,  0.0038,  0.0108,  ..., -0.0042, -0.0116, -0.0133],
        [ 0.0087,  0.0109,  0.0050,  ..., -0.0049,  0.0057,  0.0084]],
       device='cuda:0')

Parameter Name: base_model.model.layers.15.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0157,  0.0085, -0.0102,  ..., -0.0021,  0.0150,  0.0051],
        [-0.0019, -0.0100, -0.0073,  ...,  0.0047,  0.0002,  0.0001],
        [-0.0189,  0.0012, -0.0058,  ...,  0.0230,  0.0171,  0.0045],
        ...,
        [ 0.0021, -0.0061,  0.0096,  ...,  0.0032, -0.0034, -0.0046],
        [-0.0004,  0.0008, -0.0104,  ...,  0.0124,  0.0078,  0.0028],
        [ 0.0057, -0.0009,  0.0073,  ...,  0.0033, -0.0116, -0.0124]],
       device='cuda:0')

Parameter Name: base_model.model.layers.15.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 23],
        [219],
        [162],
        ...,
        [ 25],
        [110],
        [170]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.15.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0210, -0.0146, -0.0104,  ...,  0.0017,  0.0089,  0.0093],
        [-0.0061, -0.0141, -0.0148,  ..., -0.0103, -0.0367,  0.0159],
        [-0.0161, -0.0035, -0.0013,  ...,  0.0016, -0.0076, -0.0221],
        ...,
        [-0.0074,  0.0070,  0.0080,  ...,  0.0194,  0.0016, -0.0130],
        [ 0.0321, -0.0148,  0.0004,  ..., -0.0086,  0.0146, -0.0180],
        [ 0.0089, -0.0020, -0.0005,  ..., -0.0049, -0.0185,  0.0089]],
       device='cuda:0')

Parameter Name: base_model.model.layers.15.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0067, -0.0147, -0.0079,  ...,  0.0025, -0.0073,  0.0072],
        [ 0.0079, -0.0130,  0.0003,  ...,  0.0069, -0.0103, -0.0070],
        [-0.0172,  0.0091,  0.0031,  ...,  0.0035,  0.0024, -0.0070],
        ...,
        [-0.0077,  0.0017,  0.0034,  ...,  0.0041,  0.0023, -0.0125],
        [ 0.0021,  0.0125, -0.0002,  ..., -0.0100,  0.0115,  0.0023],
        [-0.0043,  0.0123, -0.0077,  ..., -0.0054,  0.0052, -0.0071]],
       device='cuda:0')

Parameter Name: base_model.model.layers.15.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[242],
        [207],
        [231],
        ...,
        [177],
        [233],
        [150]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.15.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0306,  0.0233,  0.0037,  ..., -0.0012,  0.0011, -0.0066],
        [ 0.0018, -0.0225, -0.0042,  ..., -0.0079,  0.0082,  0.0020],
        [-0.0177,  0.0011,  0.0151,  ..., -0.0019, -0.0127,  0.0095],
        ...,
        [ 0.0141,  0.0043,  0.0197,  ..., -0.0005,  0.0016,  0.0108],
        [-0.0189,  0.0121,  0.0176,  ..., -0.0203, -0.0023, -0.0093],
        [-0.0298,  0.0129,  0.0222,  ..., -0.0306,  0.0121, -0.0014]],
       device='cuda:0')

Parameter Name: base_model.model.layers.15.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0056,  0.0080, -0.0050,  ..., -0.0079, -0.0058, -0.0067],
        [-0.0122, -0.0149, -0.0043,  ...,  0.0129, -0.0124, -0.0093],
        [ 0.0062, -0.0131, -0.0009,  ...,  0.0127,  0.0020,  0.0034],
        ...,
        [-0.0079,  0.0258, -0.0145,  ..., -0.0240, -0.0041, -0.0047],
        [ 0.0097, -0.0055,  0.0015,  ...,  0.0096,  0.0092,  0.0105],
        [-0.0009,  0.0093,  0.0037,  ..., -0.0105, -0.0016, -0.0051]],
       device='cuda:0')

Parameter Name: base_model.model.layers.15.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[255],
        [ 64],
        [221],
        ...,
        [206],
        [ 38],
        [201]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.15.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-4.2459e-05, -7.9196e-03, -2.5497e-03,  ...,  3.4138e-03,
          2.1186e-02, -1.6114e-02],
        [ 1.7956e-03, -7.5599e-03, -1.0144e-02,  ...,  1.5822e-02,
         -2.0816e-02,  3.5958e-03],
        [ 1.3065e-02,  1.0797e-02,  1.3506e-02,  ..., -2.1794e-04,
         -7.3948e-03,  1.0762e-02],
        ...,
        [ 1.0573e-02, -1.7281e-02, -1.6645e-02,  ...,  5.8669e-03,
         -1.5488e-02,  1.0659e-02],
        [ 2.9270e-02, -7.0648e-03, -1.7123e-03,  ...,  6.3046e-03,
          7.5222e-03,  3.2164e-03],
        [ 1.5867e-02,  5.9543e-03,  2.8698e-03,  ..., -4.3897e-04,
          1.8637e-02,  1.9554e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.15.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0084,  0.0113, -0.0026,  ...,  0.0060,  0.0086, -0.0017],
        [ 0.0079,  0.0011, -0.0044,  ...,  0.0034,  0.0024,  0.0032],
        [ 0.0125, -0.0106,  0.0045,  ..., -0.0075, -0.0008, -0.0040],
        ...,
        [ 0.0106, -0.0106, -0.0118,  ..., -0.0048,  0.0132, -0.0010],
        [ 0.0165,  0.0008, -0.0086,  ..., -0.0031,  0.0158,  0.0095],
        [-0.0060, -0.0008,  0.0005,  ...,  0.0006, -0.0088, -0.0098]],
       device='cuda:0')

Parameter Name: base_model.model.layers.15.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[252],
        [175],
        [230],
        ...,
        [ 79],
        [ 31],
        [221]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.15.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[-0.0046,  0.0186,  0.0022,  ..., -0.0223, -0.0078, -0.0197],
        [ 0.0131, -0.0016,  0.0115,  ...,  0.0133,  0.0135,  0.0111],
        [-0.0027,  0.0066, -0.0183,  ...,  0.0221,  0.0041,  0.0155],
        ...,
        [-0.0129,  0.0118,  0.0068,  ..., -0.0154, -0.0065, -0.0244],
        [-0.0012,  0.0011, -0.0135,  ..., -0.0162,  0.0071, -0.0092],
        [ 0.0165, -0.0056, -0.0048,  ..., -0.0263,  0.0130, -0.0037]],
       device='cuda:0')

Parameter Name: base_model.model.layers.15.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0017,  0.0030,  0.0018,  ...,  0.0021, -0.0039,  0.0047],
        [-0.0015, -0.0007,  0.0048,  ..., -0.0132, -0.0098, -0.0086],
        [-0.0068,  0.0096,  0.0139,  ..., -0.0048, -0.0052, -0.0127],
        ...,
        [ 0.0006,  0.0038, -0.0028,  ...,  0.0039,  0.0058,  0.0071],
        [-0.0052, -0.0140,  0.0025,  ..., -0.0007, -0.0059,  0.0012],
        [ 0.0051,  0.0020, -0.0078,  ...,  0.0089, -0.0021,  0.0088]],
       device='cuda:0')

Parameter Name: base_model.model.layers.15.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4062, 0.4004, 0.3770,  ..., 0.3848, 0.3848, 0.3887], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.15.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.2852, 0.2715, 0.2715,  ..., 0.2852, 0.2812, 0.2812], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.16.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[118],
        [221],
        [ 43],
        ...,
        [ 20],
        [201],
        [206]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.16.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0143,  0.0031, -0.0064,  ..., -0.0358, -0.0015, -0.0090],
        [ 0.0063, -0.0236, -0.0029,  ..., -0.0229,  0.0106, -0.0089],
        [ 0.0104, -0.0116, -0.0053,  ..., -0.0201,  0.0109, -0.0184],
        ...,
        [ 0.0002,  0.0053, -0.0176,  ..., -0.0273,  0.0043, -0.0299],
        [-0.0091,  0.0259, -0.0161,  ...,  0.0039, -0.0125, -0.0078],
        [-0.0229,  0.0042, -0.0032,  ...,  0.0304,  0.0030,  0.0317]],
       device='cuda:0')

Parameter Name: base_model.model.layers.16.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0044,  0.0044,  0.0024,  ..., -0.0044, -0.0068, -0.0012],
        [ 0.0207,  0.0143,  0.0226,  ...,  0.0116, -0.0041, -0.0272],
        [-0.0051, -0.0058, -0.0074,  ..., -0.0100, -0.0009,  0.0053],
        ...,
        [-0.0053, -0.0088, -0.0033,  ..., -0.0045,  0.0012,  0.0028],
        [ 0.0066,  0.0026,  0.0089,  ...,  0.0102, -0.0078, -0.0077],
        [-0.0070, -0.0063, -0.0084,  ..., -0.0091,  0.0037,  0.0078]],
       device='cuda:0')

Parameter Name: base_model.model.layers.16.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[196],
        [105],
        [ 21],
        ...,
        [201],
        [153],
        [245]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.16.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[225],
        [236],
        [197],
        ...,
        [146],
        [ 79],
        [ 26]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.16.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0310,  0.0213,  0.0187,  ..., -0.0075, -0.0069,  0.0067],
        [ 0.0208,  0.0161,  0.0040,  ...,  0.0118, -0.0235, -0.0023],
        [ 0.0050,  0.0207,  0.0055,  ..., -0.0125,  0.0002, -0.0037],
        ...,
        [ 0.0024, -0.0038, -0.0315,  ...,  0.0174,  0.0226, -0.0029],
        [ 0.0063,  0.0159,  0.0222,  ..., -0.0066, -0.0190,  0.0015],
        [-0.0040, -0.0055, -0.0278,  ..., -0.0138, -0.0089, -0.0059]],
       device='cuda:0')

Parameter Name: base_model.model.layers.16.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0188,  0.0028,  0.0156,  ..., -0.0190,  0.0144, -0.0133],
        [ 0.0076,  0.0021,  0.0117,  ..., -0.0154,  0.0028,  0.0043],
        [ 0.0066,  0.0026, -0.0021,  ..., -0.0062,  0.0058,  0.0037],
        ...,
        [-0.0156, -0.0087, -0.0143,  ...,  0.0087, -0.0149,  0.0013],
        [-0.0018, -0.0046, -0.0082,  ...,  0.0110, -0.0027, -0.0051],
        [-0.0116, -0.0132, -0.0111,  ...,  0.0085, -0.0108,  0.0088]],
       device='cuda:0')

Parameter Name: base_model.model.layers.16.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 41],
        [206],
        [198],
        ...,
        [225],
        [ 89],
        [225]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.16.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 4.3864e-05,  4.4801e-03,  2.1448e-02,  ..., -2.0195e-02,
         -1.1550e-02,  4.6535e-02],
        [-7.2891e-04,  8.3190e-03, -6.5270e-03,  ..., -3.8011e-03,
          2.2731e-02,  3.7409e-02],
        [ 5.5124e-03, -2.0365e-02,  5.1326e-03,  ..., -1.7580e-02,
          6.1603e-04, -1.0519e-02],
        ...,
        [-2.1668e-02,  5.9151e-03,  5.4714e-03,  ...,  2.8217e-02,
          5.2250e-03, -7.4962e-03],
        [-3.5007e-03,  2.7595e-03,  1.2847e-02,  ...,  1.0239e-02,
         -6.2315e-03,  2.9683e-02],
        [ 8.4190e-03,  4.4556e-03, -1.3536e-02,  ..., -1.2371e-02,
          2.3064e-03, -1.0123e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.16.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0193,  0.0059,  0.0004,  ..., -0.0012,  0.0145, -0.0192],
        [-0.0043,  0.0026, -0.0024,  ..., -0.0029, -0.0081,  0.0027],
        [ 0.0040,  0.0078,  0.0035,  ...,  0.0065, -0.0063,  0.0055],
        ...,
        [ 0.0187,  0.0031,  0.0077,  ...,  0.0082,  0.0088,  0.0063],
        [ 0.0111, -0.0029,  0.0120,  ...,  0.0039, -0.0076,  0.0037],
        [-0.0100, -0.0192, -0.0004,  ...,  0.0009,  0.0116,  0.0004]],
       device='cuda:0')

Parameter Name: base_model.model.layers.16.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[204],
        [210],
        [210],
        ...,
        [150],
        [154],
        [ 78]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.16.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0153,  0.0083,  0.0118,  ..., -0.0175, -0.0167, -0.0067],
        [-0.0148, -0.0012, -0.0250,  ...,  0.0127, -0.0107,  0.0050],
        [ 0.0007, -0.0092, -0.0117,  ..., -0.0093, -0.0097, -0.0066],
        ...,
        [ 0.0287,  0.0129,  0.0125,  ...,  0.0021, -0.0117,  0.0098],
        [-0.0083,  0.0078, -0.0148,  ...,  0.0228, -0.0206,  0.0020],
        [-0.0129,  0.0118,  0.0180,  ...,  0.0115, -0.0092, -0.0181]],
       device='cuda:0')

Parameter Name: base_model.model.layers.16.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 1.0293e-02, -6.4330e-03,  1.3120e-02,  ..., -3.0128e-02,
         -1.7962e-02, -6.3524e-03],
        [-1.0943e-02,  3.6225e-03, -9.1174e-03,  ...,  1.1648e-02,
          1.4155e-02,  8.9108e-03],
        [-1.2367e-02, -1.3811e-02, -9.2844e-03,  ...,  6.4057e-03,
         -1.3295e-02,  3.9012e-03],
        ...,
        [-8.7870e-03, -1.8816e-02, -1.1782e-02,  ...,  3.5000e-03,
         -1.3895e-02,  1.5141e-02],
        [ 9.6792e-05,  3.0869e-03,  4.7014e-03,  ..., -6.7795e-04,
          2.2933e-03,  7.5509e-03],
        [ 1.5160e-02,  2.7053e-03,  1.1963e-02,  ..., -1.3435e-02,
         -1.7693e-02, -9.6143e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.16.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[167],
        [101],
        [147],
        ...,
        [ 21],
        [ 65],
        [204]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.16.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 2.0225e-03,  9.2355e-03, -2.0270e-02,  ...,  2.8565e-02,
         -1.6761e-02,  2.5839e-02],
        [-1.9787e-02,  2.1071e-02, -3.1399e-02,  ..., -1.8325e-02,
          1.3014e-03, -4.4491e-03],
        [-2.1161e-03,  1.1000e-02, -2.8379e-02,  ..., -1.8504e-02,
         -1.3436e-02,  9.8117e-03],
        ...,
        [ 4.1118e-03,  3.0680e-03, -2.5666e-03,  ..., -1.3725e-02,
          1.4721e-02,  9.8672e-03],
        [ 1.5528e-03, -1.9492e-02, -2.0532e-04,  ...,  3.1852e-02,
         -4.9276e-05,  8.7306e-03],
        [-1.6619e-02,  2.3867e-02, -1.4348e-02,  ..., -3.6756e-03,
          4.3908e-03,  7.9930e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.16.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 1.4006e-02, -1.0160e-02,  2.1921e-03,  ...,  8.4294e-03,
          1.5296e-02,  3.9981e-03],
        [ 7.5773e-03,  4.5048e-03,  3.8714e-04,  ..., -8.7548e-03,
         -2.9381e-05,  3.3109e-03],
        [ 1.4345e-02, -9.8764e-06, -9.1386e-03,  ..., -2.0414e-04,
          1.2639e-02, -1.1488e-03],
        ...,
        [ 1.2324e-02, -5.4978e-03, -7.4983e-03,  ...,  1.4028e-03,
          8.0929e-03, -8.4572e-03],
        [-2.4502e-04,  3.8719e-03, -1.1818e-03,  ...,  4.3710e-03,
         -8.6751e-04,  1.5574e-03],
        [ 1.1589e-02, -1.6089e-02, -1.9999e-02,  ...,  9.6320e-03,
          1.2010e-02, -1.4063e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.16.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[201],
        [ 69],
        [207],
        ...,
        [ 25],
        [ 21],
        [ 28]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.16.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[-0.0181,  0.0294,  0.0044,  ...,  0.0015, -0.0184,  0.0306],
        [ 0.0118,  0.0079,  0.0131,  ...,  0.0047,  0.0083, -0.0167],
        [-0.0071, -0.0050, -0.0051,  ...,  0.0166, -0.0102, -0.0036],
        ...,
        [-0.0276,  0.0112,  0.0099,  ..., -0.0094,  0.0042, -0.0111],
        [-0.0009,  0.0064, -0.0059,  ...,  0.0181, -0.0022,  0.0158],
        [ 0.0173, -0.0059,  0.0048,  ..., -0.0019,  0.0093, -0.0182]],
       device='cuda:0')

Parameter Name: base_model.model.layers.16.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0096,  0.0078, -0.0171,  ...,  0.0045, -0.0094,  0.0014],
        [-0.0174,  0.0212, -0.0080,  ..., -0.0043, -0.0177,  0.0199],
        [ 0.0041, -0.0091,  0.0088,  ..., -0.0180,  0.0043, -0.0057],
        ...,
        [-0.0053, -0.0061, -0.0075,  ..., -0.0012,  0.0056, -0.0045],
        [ 0.0116,  0.0018, -0.0073,  ...,  0.0171, -0.0028, -0.0047],
        [-0.0063,  0.0128,  0.0042,  ..., -0.0112,  0.0034, -0.0049]],
       device='cuda:0')

Parameter Name: base_model.model.layers.16.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4102, 0.4160, 0.3867,  ..., 0.3867, 0.4023, 0.4004], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.16.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.3027, 0.2891, 0.2910,  ..., 0.3027, 0.3066, 0.2969], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.17.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[221],
        [ 89],
        [110],
        ...,
        [ 81],
        [ 84],
        [ 18]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.17.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0014, -0.0193, -0.0212,  ..., -0.0149, -0.0126, -0.0076],
        [ 0.0183, -0.0059,  0.0111,  ...,  0.0032, -0.0044,  0.0115],
        [ 0.0064,  0.0071, -0.0177,  ..., -0.0122, -0.0087,  0.0107],
        ...,
        [-0.0121, -0.0012,  0.0243,  ..., -0.0216,  0.0061, -0.0070],
        [-0.0118, -0.0149, -0.0201,  ..., -0.0038, -0.0114, -0.0095],
        [ 0.0020, -0.0078, -0.0081,  ..., -0.0019, -0.0029, -0.0170]],
       device='cuda:0')

Parameter Name: base_model.model.layers.17.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0105, -0.0123,  0.0119,  ...,  0.0149,  0.0163,  0.0108],
        [-0.0111,  0.0103, -0.0131,  ..., -0.0101, -0.0136, -0.0140],
        [ 0.0174, -0.0186,  0.0174,  ...,  0.0166,  0.0152,  0.0161],
        ...,
        [-0.0087,  0.0092, -0.0100,  ..., -0.0107, -0.0129, -0.0072],
        [ 0.0046, -0.0006,  0.0010,  ..., -0.0008,  0.0024,  0.0036],
        [ 0.0063, -0.0031,  0.0065,  ..., -0.0025,  0.0040,  0.0052]],
       device='cuda:0')

Parameter Name: base_model.model.layers.17.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[214],
        [102],
        [ 93],
        ...,
        [ 73],
        [199],
        [105]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.17.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[198],
        [101],
        [249],
        ...,
        [ 98],
        [ 71],
        [118]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.17.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0101,  0.0212,  0.0073,  ..., -0.0123, -0.0160,  0.0211],
        [ 0.0160,  0.0028, -0.0166,  ..., -0.0036,  0.0153, -0.0112],
        [ 0.0061,  0.0166, -0.0075,  ..., -0.0031,  0.0236, -0.0061],
        ...,
        [-0.0072,  0.0231, -0.0002,  ...,  0.0171,  0.0074,  0.0216],
        [-0.0026,  0.0051,  0.0010,  ...,  0.0265, -0.0031,  0.0043],
        [ 0.0075, -0.0166, -0.0190,  ...,  0.0013,  0.0073, -0.0217]],
       device='cuda:0')

Parameter Name: base_model.model.layers.17.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-1.2691e-02,  1.2372e-02,  1.0954e-02,  ..., -9.5557e-03,
         -1.6493e-02,  6.9835e-03],
        [ 1.0462e-02, -9.0206e-03, -1.1264e-02,  ..., -1.7583e-02,
         -9.0179e-03, -6.0070e-04],
        [-7.5357e-05, -1.8087e-03, -5.5139e-03,  ..., -1.3941e-03,
         -3.8496e-03,  3.7297e-03],
        ...,
        [ 7.2738e-03, -7.4425e-03, -2.1506e-02,  ..., -1.2083e-02,
          4.8015e-03, -8.7246e-03],
        [-5.4262e-03,  6.1989e-05,  1.3126e-03,  ...,  6.6335e-03,
          1.8218e-03, -7.4102e-03],
        [ 9.1810e-03, -1.7386e-03,  4.1355e-03,  ...,  1.7859e-02,
          1.5522e-03, -9.7826e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.17.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[238],
        [111],
        [233],
        ...,
        [208],
        [163],
        [213]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.17.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0129,  0.0236,  0.0145,  ..., -0.0202,  0.0066, -0.0120],
        [ 0.0047, -0.0096,  0.0002,  ...,  0.0089, -0.0157,  0.0047],
        [-0.0004, -0.0030,  0.0119,  ...,  0.0183, -0.0208, -0.0034],
        ...,
        [-0.0017,  0.0184,  0.0064,  ..., -0.0083,  0.0077, -0.0177],
        [-0.0057, -0.0092,  0.0102,  ..., -0.0166,  0.0206, -0.0096],
        [ 0.0099,  0.0236,  0.0048,  ..., -0.0076,  0.0121, -0.0197]],
       device='cuda:0')

Parameter Name: base_model.model.layers.17.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0062, -0.0002,  0.0156,  ..., -0.0192, -0.0116, -0.0010],
        [-0.0089, -0.0011,  0.0008,  ...,  0.0065,  0.0106, -0.0078],
        [-0.0130, -0.0105,  0.0101,  ..., -0.0176,  0.0023,  0.0019],
        ...,
        [-0.0006, -0.0015,  0.0041,  ..., -0.0006, -0.0093, -0.0083],
        [ 0.0064,  0.0073, -0.0102,  ...,  0.0125,  0.0048,  0.0109],
        [-0.0011,  0.0086, -0.0011,  ...,  0.0079, -0.0091, -0.0077]],
       device='cuda:0')

Parameter Name: base_model.model.layers.17.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[164],
        [116],
        [118],
        ...,
        [233],
        [255],
        [105]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.17.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0121,  0.0239, -0.0219,  ..., -0.0146, -0.0109,  0.0006],
        [-0.0036, -0.0070,  0.0149,  ..., -0.0081,  0.0262,  0.0006],
        [-0.0149,  0.0158, -0.0084,  ..., -0.0024, -0.0175,  0.0135],
        ...,
        [ 0.0099,  0.0059, -0.0201,  ..., -0.0052, -0.0039,  0.0184],
        [-0.0144,  0.0246,  0.0016,  ...,  0.0022, -0.0086, -0.0031],
        [-0.0148, -0.0126, -0.0084,  ...,  0.0062,  0.0017, -0.0199]],
       device='cuda:0')

Parameter Name: base_model.model.layers.17.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0103, -0.0100,  0.0057,  ..., -0.0057, -0.0109,  0.0073],
        [ 0.0033, -0.0083,  0.0056,  ..., -0.0002,  0.0052,  0.0006],
        [-0.0088, -0.0092,  0.0076,  ..., -0.0081,  0.0112,  0.0089],
        ...,
        [-0.0080,  0.0022,  0.0001,  ..., -0.0087,  0.0009,  0.0154],
        [ 0.0048,  0.0046, -0.0050,  ..., -0.0037, -0.0055,  0.0003],
        [-0.0021,  0.0062, -0.0132,  ...,  0.0178, -0.0056, -0.0027]],
       device='cuda:0')

Parameter Name: base_model.model.layers.17.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[237],
        [236],
        [217],
        ...,
        [234],
        [ 70],
        [188]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.17.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0195,  0.0083,  0.0023,  ..., -0.0023,  0.0057, -0.0040],
        [ 0.0181,  0.0136, -0.0137,  ..., -0.0182, -0.0190,  0.0173],
        [ 0.0385,  0.0120, -0.0016,  ..., -0.0146, -0.0209,  0.0197],
        ...,
        [ 0.0189,  0.0225, -0.0253,  ...,  0.0038,  0.0023, -0.0004],
        [ 0.0223,  0.0236, -0.0087,  ..., -0.0268, -0.0135,  0.0121],
        [ 0.0018, -0.0232, -0.0059,  ...,  0.0146,  0.0025, -0.0138]],
       device='cuda:0')

Parameter Name: base_model.model.layers.17.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 1.0055e-02,  1.2275e-02,  1.0986e-02,  ...,  1.2861e-02,
         -1.9756e-06, -8.8048e-03],
        [-3.5194e-03,  4.6871e-03, -7.0100e-03,  ..., -9.5972e-03,
         -6.3743e-03,  1.1255e-02],
        [-1.3118e-02,  8.7964e-03, -5.4833e-03,  ...,  1.1488e-03,
         -1.0808e-02,  2.9697e-02],
        ...,
        [-8.3718e-03,  4.1819e-03,  8.8938e-03,  ..., -1.7578e-02,
          8.5888e-04, -2.5009e-03],
        [-1.1079e-02, -1.7719e-02, -6.2607e-03,  ...,  5.4942e-03,
         -7.1348e-03,  1.1031e-02],
        [-4.3147e-03,  6.6203e-03,  6.7736e-03,  ...,  4.9665e-03,
         -1.7941e-03,  5.5850e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.17.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 92],
        [101],
        [ 63],
        ...,
        [145],
        [250],
        [225]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.17.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[-0.0084,  0.0199, -0.0266,  ..., -0.0040, -0.0128, -0.0080],
        [ 0.0133, -0.0163,  0.0228,  ...,  0.0004,  0.0151, -0.0034],
        [-0.0169, -0.0147, -0.0166,  ...,  0.0152,  0.0243, -0.0038],
        ...,
        [-0.0040, -0.0088,  0.0172,  ...,  0.0267,  0.0140,  0.0091],
        [-0.0157,  0.0107, -0.0243,  ..., -0.0156, -0.0173,  0.0012],
        [-0.0100, -0.0076, -0.0092,  ..., -0.0079,  0.0015, -0.0062]],
       device='cuda:0')

Parameter Name: base_model.model.layers.17.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 4.2923e-03, -2.8679e-04,  1.1582e-03,  ..., -3.4593e-03,
          9.3525e-04, -1.0174e-02],
        [-6.0249e-03,  5.6495e-03,  3.1773e-04,  ..., -6.1552e-04,
         -1.7999e-03,  5.3440e-04],
        [-4.2934e-03,  3.2514e-03,  5.8269e-03,  ..., -3.6157e-03,
         -5.4465e-03, -7.6307e-03],
        ...,
        [-1.1021e-02,  2.1391e-02, -3.8313e-03,  ...,  2.0459e-02,
         -1.9666e-02, -1.4317e-02],
        [ 7.9798e-03,  7.4353e-05, -5.6590e-03,  ..., -6.2753e-03,
          9.0455e-03,  2.7040e-03],
        [ 3.3052e-03,  9.7243e-03,  1.0815e-02,  ..., -1.0224e-03,
         -1.5998e-03, -7.7010e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.17.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4238, 0.4277, 0.4004,  ..., 0.4199, 0.4219, 0.4043], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.17.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.3203, 0.3125, 0.3105,  ..., 0.3223, 0.3242, 0.3145], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.18.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[102],
        [ 18],
        [177],
        ...,
        [204],
        [ 71],
        [ 42]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.18.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0058,  0.0038,  0.0091,  ..., -0.0009, -0.0047, -0.0009],
        [ 0.0010,  0.0084,  0.0098,  ...,  0.0075, -0.0176, -0.0121],
        [-0.0007,  0.0054, -0.0065,  ...,  0.0009, -0.0060, -0.0091],
        ...,
        [ 0.0190, -0.0141, -0.0119,  ..., -0.0046, -0.0167, -0.0031],
        [ 0.0060, -0.0044,  0.0027,  ...,  0.0035,  0.0090, -0.0058],
        [-0.0061,  0.0152,  0.0059,  ...,  0.0058, -0.0024,  0.0010]],
       device='cuda:0')

Parameter Name: base_model.model.layers.18.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0116, -0.0101,  0.0098,  ..., -0.0012,  0.0098,  0.0106],
        [-0.0108, -0.0041,  0.0111,  ...,  0.0011,  0.0087,  0.0083],
        [-0.0160, -0.0097,  0.0135,  ..., -0.0017,  0.0110,  0.0109],
        ...,
        [ 0.0032,  0.0049, -0.0061,  ...,  0.0068, -0.0112, -0.0184],
        [-0.0108, -0.0094,  0.0092,  ...,  0.0085,  0.0065,  0.0059],
        [ 0.0245,  0.0250, -0.0266,  ..., -0.0130, -0.0273, -0.0270]],
       device='cuda:0')

Parameter Name: base_model.model.layers.18.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[194],
        [253],
        [217],
        ...,
        [106],
        [100],
        [236]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.18.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[212],
        [222],
        [ 17],
        ...,
        [165],
        [110],
        [201]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.18.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0022, -0.0264, -0.0069,  ..., -0.0127, -0.0071, -0.0172],
        [ 0.0015, -0.0155, -0.0071,  ...,  0.0063,  0.0082, -0.0089],
        [ 0.0323,  0.0066, -0.0184,  ..., -0.0120, -0.0264,  0.0021],
        ...,
        [-0.0098, -0.0167, -0.0051,  ...,  0.0233,  0.0046, -0.0030],
        [-0.0072, -0.0099, -0.0020,  ..., -0.0034, -0.0140, -0.0199],
        [-0.0047, -0.0175, -0.0023,  ..., -0.0156, -0.0048, -0.0147]],
       device='cuda:0')

Parameter Name: base_model.model.layers.18.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-1.7837e-03,  7.3604e-03,  4.7078e-03,  ...,  3.7819e-03,
         -3.1033e-03, -4.1452e-03],
        [-1.0034e-05,  8.7159e-03, -5.4058e-03,  ...,  5.4423e-03,
          4.0117e-04, -1.9747e-03],
        [-1.3043e-02,  2.9460e-03,  9.0109e-03,  ...,  2.5231e-03,
         -1.7429e-02, -7.0774e-03],
        ...,
        [ 1.2380e-02, -1.0329e-02, -8.3130e-03,  ...,  2.1982e-03,
          4.5834e-03, -7.2573e-04],
        [-1.2835e-02,  2.0163e-02, -5.3374e-03,  ...,  1.8142e-03,
         -1.9838e-02, -4.5891e-03],
        [ 3.6145e-04,  2.1580e-03,  6.2328e-03,  ..., -1.5492e-02,
          2.0174e-03,  7.1329e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.18.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[199],
        [204],
        [ 66],
        ...,
        [203],
        [ 92],
        [ 77]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.18.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0102,  0.0177, -0.0081,  ...,  0.0060,  0.0192, -0.0111],
        [-0.0063,  0.0080,  0.0041,  ...,  0.0078,  0.0124, -0.0074],
        [ 0.0032, -0.0311, -0.0015,  ...,  0.0336, -0.0291, -0.0081],
        ...,
        [-0.0072, -0.0114,  0.0036,  ...,  0.0186,  0.0082,  0.0066],
        [-0.0068, -0.0030,  0.0119,  ...,  0.0059, -0.0089,  0.0067],
        [-0.0073,  0.0231,  0.0035,  ..., -0.0024,  0.0012, -0.0148]],
       device='cuda:0')

Parameter Name: base_model.model.layers.18.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-4.1025e-03,  1.0653e-02,  8.8982e-03,  ...,  1.1116e-03,
          6.6113e-03, -1.3653e-02],
        [ 3.1672e-03, -1.9515e-03,  1.9841e-02,  ..., -5.3639e-03,
          1.4640e-02, -2.1332e-02],
        [ 1.0850e-03, -4.1071e-03, -5.1208e-03,  ...,  3.2794e-03,
         -5.3761e-03, -4.2644e-04],
        ...,
        [-2.9417e-03,  1.2297e-03,  1.1210e-02,  ...,  1.4502e-05,
          1.7432e-03, -1.1410e-03],
        [-9.5124e-03, -4.6965e-04,  1.1604e-02,  ...,  1.8597e-02,
          5.4478e-03, -3.1796e-03],
        [-1.2872e-02, -9.2347e-03,  7.0608e-03,  ...,  1.6844e-02,
          1.0147e-02, -7.5495e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.18.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[126],
        [121],
        [ 13],
        ...,
        [169],
        [150],
        [225]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.18.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0148, -0.0113, -0.0311,  ...,  0.0070, -0.0136,  0.0020],
        [-0.0088,  0.0115,  0.0171,  ..., -0.0038,  0.0132,  0.0304],
        [ 0.0123,  0.0093, -0.0181,  ...,  0.0202,  0.0135,  0.0003],
        ...,
        [-0.0202, -0.0037,  0.0070,  ..., -0.0033,  0.0158,  0.0114],
        [ 0.0067, -0.0095, -0.0050,  ..., -0.0021,  0.0081,  0.0078],
        [-0.0252,  0.0265, -0.0275,  ..., -0.0004, -0.0032, -0.0106]],
       device='cuda:0')

Parameter Name: base_model.model.layers.18.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-3.0421e-03, -8.4686e-03, -8.9003e-03,  ..., -9.0961e-03,
         -8.4768e-03,  6.9892e-03],
        [-1.7331e-02, -5.6397e-03, -1.3395e-02,  ...,  9.0298e-03,
         -2.0360e-03,  4.0323e-03],
        [ 7.4981e-03,  6.3691e-03,  4.6805e-03,  ..., -2.3972e-04,
          6.2761e-03, -9.8838e-03],
        ...,
        [-1.7052e-05,  3.0410e-03, -9.8048e-03,  ...,  1.1665e-02,
          3.7530e-03, -7.8166e-03],
        [-4.0259e-03, -7.9246e-03, -5.0287e-03,  ..., -3.3050e-03,
         -8.0520e-03,  3.9314e-03],
        [-2.0009e-02,  6.8516e-03, -1.3009e-02,  ...,  1.0225e-02,
          7.0526e-03,  5.8059e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.18.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[118],
        [ 36],
        [ 77],
        ...,
        [237],
        [124],
        [ 68]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.18.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0138,  0.0226, -0.0035,  ..., -0.0024,  0.0103,  0.0239],
        [ 0.0124,  0.0350,  0.0115,  ..., -0.0102,  0.0149,  0.0039],
        [ 0.0059,  0.0266,  0.0122,  ...,  0.0051,  0.0052,  0.0098],
        ...,
        [-0.0107,  0.0032, -0.0187,  ..., -0.0106, -0.0040, -0.0111],
        [-0.0067, -0.0246, -0.0022,  ...,  0.0065, -0.0203, -0.0142],
        [ 0.0032,  0.0197,  0.0184,  ...,  0.0235, -0.0093,  0.0138]],
       device='cuda:0')

Parameter Name: base_model.model.layers.18.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0153, -0.0131, -0.0083,  ...,  0.0151,  0.0065, -0.0054],
        [ 0.0208,  0.0008,  0.0186,  ..., -0.0091, -0.0174, -0.0073],
        [ 0.0136,  0.0053,  0.0024,  ...,  0.0019, -0.0021,  0.0023],
        ...,
        [ 0.0003, -0.0040, -0.0026,  ..., -0.0079,  0.0032,  0.0030],
        [-0.0069, -0.0075, -0.0107,  ...,  0.0059,  0.0074, -0.0022],
        [-0.0055,  0.0034, -0.0042,  ...,  0.0048,  0.0059, -0.0091]],
       device='cuda:0')

Parameter Name: base_model.model.layers.18.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 39],
        [163],
        [147],
        ...,
        [231],
        [ 94],
        [ 71]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.18.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 0.0162,  0.0329, -0.0012,  ..., -0.0151,  0.0028, -0.0111],
        [-0.0024, -0.0289, -0.0102,  ...,  0.0069, -0.0193,  0.0031],
        [ 0.0019,  0.0201, -0.0139,  ...,  0.0075,  0.0135, -0.0010],
        ...,
        [-0.0133, -0.0376,  0.0046,  ...,  0.0161, -0.0031, -0.0007],
        [ 0.0004,  0.0161, -0.0078,  ..., -0.0160,  0.0015, -0.0079],
        [ 0.0025,  0.0213, -0.0258,  ..., -0.0038,  0.0129,  0.0116]],
       device='cuda:0')

Parameter Name: base_model.model.layers.18.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0114, -0.0046,  0.0066,  ..., -0.0083,  0.0086,  0.0031],
        [-0.0032,  0.0066, -0.0093,  ...,  0.0144, -0.0057, -0.0012],
        [ 0.0024,  0.0030,  0.0017,  ..., -0.0003, -0.0022,  0.0087],
        ...,
        [-0.0059,  0.0064, -0.0060,  ...,  0.0014, -0.0024, -0.0099],
        [-0.0099,  0.0078, -0.0087,  ...,  0.0112,  0.0003, -0.0140],
        [-0.0104,  0.0018, -0.0076,  ...,  0.0062,  0.0005, -0.0011]],
       device='cuda:0')

Parameter Name: base_model.model.layers.18.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4473, 0.4473, 0.4277,  ..., 0.4297, 0.4414, 0.4258], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.18.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.3398, 0.3301, 0.3281,  ..., 0.3359, 0.3398, 0.3340], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.19.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 22],
        [253],
        [103],
        ...,
        [ 81],
        [ 89],
        [174]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.19.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0079,  0.0125, -0.0125,  ...,  0.0141,  0.0081,  0.0147],
        [ 0.0092,  0.0189,  0.0031,  ..., -0.0022, -0.0075,  0.0098],
        [-0.0202,  0.0305, -0.0150,  ...,  0.0122,  0.0049,  0.0173],
        ...,
        [-0.0297, -0.0031,  0.0096,  ...,  0.0045, -0.0130,  0.0024],
        [ 0.0241, -0.0030, -0.0189,  ..., -0.0027,  0.0012, -0.0167],
        [ 0.0184, -0.0041,  0.0038,  ..., -0.0005,  0.0188, -0.0141]],
       device='cuda:0')

Parameter Name: base_model.model.layers.19.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0154,  0.0109,  0.0182,  ..., -0.0063,  0.0096,  0.0075],
        [ 0.0124,  0.0034,  0.0151,  ..., -0.0090, -0.0085,  0.0022],
        [-0.0133, -0.0047, -0.0157,  ...,  0.0038,  0.0040, -0.0013],
        ...,
        [ 0.0012,  0.0031,  0.0016,  ..., -0.0049,  0.0042,  0.0041],
        [-0.0082,  0.0069, -0.0105,  ..., -0.0082,  0.0080,  0.0062],
        [ 0.0091, -0.0024,  0.0104,  ...,  0.0044, -0.0026, -0.0038]],
       device='cuda:0')

Parameter Name: base_model.model.layers.19.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 84],
        [ 30],
        [206],
        ...,
        [ 86],
        [239],
        [100]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.19.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 30],
        [153],
        [102],
        ...,
        [150],
        [109],
        [196]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.19.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0068,  0.0203, -0.0135,  ...,  0.0145, -0.0169, -0.0060],
        [-0.0174, -0.0061, -0.0164,  ...,  0.0211,  0.0009,  0.0065],
        [-0.0288, -0.0012,  0.0198,  ..., -0.0201, -0.0155,  0.0008],
        ...,
        [-0.0083,  0.0294,  0.0126,  ..., -0.0030,  0.0166,  0.0033],
        [-0.0014, -0.0148, -0.0022,  ...,  0.0192, -0.0066, -0.0078],
        [-0.0073, -0.0028,  0.0287,  ...,  0.0011, -0.0087,  0.0047]],
       device='cuda:0')

Parameter Name: base_model.model.layers.19.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0118,  0.0152, -0.0161,  ..., -0.0140,  0.0098, -0.0034],
        [-0.0024, -0.0039, -0.0036,  ...,  0.0056,  0.0052, -0.0053],
        [ 0.0041,  0.0055, -0.0039,  ..., -0.0030,  0.0015,  0.0080],
        ...,
        [-0.0028,  0.0082, -0.0042,  ..., -0.0002, -0.0040,  0.0015],
        [ 0.0055,  0.0046,  0.0014,  ..., -0.0011, -0.0046, -0.0070],
        [ 0.0061, -0.0015,  0.0124,  ...,  0.0085, -0.0147,  0.0064]],
       device='cuda:0')

Parameter Name: base_model.model.layers.19.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 75],
        [ 92],
        [229],
        ...,
        [ 95],
        [ 92],
        [244]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.19.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0053, -0.0133, -0.0041,  ...,  0.0102,  0.0120, -0.0130],
        [ 0.0179,  0.0175, -0.0021,  ...,  0.0126, -0.0168, -0.0220],
        [-0.0228, -0.0010,  0.0007,  ..., -0.0086, -0.0024,  0.0461],
        ...,
        [ 0.0011,  0.0099,  0.0059,  ...,  0.0183,  0.0210, -0.0232],
        [-0.0036, -0.0092,  0.0200,  ..., -0.0142,  0.0066,  0.0169],
        [ 0.0132,  0.0151, -0.0200,  ...,  0.0089, -0.0060,  0.0057]],
       device='cuda:0')

Parameter Name: base_model.model.layers.19.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 1.1467e-03, -8.5839e-03,  1.0758e-02,  ...,  1.1512e-03,
          3.8040e-03, -7.7204e-03],
        [-3.1467e-03, -2.0486e-03, -5.8041e-03,  ...,  3.6409e-03,
         -3.1681e-03,  8.9472e-05],
        [-3.4309e-03, -6.7931e-03,  6.0232e-03,  ...,  3.5429e-03,
          1.1133e-02, -2.4201e-03],
        ...,
        [ 9.1707e-03,  1.0728e-02,  3.6321e-03,  ..., -1.3135e-03,
          2.2742e-03, -2.7576e-03],
        [-1.4950e-02,  1.7566e-02,  3.9968e-03,  ...,  6.5704e-03,
         -1.5073e-03,  9.1081e-03],
        [ 5.8872e-04, -6.3580e-04,  1.1743e-02,  ..., -3.2710e-03,
         -5.4303e-03,  3.0527e-04]], device='cuda:0')

Parameter Name: base_model.model.layers.19.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[246],
        [102],
        [124],
        ...,
        [105],
        [233],
        [ 97]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.19.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0058,  0.0015, -0.0023,  ...,  0.0015,  0.0045, -0.0079],
        [-0.0118, -0.0208,  0.0099,  ...,  0.0070, -0.0117,  0.0071],
        [-0.0282, -0.0125, -0.0218,  ...,  0.0141, -0.0116,  0.0248],
        ...,
        [ 0.0086, -0.0123,  0.0052,  ..., -0.0120, -0.0080,  0.0022],
        [-0.0064, -0.0109, -0.0022,  ...,  0.0060,  0.0031,  0.0086],
        [-0.0129, -0.0034, -0.0121,  ..., -0.0048, -0.0077, -0.0092]],
       device='cuda:0')

Parameter Name: base_model.model.layers.19.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-9.4753e-03,  1.4077e-02,  2.0454e-02,  ...,  1.5379e-02,
          1.7196e-02, -1.3963e-02],
        [ 8.8869e-03, -8.5490e-03, -3.9617e-03,  ..., -1.1315e-03,
          3.1028e-03,  4.4409e-03],
        [-1.2074e-02, -8.0792e-03, -7.5551e-03,  ..., -1.2189e-02,
         -9.1119e-03, -6.9471e-03],
        ...,
        [ 7.1802e-03,  5.8917e-03,  7.5787e-03,  ...,  1.0616e-02,
          1.1518e-02,  6.4434e-03],
        [ 9.0270e-03,  3.1422e-03,  1.2880e-02,  ...,  9.3122e-03,
          1.4239e-02,  2.4829e-03],
        [-7.0891e-06, -6.7916e-03, -5.2469e-03,  ..., -8.8626e-03,
         -4.0553e-03,  5.0266e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.19.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 29],
        [ 70],
        [199],
        ...,
        [190],
        [233],
        [ 22]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.19.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 1.9170e-02, -2.1166e-02, -1.1524e-02,  ..., -8.7330e-03,
         -1.1925e-02,  7.2314e-03],
        [ 5.8350e-03, -2.1760e-02, -6.8453e-03,  ..., -1.1255e-02,
          7.1938e-03,  2.0991e-02],
        [ 2.8427e-03, -2.5124e-03, -7.8873e-03,  ...,  8.0550e-03,
          1.8225e-03, -6.4995e-03],
        ...,
        [ 2.0708e-03,  3.3236e-02,  7.4503e-04,  ...,  2.5157e-02,
          1.3342e-02, -1.7835e-03],
        [ 8.6720e-03, -1.8177e-02, -1.0747e-02,  ..., -7.6817e-03,
         -1.8142e-03, -4.7567e-03],
        [ 5.1697e-06,  1.4479e-02, -6.9439e-03,  ..., -1.3233e-04,
          7.6683e-04,  6.2094e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.19.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0114, -0.0108, -0.0149,  ...,  0.0084, -0.0078,  0.0077],
        [ 0.0101,  0.0162, -0.0039,  ...,  0.0036, -0.0184, -0.0160],
        [ 0.0038,  0.0038,  0.0049,  ...,  0.0058,  0.0044, -0.0030],
        ...,
        [ 0.0103,  0.0087, -0.0055,  ...,  0.0021, -0.0104, -0.0093],
        [-0.0071, -0.0020, -0.0028,  ...,  0.0004, -0.0126,  0.0041],
        [-0.0138, -0.0085,  0.0006,  ...,  0.0160, -0.0107,  0.0041]],
       device='cuda:0')

Parameter Name: base_model.model.layers.19.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[237],
        [110],
        [ 25],
        ...,
        [ 37],
        [225],
        [102]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.19.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[-0.0082,  0.0177, -0.0037,  ...,  0.0004,  0.0234, -0.0002],
        [-0.0063, -0.0080,  0.0011,  ...,  0.0047, -0.0005,  0.0080],
        [ 0.0030, -0.0201, -0.0002,  ...,  0.0008, -0.0219,  0.0085],
        ...,
        [-0.0035, -0.0184,  0.0048,  ...,  0.0199, -0.0262,  0.0005],
        [ 0.0031, -0.0168,  0.0065,  ..., -0.0061, -0.0416, -0.0101],
        [-0.0087, -0.0183,  0.0031,  ...,  0.0076, -0.0222, -0.0015]],
       device='cuda:0')

Parameter Name: base_model.model.layers.19.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0052, -0.0073, -0.0097,  ..., -0.0218,  0.0029,  0.0035],
        [ 0.0027,  0.0055, -0.0139,  ..., -0.0052, -0.0011,  0.0022],
        [ 0.0104, -0.0136, -0.0141,  ..., -0.0256, -0.0119, -0.0156],
        ...,
        [ 0.0088,  0.0157,  0.0166,  ...,  0.0097,  0.0049,  0.0120],
        [ 0.0129,  0.0092,  0.0094,  ...,  0.0084,  0.0135,  0.0066],
        [-0.0015, -0.0091, -0.0210,  ..., -0.0012, -0.0027, -0.0146]],
       device='cuda:0')

Parameter Name: base_model.model.layers.19.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4512, 0.4570, 0.4375,  ..., 0.4258, 0.4336, 0.4375], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.19.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.3535, 0.3398, 0.3418,  ..., 0.3496, 0.3496, 0.3477], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.20.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 31],
        [ 45],
        [ 94],
        ...,
        [ 99],
        [ 79],
        [233]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.20.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0138, -0.0020, -0.0086,  ...,  0.0102,  0.0088,  0.0006],
        [-0.0022,  0.0102, -0.0044,  ...,  0.0024,  0.0152,  0.0143],
        [ 0.0030, -0.0003,  0.0041,  ...,  0.0214,  0.0054,  0.0019],
        ...,
        [ 0.0068, -0.0256, -0.0024,  ...,  0.0366,  0.0120,  0.0026],
        [-0.0020, -0.0131,  0.0064,  ..., -0.0017, -0.0045, -0.0112],
        [ 0.0084,  0.0203,  0.0206,  ..., -0.0179,  0.0163, -0.0080]],
       device='cuda:0')

Parameter Name: base_model.model.layers.20.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0105, -0.0093,  0.0049,  ...,  0.0023,  0.0112, -0.0114],
        [-0.0108,  0.0100, -0.0104,  ..., -0.0116, -0.0092,  0.0089],
        [-0.0033,  0.0021, -0.0107,  ..., -0.0122, -0.0027,  0.0015],
        ...,
        [ 0.0075, -0.0057,  0.0124,  ...,  0.0123,  0.0083, -0.0077],
        [ 0.0089, -0.0082,  0.0169,  ...,  0.0159,  0.0100, -0.0088],
        [-0.0044,  0.0040, -0.0120,  ..., -0.0124, -0.0052,  0.0038]],
       device='cuda:0')

Parameter Name: base_model.model.layers.20.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[231],
        [ 93],
        [158],
        ...,
        [105],
        [164],
        [194]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.20.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[236],
        [ 65],
        [209],
        ...,
        [117],
        [238],
        [251]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.20.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0224, -0.0086,  0.0019,  ..., -0.0131,  0.0115, -0.0069],
        [ 0.0029,  0.0187, -0.0037,  ..., -0.0173,  0.0182,  0.0004],
        [-0.0152,  0.0148,  0.0310,  ...,  0.0021, -0.0065,  0.0021],
        ...,
        [-0.0041,  0.0182, -0.0187,  ..., -0.0002, -0.0156, -0.0078],
        [-0.0071, -0.0174, -0.0008,  ...,  0.0023, -0.0037,  0.0171],
        [-0.0199,  0.0298, -0.0119,  ...,  0.0057,  0.0148, -0.0101]],
       device='cuda:0')

Parameter Name: base_model.model.layers.20.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0050, -0.0107, -0.0024,  ...,  0.0001,  0.0033, -0.0124],
        [ 0.0109,  0.0086, -0.0072,  ...,  0.0031, -0.0039,  0.0063],
        [-0.0024,  0.0099,  0.0065,  ..., -0.0014, -0.0066,  0.0104],
        ...,
        [ 0.0071,  0.0176, -0.0002,  ...,  0.0253, -0.0224,  0.0102],
        [ 0.0132, -0.0058,  0.0034,  ..., -0.0051,  0.0066, -0.0053],
        [ 0.0058, -0.0047, -0.0051,  ..., -0.0035,  0.0037, -0.0042]],
       device='cuda:0')

Parameter Name: base_model.model.layers.20.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 97],
        [ 46],
        [102],
        ...,
        [ 30],
        [212],
        [215]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.20.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0162,  0.0083, -0.0305,  ...,  0.0139,  0.0169, -0.0214],
        [ 0.0157, -0.0017,  0.0075,  ...,  0.0305, -0.0152,  0.0042],
        [ 0.0036, -0.0058,  0.0208,  ..., -0.0077, -0.0164,  0.0151],
        ...,
        [-0.0310, -0.0057,  0.0081,  ...,  0.0173,  0.0085, -0.0043],
        [ 0.0016, -0.0130,  0.0314,  ..., -0.0092, -0.0165,  0.0215],
        [ 0.0075, -0.0211,  0.0185,  ...,  0.0106, -0.0084,  0.0076]],
       device='cuda:0')

Parameter Name: base_model.model.layers.20.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0052, -0.0219,  0.0021,  ..., -0.0123,  0.0077, -0.0045],
        [ 0.0010, -0.0028, -0.0045,  ..., -0.0042,  0.0067, -0.0017],
        [ 0.0123,  0.0032, -0.0046,  ...,  0.0241, -0.0162, -0.0160],
        ...,
        [-0.0041, -0.0113,  0.0059,  ..., -0.0032, -0.0047, -0.0008],
        [-0.0015, -0.0036, -0.0005,  ..., -0.0022, -0.0062, -0.0045],
        [ 0.0108, -0.0014, -0.0103,  ...,  0.0035, -0.0093, -0.0015]],
       device='cuda:0')

Parameter Name: base_model.model.layers.20.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 30],
        [214],
        [148],
        ...,
        [186],
        [ 17],
        [222]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.20.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0136,  0.0046, -0.0118,  ..., -0.0003, -0.0214, -0.0059],
        [-0.0227,  0.0023,  0.0200,  ..., -0.0090,  0.0163, -0.0242],
        [-0.0027, -0.0247,  0.0144,  ..., -0.0144, -0.0314, -0.0341],
        ...,
        [-0.0071, -0.0133, -0.0314,  ..., -0.0211, -0.0041, -0.0286],
        [-0.0205,  0.0004, -0.0036,  ...,  0.0188,  0.0242, -0.0155],
        [-0.0072, -0.0105, -0.0178,  ...,  0.0100,  0.0061, -0.0443]],
       device='cuda:0')

Parameter Name: base_model.model.layers.20.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0067,  0.0029, -0.0028,  ...,  0.0011,  0.0044,  0.0040],
        [ 0.0010, -0.0101,  0.0003,  ...,  0.0082,  0.0002, -0.0131],
        [-0.0044, -0.0021, -0.0014,  ..., -0.0028, -0.0078,  0.0033],
        ...,
        [-0.0079,  0.0093, -0.0048,  ...,  0.0018, -0.0011,  0.0120],
        [-0.0107,  0.0073, -0.0047,  ...,  0.0033,  0.0064,  0.0247],
        [ 0.0082, -0.0113, -0.0102,  ..., -0.0183, -0.0058, -0.0070]],
       device='cuda:0')

Parameter Name: base_model.model.layers.20.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[185],
        [ 17],
        [233],
        ...,
        [205],
        [ 63],
        [206]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.20.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0005,  0.0127,  0.0168,  ..., -0.0038,  0.0052, -0.0004],
        [-0.0111,  0.0221,  0.0029,  ..., -0.0155,  0.0123,  0.0048],
        [ 0.0033, -0.0081, -0.0076,  ...,  0.0034, -0.0030, -0.0121],
        ...,
        [-0.0037,  0.0135, -0.0093,  ...,  0.0122,  0.0103, -0.0168],
        [ 0.0183, -0.0185,  0.0146,  ..., -0.0145, -0.0155, -0.0063],
        [ 0.0046,  0.0145, -0.0025,  ...,  0.0109,  0.0046, -0.0062]],
       device='cuda:0')

Parameter Name: base_model.model.layers.20.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 3.8256e-03,  5.5708e-03, -5.5049e-03,  ..., -2.7482e-02,
          5.6960e-04, -1.3268e-02],
        [-8.6726e-03,  2.2617e-03, -8.1515e-04,  ...,  5.7187e-03,
         -4.9293e-03,  4.5815e-03],
        [ 1.7167e-02,  1.2862e-02, -4.5240e-03,  ...,  5.9631e-05,
         -1.6000e-02,  2.0465e-03],
        ...,
        [-1.5419e-03,  1.4406e-03,  7.2363e-03,  ..., -1.1490e-02,
          1.8953e-02, -1.2311e-02],
        [ 4.5327e-03, -7.3374e-03, -4.7382e-03,  ..., -1.4235e-02,
          4.4760e-03, -1.0206e-02],
        [-7.4373e-03,  1.1889e-02,  4.1893e-04,  ...,  7.3359e-03,
          8.6169e-03, -2.2332e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.20.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[149],
        [158],
        [105],
        ...,
        [110],
        [ 57],
        [254]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.20.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 0.0300,  0.0087,  0.0169,  ..., -0.0253, -0.0161, -0.0015],
        [-0.0273,  0.0116,  0.0145,  ...,  0.0203, -0.0018, -0.0037],
        [ 0.0173, -0.0053, -0.0089,  ..., -0.0094, -0.0061, -0.0153],
        ...,
        [-0.0119, -0.0039, -0.0261,  ...,  0.0084,  0.0044, -0.0152],
        [-0.0110, -0.0095, -0.0123,  ..., -0.0013,  0.0053,  0.0083],
        [-0.0045,  0.0024, -0.0063,  ...,  0.0051, -0.0116,  0.0034]],
       device='cuda:0')

Parameter Name: base_model.model.layers.20.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 8.0132e-04,  2.0335e-03,  5.1110e-04,  ...,  3.3743e-03,
          1.1914e-02, -4.8186e-03],
        [ 4.9951e-03,  4.6355e-03, -5.3993e-03,  ...,  2.9768e-03,
         -2.1028e-03, -2.3739e-04],
        [ 3.2123e-03,  7.2282e-04, -2.3818e-05,  ..., -1.0140e-03,
          2.8891e-03, -9.5415e-03],
        ...,
        [-1.9443e-03, -1.2313e-02,  9.8263e-03,  ..., -4.2965e-03,
         -4.8369e-03, -2.5333e-03],
        [ 6.0757e-03,  2.0661e-03,  1.2222e-02,  ..., -1.3290e-02,
         -2.2387e-02, -1.5907e-02],
        [ 1.0020e-02,  5.2028e-03,  2.6207e-04,  ...,  9.4120e-03,
          4.8015e-03,  1.5012e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.20.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4531, 0.4668, 0.4375,  ..., 0.4336, 0.4336, 0.4473], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.20.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.3633, 0.3574, 0.3516,  ..., 0.3633, 0.3613, 0.3574], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.21.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[174],
        [ 84],
        [234],
        ...,
        [247],
        [254],
        [125]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.21.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0016,  0.0051,  0.0022,  ...,  0.0008, -0.0125, -0.0052],
        [ 0.0111,  0.0009,  0.0147,  ...,  0.0070,  0.0046,  0.0142],
        [-0.0071, -0.0119, -0.0031,  ...,  0.0196,  0.0043, -0.0212],
        ...,
        [-0.0092, -0.0003, -0.0113,  ..., -0.0100, -0.0085, -0.0276],
        [-0.0092,  0.0120,  0.0131,  ..., -0.0031, -0.0111,  0.0195],
        [-0.0241,  0.0054, -0.0151,  ...,  0.0113, -0.0057, -0.0266]],
       device='cuda:0')

Parameter Name: base_model.model.layers.21.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-1.0587e-03, -5.2121e-03,  6.6511e-03,  ...,  5.9779e-03,
         -4.7285e-03,  2.5749e-03],
        [-6.3238e-04, -1.2314e-02,  1.2701e-02,  ...,  1.0730e-02,
         -1.0391e-02,  7.2479e-03],
        [ 2.7948e-02, -1.8643e-02,  2.3371e-02,  ...,  2.0353e-02,
         -1.9876e-02,  2.2264e-02],
        ...,
        [-1.0671e-03, -2.3627e-03,  2.4349e-03,  ...,  8.7480e-04,
         -5.0941e-04,  2.1548e-03],
        [-9.8991e-04,  3.9800e-05,  4.8753e-03,  ...,  2.7595e-03,
         -1.9017e-03,  3.3638e-03],
        [ 1.4007e-02,  2.0867e-02, -2.1327e-02,  ..., -2.0963e-02,
          2.0683e-02, -1.9286e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.21.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[100],
        [ 98],
        [ 41],
        ...,
        [110],
        [ 81],
        [195]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.21.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 22],
        [158],
        [237],
        ...,
        [172],
        [102],
        [241]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.21.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0290,  0.0133, -0.0127,  ...,  0.0064,  0.0087,  0.0032],
        [-0.0214, -0.0167, -0.0027,  ..., -0.0051,  0.0009, -0.0143],
        [-0.0141,  0.0216,  0.0004,  ...,  0.0046,  0.0294,  0.0116],
        ...,
        [-0.0274, -0.0187,  0.0058,  ..., -0.0056,  0.0044, -0.0151],
        [-0.0117,  0.0076, -0.0190,  ..., -0.0133,  0.0111,  0.0014],
        [ 0.0180,  0.0134,  0.0273,  ..., -0.0209, -0.0114, -0.0088]],
       device='cuda:0')

Parameter Name: base_model.model.layers.21.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 5.1134e-03, -9.7136e-03, -3.6217e-03,  ...,  2.7957e-03,
          1.1951e-02,  6.2614e-05],
        [ 3.0447e-03,  1.6095e-02,  4.5891e-03,  ...,  6.1407e-04,
          2.7069e-03,  1.7987e-03],
        [ 1.8124e-02, -7.3108e-03,  2.5031e-03,  ..., -9.3778e-03,
          1.5430e-02, -7.2663e-03],
        ...,
        [-7.9377e-03,  3.4065e-03,  4.0815e-04,  ..., -4.6134e-03,
         -7.2159e-03,  6.3203e-03],
        [ 9.9495e-03, -5.2911e-03,  2.0023e-03,  ..., -2.0153e-02,
          1.2887e-02, -2.6060e-03],
        [-5.1427e-04,  6.8005e-03,  5.6015e-03,  ...,  1.1844e-02,
         -5.7542e-03,  5.3341e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.21.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[249],
        [121],
        [149],
        ...,
        [223],
        [114],
        [198]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.21.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0109,  0.0060, -0.0012,  ..., -0.0139,  0.0206, -0.0172],
        [-0.0240,  0.0022, -0.0221,  ...,  0.0144, -0.0168, -0.0024],
        [ 0.0061, -0.0160,  0.0024,  ..., -0.0011, -0.0012,  0.0142],
        ...,
        [ 0.0171, -0.0170, -0.0007,  ..., -0.0210, -0.0192,  0.0218],
        [ 0.0166,  0.0110,  0.0136,  ...,  0.0187, -0.0064, -0.0189],
        [ 0.0076,  0.0101,  0.0168,  ...,  0.0097, -0.0003,  0.0352]],
       device='cuda:0')

Parameter Name: base_model.model.layers.21.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0096, -0.0027,  0.0012,  ...,  0.0087, -0.0083, -0.0022],
        [ 0.0112,  0.0019,  0.0059,  ..., -0.0054,  0.0095,  0.0144],
        [-0.0049,  0.0073,  0.0125,  ...,  0.0162,  0.0077,  0.0153],
        ...,
        [-0.0091,  0.0002,  0.0082,  ...,  0.0029, -0.0151, -0.0148],
        [ 0.0149,  0.0040,  0.0093,  ...,  0.0076, -0.0125, -0.0043],
        [-0.0029,  0.0080, -0.0035,  ..., -0.0155,  0.0009, -0.0086]],
       device='cuda:0')

Parameter Name: base_model.model.layers.21.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[157],
        [125],
        [127],
        ...,
        [177],
        [220],
        [ 22]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.21.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0166,  0.0039, -0.0105,  ..., -0.0104, -0.0007,  0.0085],
        [-0.0086, -0.0132, -0.0077,  ...,  0.0083, -0.0087,  0.0084],
        [ 0.0150,  0.0206, -0.0059,  ...,  0.0017,  0.0084,  0.0002],
        ...,
        [ 0.0007, -0.0207, -0.0070,  ...,  0.0065, -0.0041, -0.0094],
        [-0.0157, -0.0165,  0.0036,  ..., -0.0075,  0.0111, -0.0131],
        [ 0.0038,  0.0054,  0.0050,  ..., -0.0218,  0.0004,  0.0070]],
       device='cuda:0')

Parameter Name: base_model.model.layers.21.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0009, -0.0199,  0.0183,  ..., -0.0176,  0.0037,  0.0056],
        [ 0.0016, -0.0051,  0.0111,  ..., -0.0072,  0.0076,  0.0138],
        [ 0.0025, -0.0061, -0.0092,  ..., -0.0087,  0.0023,  0.0023],
        ...,
        [ 0.0091,  0.0079,  0.0077,  ...,  0.0018, -0.0135, -0.0078],
        [-0.0175, -0.0029,  0.0108,  ..., -0.0158, -0.0110,  0.0200],
        [ 0.0140, -0.0163,  0.0016,  ..., -0.0002, -0.0016, -0.0069]],
       device='cuda:0')

Parameter Name: base_model.model.layers.21.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 42],
        [217],
        [ 86],
        ...,
        [174],
        [ 30],
        [234]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.21.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0233,  0.0102,  0.0062,  ..., -0.0029, -0.0035,  0.0231],
        [ 0.0051, -0.0017, -0.0197,  ...,  0.0081,  0.0063, -0.0025],
        [ 0.0232, -0.0155, -0.0067,  ..., -0.0082, -0.0195, -0.0086],
        ...,
        [ 0.0029,  0.0056, -0.0234,  ..., -0.0045,  0.0038, -0.0047],
        [ 0.0073, -0.0060, -0.0220,  ..., -0.0185, -0.0025, -0.0063],
        [ 0.0152,  0.0133,  0.0039,  ..., -0.0197, -0.0318,  0.0053]],
       device='cuda:0')

Parameter Name: base_model.model.layers.21.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0292, -0.0138, -0.0174,  ..., -0.0260, -0.0166, -0.0029],
        [ 0.0010,  0.0005,  0.0096,  ..., -0.0089,  0.0090, -0.0065],
        [ 0.0051, -0.0003, -0.0077,  ..., -0.0120,  0.0005,  0.0080],
        ...,
        [-0.0027, -0.0092,  0.0043,  ...,  0.0006, -0.0135, -0.0018],
        [ 0.0055, -0.0149, -0.0106,  ..., -0.0172, -0.0001, -0.0200],
        [-0.0157, -0.0075, -0.0007,  ...,  0.0002,  0.0048, -0.0038]],
       device='cuda:0')

Parameter Name: base_model.model.layers.21.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[116],
        [145],
        [ 98],
        ...,
        [212],
        [159],
        [ 77]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.21.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[-0.0141,  0.0027,  0.0108,  ...,  0.0258,  0.0092,  0.0012],
        [-0.0128, -0.0080,  0.0103,  ...,  0.0037, -0.0020,  0.0109],
        [-0.0193,  0.0091, -0.0020,  ..., -0.0004, -0.0070, -0.0007],
        ...,
        [-0.0282,  0.0013,  0.0062,  ...,  0.0220, -0.0176,  0.0026],
        [ 0.0131, -0.0221,  0.0068,  ..., -0.0113,  0.0061, -0.0084],
        [ 0.0331, -0.0090, -0.0069,  ..., -0.0204, -0.0012, -0.0023]],
       device='cuda:0')

Parameter Name: base_model.model.layers.21.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0046, -0.0068,  0.0141,  ...,  0.0139, -0.0154, -0.0108],
        [ 0.0030,  0.0018,  0.0045,  ..., -0.0077,  0.0043,  0.0015],
        [ 0.0117, -0.0005,  0.0014,  ...,  0.0099, -0.0148, -0.0072],
        ...,
        [ 0.0068,  0.0141,  0.0132,  ...,  0.0045,  0.0018,  0.0004],
        [-0.0007,  0.0115, -0.0042,  ...,  0.0009, -0.0021, -0.0049],
        [ 0.0074, -0.0034, -0.0005,  ...,  0.0050,  0.0085, -0.0008]],
       device='cuda:0')

Parameter Name: base_model.model.layers.21.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4785, 0.4863, 0.4688,  ..., 0.4551, 0.4707, 0.4766], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.21.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.3730, 0.3691, 0.3633,  ..., 0.3789, 0.3711, 0.3730], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.22.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[207],
        [236],
        [167],
        ...,
        [102],
        [109],
        [103]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.22.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0182,  0.0002, -0.0114,  ...,  0.0058,  0.0012,  0.0047],
        [-0.0235,  0.0109, -0.0030,  ...,  0.0183,  0.0152,  0.0218],
        [-0.0078,  0.0109, -0.0056,  ...,  0.0042,  0.0177,  0.0154],
        ...,
        [ 0.0118, -0.0065, -0.0055,  ..., -0.0279,  0.0025,  0.0209],
        [-0.0230,  0.0150, -0.0092,  ...,  0.0067, -0.0187, -0.0149],
        [-0.0085, -0.0067, -0.0098,  ...,  0.0125,  0.0425,  0.0102]],
       device='cuda:0')

Parameter Name: base_model.model.layers.22.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0043, -0.0050, -0.0014,  ..., -0.0138,  0.0103, -0.0100],
        [ 0.0021,  0.0096,  0.0070,  ..., -0.0099, -0.0025,  0.0039],
        [ 0.0065,  0.0035,  0.0008,  ..., -0.0097,  0.0043, -0.0015],
        ...,
        [ 0.0039, -0.0034, -0.0010,  ..., -0.0014,  0.0020, -0.0005],
        [-0.0058, -0.0033, -0.0012,  ...,  0.0083, -0.0042,  0.0011],
        [-0.0007,  0.0064,  0.0079,  ...,  0.0072, -0.0090,  0.0081]],
       device='cuda:0')

Parameter Name: base_model.model.layers.22.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[201],
        [233],
        [233],
        ...,
        [ 58],
        [148],
        [198]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.22.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[198],
        [151],
        [ 52],
        ...,
        [102],
        [102],
        [  2]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.22.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0306,  0.0177, -0.0135,  ...,  0.0050, -0.0273, -0.0135],
        [-0.0191, -0.0170,  0.0102,  ...,  0.0047,  0.0211,  0.0108],
        [ 0.0054,  0.0187, -0.0027,  ...,  0.0052, -0.0341, -0.0356],
        ...,
        [ 0.0209, -0.0158, -0.0066,  ..., -0.0157, -0.0043, -0.0110],
        [-0.0071,  0.0053, -0.0041,  ...,  0.0011,  0.0215,  0.0152],
        [ 0.0041,  0.0113,  0.0124,  ..., -0.0152, -0.0291, -0.0214]],
       device='cuda:0')

Parameter Name: base_model.model.layers.22.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-7.1737e-04,  1.0763e-02, -9.8312e-03,  ...,  7.2501e-03,
          6.8619e-03, -8.1943e-03],
        [ 1.0606e-02, -4.5446e-03,  7.6782e-03,  ...,  1.1479e-03,
         -9.4547e-03,  7.0987e-03],
        [ 1.2564e-03, -8.9392e-03,  6.4745e-03,  ..., -5.8662e-03,
         -4.8465e-03,  9.0684e-03],
        ...,
        [-4.6951e-03,  4.0344e-03, -5.2844e-03,  ...,  1.2715e-02,
          7.8079e-03, -7.5908e-03],
        [-4.1492e-03,  8.1875e-03, -4.3978e-03,  ...,  1.4976e-02,
          3.8605e-03, -9.8192e-03],
        [-1.1550e-03, -2.4255e-03,  1.5504e-03,  ..., -2.6116e-03,
          1.1876e-03, -6.9950e-05]], device='cuda:0')

Parameter Name: base_model.model.layers.22.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 87],
        [206],
        [ 70],
        ...,
        [ 97],
        [118],
        [119]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.22.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0081,  0.0085, -0.0061,  ...,  0.0017,  0.0095, -0.0107],
        [ 0.0046,  0.0070,  0.0067,  ...,  0.0123, -0.0185,  0.0031],
        [-0.0137,  0.0043, -0.0007,  ..., -0.0148,  0.0020, -0.0010],
        ...,
        [-0.0082,  0.0047, -0.0039,  ...,  0.0014, -0.0020, -0.0169],
        [ 0.0183, -0.0021, -0.0187,  ...,  0.0004, -0.0173, -0.0009],
        [ 0.0039, -0.0139, -0.0010,  ..., -0.0217,  0.0142,  0.0079]],
       device='cuda:0')

Parameter Name: base_model.model.layers.22.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 8.9917e-04, -4.4687e-03, -4.0260e-03,  ..., -9.8214e-05,
          2.0480e-03,  1.2015e-02],
        [ 7.8795e-04,  9.3047e-03, -4.4354e-03,  ..., -6.4832e-03,
          1.1000e-02,  2.0750e-02],
        [-2.3352e-03,  6.0308e-04,  1.8467e-03,  ..., -5.6663e-03,
         -1.1956e-02,  2.0925e-03],
        ...,
        [ 1.1288e-02,  1.8750e-03,  2.2685e-03,  ...,  1.3306e-02,
         -2.3013e-02, -1.0647e-02],
        [ 7.9276e-03, -1.4291e-02,  1.1043e-02,  ...,  5.7615e-03,
         -5.5311e-03,  3.8318e-03],
        [-2.9881e-03,  6.0149e-03, -6.7192e-03,  ...,  3.7701e-03,
          7.4616e-03,  7.3329e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.22.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[255],
        [ 76],
        [204],
        ...,
        [158],
        [ 31],
        [ 68]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.22.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0056, -0.0259,  0.0002,  ...,  0.0112,  0.0250,  0.0083],
        [-0.0059,  0.0187, -0.0105,  ...,  0.0242,  0.0207, -0.0236],
        [-0.0041,  0.0079, -0.0197,  ..., -0.0146, -0.0110,  0.0024],
        ...,
        [-0.0183,  0.0112, -0.0157,  ..., -0.0018,  0.0009, -0.0180],
        [-0.0019,  0.0176, -0.0043,  ...,  0.0028, -0.0132,  0.0149],
        [ 0.0167,  0.0091, -0.0232,  ..., -0.0290, -0.0013,  0.0115]],
       device='cuda:0')

Parameter Name: base_model.model.layers.22.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0069, -0.0035, -0.0170,  ...,  0.0009,  0.0117, -0.0060],
        [ 0.0050,  0.0057, -0.0041,  ...,  0.0100,  0.0101,  0.0002],
        [ 0.0162,  0.0078,  0.0203,  ..., -0.0018, -0.0032,  0.0122],
        ...,
        [-0.0056,  0.0052,  0.0077,  ..., -0.0045,  0.0049,  0.0011],
        [ 0.0223, -0.0069,  0.0122,  ...,  0.0017, -0.0177,  0.0202],
        [ 0.0058,  0.0027,  0.0285,  ...,  0.0191,  0.0019,  0.0181]],
       device='cuda:0')

Parameter Name: base_model.model.layers.22.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 37],
        [ 28],
        [ 82],
        ...,
        [237],
        [202],
        [183]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.22.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0027, -0.0260,  0.0130,  ..., -0.0077, -0.0023, -0.0214],
        [ 0.0167,  0.0235, -0.0158,  ...,  0.0148,  0.0090,  0.0263],
        [ 0.0157,  0.0206,  0.0229,  ...,  0.0026,  0.0027,  0.0144],
        ...,
        [-0.0026, -0.0076, -0.0037,  ...,  0.0274, -0.0107,  0.0057],
        [-0.0211, -0.0323,  0.0107,  ..., -0.0113, -0.0048,  0.0067],
        [-0.0205, -0.0152,  0.0113,  ..., -0.0053,  0.0165,  0.0160]],
       device='cuda:0')

Parameter Name: base_model.model.layers.22.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-6.9755e-03,  4.9567e-04,  3.6881e-03,  ...,  1.5758e-02,
         -4.4700e-03,  6.5078e-03],
        [ 7.9924e-04,  3.9805e-03,  2.7012e-03,  ..., -5.6398e-03,
         -7.1868e-03,  2.9217e-03],
        [ 2.2505e-02, -1.4144e-02,  4.1313e-03,  ..., -2.1714e-02,
          8.9848e-03, -1.0297e-02],
        ...,
        [ 9.7135e-04, -8.6916e-03, -3.4534e-03,  ..., -9.8637e-05,
         -1.0987e-02, -1.1579e-02],
        [-3.8872e-03,  4.8090e-03, -3.9610e-03,  ..., -7.6460e-03,
         -8.0436e-03,  1.0724e-02],
        [-2.6137e-03, -8.8617e-04, -6.4025e-03,  ..., -6.9985e-03,
         -8.4693e-03, -2.9213e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.22.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[126],
        [118],
        [197],
        ...,
        [ 86],
        [201],
        [214]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.22.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 0.0114,  0.0117,  0.0183,  ..., -0.0234, -0.0092, -0.0026],
        [ 0.0073, -0.0072,  0.0081,  ..., -0.0068, -0.0050, -0.0135],
        [-0.0004,  0.0144, -0.0141,  ...,  0.0084,  0.0153,  0.0125],
        ...,
        [-0.0052,  0.0071, -0.0013,  ...,  0.0054,  0.0034, -0.0072],
        [ 0.0147, -0.0076,  0.0015,  ..., -0.0067,  0.0032, -0.0008],
        [ 0.0142, -0.0042,  0.0288,  ..., -0.0146, -0.0047, -0.0044]],
       device='cuda:0')

Parameter Name: base_model.model.layers.22.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0085,  0.0019,  0.0031,  ...,  0.0089, -0.0156,  0.0181],
        [ 0.0096,  0.0129,  0.0121,  ...,  0.0138, -0.0001,  0.0043],
        [-0.0067, -0.0012,  0.0084,  ..., -0.0076, -0.0103,  0.0113],
        ...,
        [-0.0044, -0.0053,  0.0053,  ...,  0.0066, -0.0067, -0.0102],
        [-0.0025, -0.0192, -0.0255,  ..., -0.0157,  0.0166, -0.0111],
        [ 0.0096,  0.0115, -0.0004,  ...,  0.0098,  0.0058,  0.0039]],
       device='cuda:0')

Parameter Name: base_model.model.layers.22.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4863, 0.4863, 0.4746,  ..., 0.4688, 0.4863, 0.4863], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.22.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.3848, 0.3809, 0.3828,  ..., 0.3926, 0.3867, 0.3887], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.23.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[109],
        [ 18],
        [117],
        ...,
        [126],
        [246],
        [ 94]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.23.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0205, -0.0136,  0.0053,  ..., -0.0015,  0.0048,  0.0072],
        [-0.0280,  0.0110,  0.0169,  ..., -0.0124, -0.0108, -0.0057],
        [-0.0063,  0.0115,  0.0191,  ...,  0.0054,  0.0004,  0.0058],
        ...,
        [-0.0119, -0.0141,  0.0235,  ..., -0.0137, -0.0193,  0.0055],
        [-0.0040, -0.0007,  0.0141,  ...,  0.0005,  0.0098,  0.0022],
        [-0.0033,  0.0134,  0.0095,  ..., -0.0083, -0.0137,  0.0062]],
       device='cuda:0')

Parameter Name: base_model.model.layers.23.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0053,  0.0045,  0.0016,  ...,  0.0053, -0.0065,  0.0065],
        [-0.0113,  0.0110,  0.0108,  ...,  0.0130, -0.0098,  0.0121],
        [-0.0081,  0.0049,  0.0012,  ...,  0.0051, -0.0053,  0.0063],
        ...,
        [-0.0044,  0.0010,  0.0009,  ...,  0.0004,  0.0018,  0.0017],
        [-0.0226,  0.0187,  0.0137,  ...,  0.0217,  0.0080,  0.0234],
        [-0.0088,  0.0110,  0.0102,  ...,  0.0047,  0.0075,  0.0052]],
       device='cuda:0')

Parameter Name: base_model.model.layers.23.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[151],
        [103],
        [ 98],
        ...,
        [ 91],
        [ 33],
        [ 30]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.23.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 21],
        [153],
        [ 23],
        ...,
        [105],
        [166],
        [106]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.23.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 4.7001e-03, -1.4624e-02,  5.1745e-03,  ..., -6.2550e-03,
          1.6723e-02,  5.7420e-05],
        [-1.1144e-02,  7.7100e-03, -7.0927e-03,  ...,  3.1384e-02,
         -3.4008e-02,  1.6115e-02],
        [-4.8068e-04,  4.6853e-03,  1.3159e-03,  ..., -1.1286e-02,
         -1.5780e-02, -5.5405e-03],
        ...,
        [-2.1333e-03, -4.8633e-03,  1.0821e-02,  ..., -2.0093e-02,
          4.3470e-02, -2.7843e-03],
        [-1.4462e-03, -4.3272e-03,  1.5818e-02,  ...,  1.1316e-02,
         -9.5721e-03, -1.1310e-02],
        [ 8.3449e-03, -4.8563e-03,  4.1524e-03,  ...,  6.8521e-03,
         -2.9255e-02,  1.1278e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.23.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0102, -0.0007,  0.0014,  ..., -0.0054,  0.0076,  0.0063],
        [-0.0238,  0.0258,  0.0054,  ..., -0.0208,  0.0148,  0.0277],
        [ 0.0108,  0.0015,  0.0063,  ...,  0.0130, -0.0039, -0.0079],
        ...,
        [-0.0022,  0.0083, -0.0018,  ..., -0.0068,  0.0066,  0.0069],
        [ 0.0117, -0.0118,  0.0087,  ...,  0.0128, -0.0038, -0.0021],
        [-0.0063,  0.0061, -0.0034,  ..., -0.0019,  0.0045,  0.0039]],
       device='cuda:0')

Parameter Name: base_model.model.layers.23.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[238],
        [198],
        [107],
        ...,
        [111],
        [110],
        [141]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.23.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0085, -0.0133,  0.0145,  ...,  0.0228,  0.0172,  0.0009],
        [-0.0042,  0.0268,  0.0041,  ...,  0.0046, -0.0125,  0.0204],
        [ 0.0170,  0.0025, -0.0046,  ..., -0.0142,  0.0014, -0.0017],
        ...,
        [ 0.0154,  0.0018,  0.0235,  ...,  0.0116,  0.0020,  0.0079],
        [-0.0024,  0.0080,  0.0119,  ..., -0.0202, -0.0211,  0.0016],
        [ 0.0026, -0.0024,  0.0176,  ..., -0.0041,  0.0137, -0.0325]],
       device='cuda:0')

Parameter Name: base_model.model.layers.23.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 3.9716e-03,  2.0728e-02,  2.6930e-04,  ..., -1.6561e-02,
          1.4121e-02,  7.3735e-05],
        [-3.1769e-03, -7.0841e-03,  8.6559e-03,  ...,  7.8416e-03,
          8.2672e-03, -1.1911e-02],
        [-3.4703e-03, -1.9366e-02,  1.3876e-03,  ..., -1.0851e-02,
          2.6020e-03,  6.6425e-03],
        ...,
        [-1.6875e-03, -1.3900e-03, -2.0625e-02,  ..., -1.7184e-02,
         -1.8646e-02, -3.1934e-03],
        [-1.2856e-02,  4.9051e-03,  8.7860e-04,  ..., -8.7475e-03,
         -2.8830e-03,  2.2188e-03],
        [-1.3591e-02,  5.9324e-03,  1.8531e-03,  ..., -1.3068e-02,
          2.7601e-03, -1.8689e-04]], device='cuda:0')

Parameter Name: base_model.model.layers.23.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[229],
        [159],
        [ 17],
        ...,
        [151],
        [254],
        [ 30]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.23.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0028, -0.0061, -0.0167,  ...,  0.0088, -0.0086, -0.0100],
        [ 0.0133,  0.0208, -0.0006,  ..., -0.0016,  0.0004, -0.0018],
        [-0.0018,  0.0095,  0.0182,  ..., -0.0034,  0.0218, -0.0342],
        ...,
        [-0.0006, -0.0017, -0.0158,  ...,  0.0276, -0.0092,  0.0020],
        [ 0.0011,  0.0156, -0.0081,  ..., -0.0079, -0.0029,  0.0297],
        [-0.0063, -0.0150, -0.0152,  ..., -0.0017,  0.0167, -0.0110]],
       device='cuda:0')

Parameter Name: base_model.model.layers.23.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-8.9158e-05, -1.6619e-03, -1.1963e-02,  ...,  4.5299e-03,
         -5.2541e-03,  7.2821e-03],
        [ 2.0864e-02,  3.8157e-03,  5.3289e-03,  ..., -1.2973e-02,
          3.3613e-03, -1.7636e-02],
        [ 8.2744e-03,  3.4002e-03, -2.2356e-03,  ...,  2.7312e-02,
         -1.0622e-02,  9.2265e-03],
        ...,
        [-5.7691e-03, -4.6520e-03, -8.4928e-03,  ...,  1.2640e-02,
         -4.4660e-03, -1.1426e-03],
        [ 5.0896e-03,  4.2219e-04,  2.3124e-02,  ..., -2.8316e-03,
         -7.5949e-03,  6.0568e-03],
        [ 3.9497e-03, -3.5535e-03, -7.1306e-03,  ...,  8.2829e-04,
         -7.8827e-03,  7.3489e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.23.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 87],
        [ 93],
        [238],
        ...,
        [ 89],
        [169],
        [213]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.23.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0138, -0.0089, -0.0063,  ...,  0.0117,  0.0027, -0.0202],
        [-0.0169,  0.0128, -0.0069,  ..., -0.0103, -0.0155, -0.0083],
        [-0.0153,  0.0043,  0.0093,  ...,  0.0016,  0.0049, -0.0012],
        ...,
        [-0.0121,  0.0044, -0.0050,  ...,  0.0103, -0.0100,  0.0003],
        [ 0.0250,  0.0171,  0.0021,  ...,  0.0217,  0.0138,  0.0093],
        [ 0.0094,  0.0119, -0.0106,  ..., -0.0038,  0.0164, -0.0038]],
       device='cuda:0')

Parameter Name: base_model.model.layers.23.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0156, -0.0041, -0.0110,  ...,  0.0124, -0.0218, -0.0089],
        [-0.0059, -0.0074,  0.0030,  ...,  0.0080, -0.0157,  0.0083],
        [ 0.0042, -0.0075, -0.0113,  ...,  0.0010, -0.0064, -0.0150],
        ...,
        [ 0.0042, -0.0034, -0.0044,  ..., -0.0142,  0.0078, -0.0003],
        [-0.0255,  0.0130, -0.0119,  ...,  0.0001,  0.0027, -0.0142],
        [ 0.0036,  0.0155,  0.0125,  ..., -0.0049, -0.0070,  0.0020]],
       device='cuda:0')

Parameter Name: base_model.model.layers.23.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[151],
        [210],
        [230],
        ...,
        [153],
        [223],
        [ 78]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.23.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 0.0066,  0.0051, -0.0160,  ..., -0.0140,  0.0057,  0.0049],
        [-0.0024, -0.0137,  0.0148,  ..., -0.0078, -0.0156, -0.0016],
        [ 0.0054,  0.0002, -0.0207,  ...,  0.0119,  0.0167, -0.0027],
        ...,
        [ 0.0017,  0.0029, -0.0157,  ..., -0.0070, -0.0004, -0.0103],
        [-0.0149, -0.0066,  0.0175,  ...,  0.0019,  0.0074,  0.0028],
        [ 0.0070, -0.0169,  0.0085,  ...,  0.0022, -0.0153,  0.0023]],
       device='cuda:0')

Parameter Name: base_model.model.layers.23.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0044,  0.0020, -0.0057,  ...,  0.0002,  0.0069, -0.0069],
        [ 0.0060, -0.0132, -0.0034,  ...,  0.0148, -0.0083, -0.0052],
        [ 0.0093, -0.0024,  0.0061,  ..., -0.0093,  0.0078,  0.0087],
        ...,
        [-0.0006, -0.0040,  0.0017,  ..., -0.0027, -0.0075, -0.0073],
        [-0.0107,  0.0166, -0.0009,  ..., -0.0108, -0.0135,  0.0065],
        [ 0.0025,  0.0035, -0.0194,  ..., -0.0068, -0.0099,  0.0024]],
       device='cuda:0')

Parameter Name: base_model.model.layers.23.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.5117, 0.5234, 0.5078,  ..., 0.5039, 0.5195, 0.5234], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.23.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4004, 0.3926, 0.3945,  ..., 0.3984, 0.4004, 0.4023], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.24.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 79],
        [102],
        [223],
        ...,
        [103],
        [158],
        [ 67]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.24.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0026, -0.0097,  0.0010,  ..., -0.0120, -0.0233,  0.0046],
        [-0.0084, -0.0020,  0.0297,  ...,  0.0148, -0.0176,  0.0147],
        [ 0.0093, -0.0032,  0.0002,  ...,  0.0090,  0.0263, -0.0038],
        ...,
        [-0.0091, -0.0058, -0.0028,  ..., -0.0103, -0.0351, -0.0041],
        [ 0.0006,  0.0154,  0.0214,  ..., -0.0090, -0.0126,  0.0030],
        [ 0.0190, -0.0019, -0.0258,  ...,  0.0101,  0.0059, -0.0014]],
       device='cuda:0')

Parameter Name: base_model.model.layers.24.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0175,  0.0112, -0.0208,  ...,  0.0187,  0.0153, -0.0144],
        [ 0.0137,  0.0131, -0.0094,  ...,  0.0144,  0.0130, -0.0087],
        [ 0.0081,  0.0103, -0.0049,  ...,  0.0100,  0.0125, -0.0061],
        ...,
        [ 0.0011,  0.0003,  0.0045,  ..., -0.0069, -0.0049,  0.0056],
        [ 0.0148,  0.0162, -0.0229,  ...,  0.0222,  0.0091, -0.0139],
        [ 0.0214,  0.0174, -0.0139,  ...,  0.0151,  0.0181, -0.0115]],
       device='cuda:0')

Parameter Name: base_model.model.layers.24.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 81],
        [225],
        [204],
        ...,
        [ 79],
        [ 65],
        [227]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.24.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 92],
        [233],
        [173],
        ...,
        [ 33],
        [148],
        [254]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.24.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0234,  0.0079,  0.0034,  ..., -0.0197,  0.0072, -0.0198],
        [ 0.0207,  0.0011,  0.0284,  ..., -0.0092, -0.0093,  0.0105],
        [ 0.0012,  0.0080, -0.0049,  ...,  0.0011, -0.0042,  0.0130],
        ...,
        [-0.0182,  0.0122, -0.0308,  ...,  0.0070,  0.0084, -0.0149],
        [ 0.0143,  0.0110,  0.0006,  ..., -0.0268, -0.0014,  0.0101],
        [-0.0249, -0.0067, -0.0141,  ...,  0.0221,  0.0083,  0.0150]],
       device='cuda:0')

Parameter Name: base_model.model.layers.24.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0053,  0.0026,  0.0045,  ..., -0.0071,  0.0046, -0.0042],
        [-0.0051,  0.0066, -0.0075,  ..., -0.0108,  0.0087, -0.0090],
        [ 0.0180,  0.0126,  0.0140,  ..., -0.0062,  0.0102, -0.0200],
        ...,
        [ 0.0176,  0.0139,  0.0129,  ..., -0.0104,  0.0098, -0.0140],
        [-0.0139, -0.0097, -0.0080,  ...,  0.0077, -0.0109,  0.0122],
        [ 0.0145,  0.0045,  0.0078,  ..., -0.0120,  0.0137, -0.0136]],
       device='cuda:0')

Parameter Name: base_model.model.layers.24.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[244],
        [ 90],
        [ 98],
        ...,
        [ 17],
        [150],
        [199]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.24.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0045, -0.0065,  0.0294,  ..., -0.0144, -0.0167,  0.0078],
        [-0.0182, -0.0079,  0.0202,  ..., -0.0221,  0.0120,  0.0070],
        [ 0.0164,  0.0087, -0.0146,  ...,  0.0127, -0.0145,  0.0053],
        ...,
        [-0.0250, -0.0217,  0.0080,  ..., -0.0084,  0.0271,  0.0077],
        [ 0.0038,  0.0355, -0.0102,  ...,  0.0063,  0.0007,  0.0089],
        [ 0.0071,  0.0070, -0.0021,  ...,  0.0021, -0.0066, -0.0151]],
       device='cuda:0')

Parameter Name: base_model.model.layers.24.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0006, -0.0043,  0.0048,  ..., -0.0004, -0.0085, -0.0081],
        [-0.0004,  0.0062,  0.0024,  ...,  0.0111, -0.0138, -0.0177],
        [-0.0020,  0.0125, -0.0085,  ...,  0.0060, -0.0034,  0.0114],
        ...,
        [ 0.0135,  0.0081, -0.0083,  ...,  0.0021,  0.0040, -0.0018],
        [ 0.0004,  0.0104,  0.0059,  ...,  0.0176,  0.0025, -0.0077],
        [ 0.0065,  0.0051, -0.0147,  ...,  0.0023,  0.0073, -0.0060]],
       device='cuda:0')

Parameter Name: base_model.model.layers.24.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[223],
        [127],
        [ 25],
        ...,
        [196],
        [114],
        [203]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.24.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0078,  0.0001,  0.0113,  ..., -0.0149, -0.0013,  0.0208],
        [-0.0095,  0.0210,  0.0025,  ...,  0.0038,  0.0010, -0.0112],
        [ 0.0025, -0.0208,  0.0020,  ..., -0.0006,  0.0160, -0.0329],
        ...,
        [ 0.0090, -0.0181, -0.0158,  ..., -0.0086, -0.0147, -0.0086],
        [ 0.0081,  0.0049,  0.0089,  ..., -0.0025, -0.0016,  0.0114],
        [ 0.0079,  0.0097,  0.0262,  ..., -0.0105, -0.0077,  0.0071]],
       device='cuda:0')

Parameter Name: base_model.model.layers.24.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0030, -0.0007,  0.0105,  ...,  0.0041,  0.0085,  0.0017],
        [ 0.0100, -0.0106,  0.0042,  ..., -0.0020, -0.0064, -0.0020],
        [-0.0193,  0.0072,  0.0115,  ...,  0.0088, -0.0020,  0.0076],
        ...,
        [ 0.0039,  0.0045,  0.0015,  ...,  0.0149, -0.0046, -0.0059],
        [-0.0008, -0.0004,  0.0074,  ...,  0.0109,  0.0093,  0.0125],
        [ 0.0014,  0.0017, -0.0024,  ..., -0.0048, -0.0033,  0.0047]],
       device='cuda:0')

Parameter Name: base_model.model.layers.24.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 25],
        [ 64],
        [227],
        ...,
        [205],
        [ 21],
        [ 36]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.24.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0162,  0.0109, -0.0033,  ...,  0.0250, -0.0227,  0.0093],
        [ 0.0083, -0.0129, -0.0179,  ...,  0.0208, -0.0048,  0.0057],
        [-0.0123, -0.0002, -0.0002,  ..., -0.0273, -0.0063,  0.0281],
        ...,
        [-0.0131,  0.0093,  0.0273,  ...,  0.0120,  0.0018, -0.0041],
        [ 0.0026,  0.0012,  0.0114,  ..., -0.0073, -0.0266,  0.0132],
        [-0.0131,  0.0042, -0.0058,  ..., -0.0079, -0.0083, -0.0060]],
       device='cuda:0')

Parameter Name: base_model.model.layers.24.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0174, -0.0043, -0.0073,  ..., -0.0011,  0.0114, -0.0029],
        [-0.0101, -0.0087, -0.0062,  ...,  0.0105, -0.0136,  0.0127],
        [ 0.0079, -0.0095,  0.0146,  ...,  0.0116,  0.0048,  0.0058],
        ...,
        [ 0.0070,  0.0076, -0.0013,  ...,  0.0009,  0.0022, -0.0023],
        [-0.0071, -0.0004, -0.0045,  ...,  0.0022,  0.0006, -0.0023],
        [-0.0014, -0.0031,  0.0092,  ..., -0.0044,  0.0094,  0.0029]],
       device='cuda:0')

Parameter Name: base_model.model.layers.24.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[239],
        [213],
        [ 21],
        ...,
        [ 99],
        [231],
        [234]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.24.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 0.0034,  0.0105,  0.0013,  ...,  0.0001, -0.0312, -0.0204],
        [-0.0008,  0.0107,  0.0298,  ...,  0.0040,  0.0234,  0.0113],
        [ 0.0013,  0.0093,  0.0124,  ..., -0.0100,  0.0097, -0.0047],
        ...,
        [-0.0049, -0.0027, -0.0130,  ..., -0.0004,  0.0146,  0.0116],
        [ 0.0018, -0.0286, -0.0089,  ...,  0.0050,  0.0167,  0.0233],
        [-0.0089, -0.0079,  0.0046,  ..., -0.0038, -0.0045,  0.0105]],
       device='cuda:0')

Parameter Name: base_model.model.layers.24.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0020, -0.0044,  0.0016,  ...,  0.0006, -0.0087,  0.0028],
        [-0.0094,  0.0094,  0.0049,  ...,  0.0066,  0.0066, -0.0075],
        [-0.0107, -0.0010, -0.0046,  ..., -0.0018,  0.0140, -0.0077],
        ...,
        [-0.0150, -0.0071, -0.0027,  ...,  0.0077,  0.0001, -0.0126],
        [ 0.0232, -0.0036, -0.0110,  ..., -0.0253,  0.0048,  0.0227],
        [-0.0093, -0.0057,  0.0072,  ...,  0.0035,  0.0195, -0.0033]],
       device='cuda:0')

Parameter Name: base_model.model.layers.24.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4941, 0.5195, 0.5117,  ..., 0.4863, 0.5156, 0.5078], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.24.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4102, 0.4062, 0.4082,  ..., 0.4121, 0.4160, 0.4102], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.25.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[109],
        [175],
        [ 93],
        ...,
        [ 76],
        [ 97],
        [125]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.25.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0216, -0.0169, -0.0031,  ..., -0.0071, -0.0164, -0.0275],
        [ 0.0064,  0.0049, -0.0183,  ..., -0.0013, -0.0058,  0.0165],
        [ 0.0069,  0.0003,  0.0072,  ...,  0.0129, -0.0207,  0.0057],
        ...,
        [ 0.0010, -0.0224,  0.0059,  ...,  0.0033,  0.0006,  0.0022],
        [ 0.0107, -0.0243,  0.0158,  ...,  0.0094,  0.0066, -0.0107],
        [-0.0013, -0.0035, -0.0202,  ...,  0.0018,  0.0243,  0.0068]],
       device='cuda:0')

Parameter Name: base_model.model.layers.25.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0117,  0.0134, -0.0004,  ..., -0.0140, -0.0197,  0.0154],
        [ 0.0023,  0.0032,  0.0121,  ...,  0.0079,  0.0138, -0.0009],
        [-0.0097,  0.0103, -0.0200,  ...,  0.0140, -0.0089,  0.0259],
        ...,
        [-0.0045, -0.0071, -0.0108,  ...,  0.0073,  0.0105, -0.0016],
        [-0.0037, -0.0040,  0.0007,  ...,  0.0046,  0.0026, -0.0016],
        [ 0.0058, -0.0055, -0.0007,  ..., -0.0029, -0.0013, -0.0046]],
       device='cuda:0')

Parameter Name: base_model.model.layers.25.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[205],
        [238],
        [116],
        ...,
        [ 75],
        [245],
        [111]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.25.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[103],
        [110],
        [ 30],
        ...,
        [ 81],
        [161],
        [ 68]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.25.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0028,  0.0089,  0.0080,  ..., -0.0420, -0.0075, -0.0108],
        [-0.0023, -0.0033, -0.0168,  ...,  0.0164,  0.0233, -0.0004],
        [-0.0012,  0.0063, -0.0252,  ...,  0.0385,  0.0277, -0.0102],
        ...,
        [ 0.0108, -0.0103, -0.0306,  ...,  0.0268,  0.0059, -0.0087],
        [ 0.0115, -0.0033, -0.0389,  ...,  0.0294,  0.0030,  0.0190],
        [ 0.0087, -0.0077, -0.0100,  ...,  0.0154,  0.0032, -0.0062]],
       device='cuda:0')

Parameter Name: base_model.model.layers.25.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0011, -0.0009, -0.0010,  ..., -0.0036,  0.0070, -0.0006],
        [-0.0076,  0.0089, -0.0013,  ...,  0.0054,  0.0045,  0.0047],
        [ 0.0027, -0.0053,  0.0068,  ..., -0.0128, -0.0015, -0.0020],
        ...,
        [-0.0077,  0.0076,  0.0121,  ...,  0.0096,  0.0068,  0.0071],
        [-0.0037,  0.0031, -0.0066,  ..., -0.0015,  0.0004, -0.0088],
        [-0.0119,  0.0095,  0.0122,  ...,  0.0091,  0.0137,  0.0066]],
       device='cuda:0')

Parameter Name: base_model.model.layers.25.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[118],
        [ 30],
        [150],
        ...,
        [165],
        [ 42],
        [207]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.25.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 3.0390e-02,  2.1394e-03,  2.7400e-05,  ...,  1.0452e-02,
          2.7953e-03, -3.6142e-03],
        [ 2.6068e-03,  3.0360e-02,  2.8144e-02,  ...,  1.4841e-02,
         -3.7987e-04,  1.5762e-02],
        [-2.5488e-02,  4.6394e-03, -6.4396e-03,  ..., -1.9593e-03,
         -3.1164e-03, -1.2354e-02],
        ...,
        [ 4.9737e-03,  7.0589e-03,  6.2282e-03,  ...,  1.4923e-02,
          1.6903e-02,  1.9971e-02],
        [ 7.2780e-03, -7.3533e-03, -7.3387e-03,  ...,  9.4065e-04,
          1.2374e-02,  3.8172e-03],
        [-1.3710e-02, -2.4913e-03, -1.1713e-02,  ...,  4.5495e-03,
         -1.3393e-02, -1.2427e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.25.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 2.2120e-03,  1.2274e-02,  4.3332e-05,  ..., -4.8510e-03,
         -1.0314e-02, -3.6081e-04],
        [ 4.6332e-03,  1.8563e-03,  1.1499e-02,  ...,  3.8366e-04,
          6.3745e-04,  7.1463e-04],
        [ 7.6583e-03, -7.0385e-03,  1.4479e-03,  ...,  7.8181e-03,
         -9.8227e-03,  2.9938e-03],
        ...,
        [-2.8925e-03,  2.3378e-03,  3.2610e-03,  ..., -9.4639e-03,
         -1.0762e-02, -6.9384e-03],
        [ 1.1820e-03, -8.2882e-03, -3.2988e-03,  ...,  8.2156e-03,
          9.4001e-03, -1.0845e-02],
        [ 1.7883e-03, -4.7840e-03,  1.2918e-02,  ...,  4.3364e-03,
          3.4299e-03,  2.3561e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.25.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[155],
        [ 58],
        [ 74],
        ...,
        [ 79],
        [ 98],
        [ 30]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.25.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0041, -0.0192, -0.0036,  ...,  0.0159,  0.0069,  0.0033],
        [-0.0094,  0.0033,  0.0023,  ...,  0.0101, -0.0067,  0.0072],
        [-0.0184,  0.0204, -0.0085,  ..., -0.0162, -0.0037, -0.0015],
        ...,
        [ 0.0095,  0.0143,  0.0035,  ...,  0.0008, -0.0188, -0.0154],
        [-0.0041,  0.0062, -0.0109,  ...,  0.0159, -0.0084, -0.0053],
        [ 0.0007,  0.0109,  0.0156,  ..., -0.0091,  0.0103,  0.0037]],
       device='cuda:0')

Parameter Name: base_model.model.layers.25.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0188, -0.0109,  0.0011,  ..., -0.0004,  0.0167, -0.0035],
        [-0.0051, -0.0004,  0.0097,  ...,  0.0032,  0.0126, -0.0126],
        [-0.0211,  0.0164,  0.0082,  ...,  0.0136,  0.0054, -0.0113],
        ...,
        [-0.0084, -0.0077,  0.0068,  ...,  0.0217, -0.0025, -0.0165],
        [ 0.0047, -0.0023,  0.0133,  ..., -0.0102,  0.0005, -0.0002],
        [-0.0057,  0.0051,  0.0057,  ...,  0.0003,  0.0075,  0.0031]],
       device='cuda:0')

Parameter Name: base_model.model.layers.25.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[222],
        [116],
        [ 75],
        ...,
        [ 70],
        [149],
        [ 98]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.25.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 7.1331e-03, -7.5860e-03, -1.4039e-02,  ..., -9.3385e-03,
          1.3677e-03, -1.3592e-02],
        [ 1.9897e-02,  6.3804e-03,  9.6348e-03,  ..., -7.5589e-03,
          1.6769e-02,  1.4440e-03],
        [-1.1033e-03,  6.2089e-03,  1.2760e-02,  ..., -6.5481e-03,
         -1.5228e-02, -1.6147e-03],
        ...,
        [-2.4200e-02, -3.7279e-03, -2.0286e-03,  ...,  4.0718e-03,
         -3.8094e-03, -1.2111e-03],
        [-2.7001e-02, -3.9098e-03, -6.7016e-03,  ..., -5.7243e-03,
          5.6367e-03,  1.9958e-03],
        [ 1.2912e-02, -6.5619e-05, -1.0393e-02,  ...,  1.7862e-02,
          1.5588e-02, -1.0083e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.25.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0149, -0.0285,  0.0186,  ...,  0.0135,  0.0256, -0.0227],
        [-0.0045, -0.0052,  0.0047,  ...,  0.0015, -0.0034, -0.0077],
        [-0.0184, -0.0140, -0.0026,  ...,  0.0095,  0.0166, -0.0067],
        ...,
        [-0.0096,  0.0063,  0.0013,  ...,  0.0051,  0.0034, -0.0155],
        [ 0.0154,  0.0173, -0.0037,  ..., -0.0087, -0.0097,  0.0073],
        [-0.0013,  0.0110,  0.0015,  ..., -0.0014,  0.0044, -0.0004]],
       device='cuda:0')

Parameter Name: base_model.model.layers.25.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 47],
        [122],
        [102],
        ...,
        [ 84],
        [154],
        [158]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.25.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[ 0.0140,  0.0020, -0.0158,  ..., -0.0083,  0.0019,  0.0124],
        [ 0.0027, -0.0084,  0.0105,  ..., -0.0034,  0.0056,  0.0183],
        [ 0.0019, -0.0068,  0.0067,  ...,  0.0032, -0.0078, -0.0078],
        ...,
        [-0.0018, -0.0087,  0.0109,  ..., -0.0017, -0.0097, -0.0078],
        [ 0.0017, -0.0187, -0.0125,  ...,  0.0093,  0.0041, -0.0043],
        [-0.0164, -0.0043, -0.0134,  ...,  0.0092, -0.0045, -0.0052]],
       device='cuda:0')

Parameter Name: base_model.model.layers.25.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0099, -0.0142,  0.0098,  ...,  0.0107, -0.0129,  0.0093],
        [ 0.0079,  0.0067, -0.0076,  ..., -0.0030,  0.0094, -0.0073],
        [-0.0016,  0.0061, -0.0012,  ..., -0.0081,  0.0029,  0.0077],
        ...,
        [ 0.0007, -0.0107, -0.0115,  ...,  0.0122, -0.0005,  0.0043],
        [ 0.0093,  0.0179, -0.0204,  ..., -0.0177,  0.0158, -0.0141],
        [-0.0023, -0.0059,  0.0019,  ..., -0.0022,  0.0072, -0.0097]],
       device='cuda:0')

Parameter Name: base_model.model.layers.25.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.5469, 0.5547, 0.5430,  ..., 0.5508, 0.5625, 0.5508], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.25.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4180, 0.4160, 0.4199,  ..., 0.4277, 0.4238, 0.4238], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.26.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 46],
        [239],
        [ 79],
        ...,
        [113],
        [174],
        [170]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.26.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0017, -0.0059,  0.0007,  ...,  0.0115,  0.0040, -0.0105],
        [-0.0136, -0.0070, -0.0164,  ...,  0.0140,  0.0011,  0.0121],
        [ 0.0203,  0.0274, -0.0089,  ..., -0.0081, -0.0147,  0.0033],
        ...,
        [-0.0129, -0.0209,  0.0118,  ..., -0.0032,  0.0002, -0.0105],
        [-0.0183, -0.0116, -0.0010,  ...,  0.0006,  0.0208, -0.0089],
        [ 0.0027,  0.0314, -0.0079,  ...,  0.0204,  0.0005,  0.0105]],
       device='cuda:0')

Parameter Name: base_model.model.layers.26.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0123, -0.0148,  0.0159,  ..., -0.0130, -0.0165,  0.0009],
        [ 0.0230,  0.0188, -0.0240,  ...,  0.0047,  0.0096, -0.0060],
        [-0.0023,  0.0023, -0.0029,  ..., -0.0096,  0.0057,  0.0186],
        ...,
        [ 0.0062,  0.0086, -0.0055,  ...,  0.0013,  0.0059, -0.0020],
        [-0.0045,  0.0029,  0.0019,  ...,  0.0102,  0.0104, -0.0058],
        [-0.0054, -0.0111,  0.0064,  ..., -0.0106, -0.0124,  0.0084]],
       device='cuda:0')

Parameter Name: base_model.model.layers.26.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 84],
        [254],
        [127],
        ...,
        [ 97],
        [169],
        [254]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.26.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 61],
        [217],
        [ 79],
        ...,
        [245],
        [230],
        [ 20]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.26.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-1.2462e-02, -4.0368e-03,  1.2764e-02,  ..., -2.4832e-02,
         -4.0110e-03, -2.8292e-02],
        [-1.3092e-02, -2.9263e-03,  7.0181e-03,  ..., -5.4319e-03,
         -1.1607e-04, -1.2292e-03],
        [-5.8153e-03, -3.2180e-03, -2.7256e-02,  ...,  9.4351e-03,
          1.6304e-02,  2.5155e-03],
        ...,
        [ 8.8699e-05,  1.8756e-03,  1.7617e-02,  ..., -6.2525e-03,
         -1.2626e-02, -1.5015e-02],
        [ 1.3510e-02, -8.9096e-03,  9.5982e-03,  ..., -2.9397e-02,
         -1.1772e-02, -2.3078e-02],
        [-1.6288e-03, -4.9107e-03, -2.5457e-03,  ...,  1.1149e-03,
          1.1269e-02, -1.3814e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.26.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0029,  0.0104, -0.0046,  ...,  0.0106,  0.0025,  0.0152],
        [-0.0062, -0.0073, -0.0003,  ..., -0.0051, -0.0012, -0.0068],
        [-0.0049, -0.0053,  0.0036,  ..., -0.0037, -0.0051, -0.0049],
        ...,
        [ 0.0151,  0.0175, -0.0116,  ...,  0.0162,  0.0121,  0.0168],
        [ 0.0059,  0.0044, -0.0097,  ...,  0.0057,  0.0093,  0.0039],
        [-0.0256, -0.0286,  0.0266,  ..., -0.0285, -0.0273, -0.0240]],
       device='cuda:0')

Parameter Name: base_model.model.layers.26.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[113],
        [174],
        [242],
        ...,
        [214],
        [ 93],
        [ 92]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.26.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-1.3883e-02,  3.5251e-02,  1.5903e-02,  ..., -1.1693e-02,
         -1.8963e-02,  5.7275e-03],
        [-5.8996e-03,  1.6236e-02, -1.8667e-02,  ...,  2.1761e-02,
          1.0374e-02, -1.2298e-02],
        [-7.8116e-03, -2.2458e-03,  2.1255e-03,  ...,  4.5790e-03,
          1.7606e-02,  9.0394e-03],
        ...,
        [-4.1389e-03, -5.5256e-03,  2.7135e-03,  ...,  6.4024e-03,
          6.5893e-03,  2.0100e-02],
        [-9.9314e-03, -1.1073e-02,  3.9220e-03,  ..., -1.8450e-03,
          9.9145e-03,  9.4387e-03],
        [-1.8899e-02,  2.5766e-02,  8.8588e-05,  ..., -1.0441e-04,
          1.6982e-03, -2.2330e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.26.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0007, -0.0113, -0.0080,  ...,  0.0142, -0.0062,  0.0170],
        [ 0.0177, -0.0097, -0.0014,  ..., -0.0041, -0.0078,  0.0102],
        [-0.0133,  0.0028,  0.0217,  ..., -0.0147, -0.0139, -0.0004],
        ...,
        [ 0.0117, -0.0037, -0.0036,  ...,  0.0034,  0.0046,  0.0144],
        [ 0.0050, -0.0121,  0.0004,  ..., -0.0028, -0.0075,  0.0066],
        [-0.0077,  0.0070, -0.0017,  ...,  0.0138,  0.0011, -0.0080]],
       device='cuda:0')

Parameter Name: base_model.model.layers.26.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[126],
        [121],
        [164],
        ...,
        [196],
        [ 29],
        [158]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.26.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0016, -0.0062,  0.0028,  ..., -0.0151, -0.0038,  0.0143],
        [ 0.0190, -0.0077,  0.0138,  ...,  0.0064, -0.0259, -0.0246],
        [-0.0086,  0.0063,  0.0127,  ..., -0.0013, -0.0039,  0.0166],
        ...,
        [-0.0026, -0.0055, -0.0080,  ..., -0.0004,  0.0113, -0.0263],
        [-0.0043,  0.0098, -0.0096,  ...,  0.0060, -0.0039, -0.0112],
        [-0.0028, -0.0016,  0.0332,  ...,  0.0095, -0.0002,  0.0136]],
       device='cuda:0')

Parameter Name: base_model.model.layers.26.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0125,  0.0119,  0.0140,  ...,  0.0164,  0.0168,  0.0107],
        [ 0.0188, -0.0032,  0.0027,  ..., -0.0052, -0.0086, -0.0116],
        [-0.0131, -0.0025, -0.0002,  ...,  0.0152,  0.0060, -0.0072],
        ...,
        [-0.0077,  0.0008, -0.0053,  ...,  0.0059,  0.0008, -0.0168],
        [-0.0160, -0.0013,  0.0082,  ...,  0.0072, -0.0048, -0.0037],
        [ 0.0070, -0.0109, -0.0184,  ..., -0.0211, -0.0226,  0.0043]],
       device='cuda:0')

Parameter Name: base_model.model.layers.26.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[242],
        [150],
        [100],
        ...,
        [230],
        [204],
        [126]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.26.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0154,  0.0166, -0.0021,  ..., -0.0073,  0.0092,  0.0112],
        [-0.0098,  0.0091,  0.0065,  ..., -0.0028, -0.0084, -0.0007],
        [ 0.0110,  0.0002, -0.0147,  ..., -0.0104, -0.0179, -0.0048],
        ...,
        [-0.0016,  0.0060,  0.0075,  ...,  0.0015, -0.0170, -0.0035],
        [-0.0150,  0.0209, -0.0023,  ...,  0.0138,  0.0287,  0.0004],
        [-0.0182,  0.0124, -0.0058,  ..., -0.0205, -0.0061, -0.0014]],
       device='cuda:0')

Parameter Name: base_model.model.layers.26.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0222,  0.0138,  0.0016,  ...,  0.0070, -0.0087, -0.0049],
        [-0.0161,  0.0031, -0.0082,  ...,  0.0154, -0.0143, -0.0032],
        [ 0.0090, -0.0082, -0.0055,  ..., -0.0073,  0.0082, -0.0085],
        ...,
        [-0.0057,  0.0108, -0.0016,  ...,  0.0118,  0.0054, -0.0016],
        [-0.0036, -0.0021,  0.0036,  ...,  0.0053,  0.0049, -0.0100],
        [-0.0102, -0.0009, -0.0155,  ...,  0.0159, -0.0094, -0.0191]],
       device='cuda:0')

Parameter Name: base_model.model.layers.26.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[252],
        [193],
        [ 18],
        ...,
        [165],
        [ 84],
        [ 84]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.26.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[-0.0073, -0.0039, -0.0021,  ...,  0.0038,  0.0115,  0.0104],
        [-0.0055, -0.0026, -0.0033,  ...,  0.0092,  0.0125,  0.0074],
        [-0.0048, -0.0003,  0.0076,  ...,  0.0068,  0.0043,  0.0095],
        ...,
        [-0.0131, -0.0101,  0.0029,  ..., -0.0025,  0.0053,  0.0032],
        [ 0.0190,  0.0083,  0.0028,  ..., -0.0044, -0.0010, -0.0153],
        [ 0.0087, -0.0074, -0.0077,  ...,  0.0067,  0.0088, -0.0084]],
       device='cuda:0')

Parameter Name: base_model.model.layers.26.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 3.2460e-03,  8.5559e-03, -9.7604e-04,  ...,  9.4448e-03,
          5.9078e-03,  7.5779e-04],
        [ 8.1099e-04,  5.3578e-03, -2.6789e-03,  ...,  4.3339e-03,
         -5.5650e-05,  2.2599e-04],
        [ 1.6237e-03, -1.4916e-03, -7.5926e-04,  ..., -1.6066e-03,
          5.0316e-03,  6.8269e-04],
        ...,
        [-1.1193e-02, -9.4370e-03, -7.9106e-03,  ..., -5.3925e-03,
          7.8016e-03,  9.3502e-03],
        [-3.5715e-03,  2.0329e-03, -1.5931e-03,  ...,  3.5705e-03,
          4.7355e-03,  1.1891e-04],
        [ 3.7452e-03,  2.1473e-03,  6.1389e-03,  ...,  1.1221e-02,
         -1.5527e-03,  4.2789e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.26.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.5156, 0.5352, 0.5352,  ..., 0.5195, 0.5430, 0.5312], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.26.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4355, 0.4316, 0.4336,  ..., 0.4434, 0.4414, 0.4395], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.27.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[164],
        [102],
        [172],
        ...,
        [169],
        [245],
        [ 78]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.27.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 1.6317e-02, -1.1328e-02, -2.0879e-02,  ..., -1.4329e-02,
         -2.2586e-02, -5.8380e-03],
        [ 1.6772e-02,  3.9411e-03,  2.8622e-03,  ..., -1.6175e-02,
         -1.4193e-03, -1.0681e-02],
        [-4.1504e-03,  1.5712e-02,  5.2339e-03,  ..., -3.7118e-05,
          2.2601e-02,  1.0670e-02],
        ...,
        [ 3.3758e-03, -2.3500e-02, -2.5292e-02,  ..., -1.7924e-02,
          3.0914e-03, -6.2069e-03],
        [ 1.8674e-02, -1.2988e-02, -1.7495e-02,  ..., -2.9982e-03,
         -1.0520e-02, -9.1122e-03],
        [-2.3767e-02, -1.2157e-03,  3.0312e-02,  ...,  2.0939e-02,
          1.4141e-02,  1.0102e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.27.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0075,  0.0114, -0.0092,  ...,  0.0052,  0.0071, -0.0049],
        [-0.0140, -0.0172,  0.0197,  ..., -0.0151, -0.0137,  0.0093],
        [-0.0096, -0.0120,  0.0135,  ..., -0.0174, -0.0114,  0.0116],
        ...,
        [-0.0002,  0.0011,  0.0003,  ..., -0.0017,  0.0015, -0.0010],
        [ 0.0003,  0.0055, -0.0046,  ...,  0.0049,  0.0031, -0.0040],
        [-0.0043, -0.0077,  0.0069,  ..., -0.0078, -0.0060,  0.0077]],
       device='cuda:0')

Parameter Name: base_model.model.layers.27.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[238],
        [103],
        [191],
        ...,
        [ 37],
        [ 29],
        [214]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.27.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 78],
        [169],
        [213],
        ...,
        [193],
        [236],
        [212]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.27.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0054, -0.0168,  0.0340,  ...,  0.0209, -0.0074, -0.0225],
        [-0.0006,  0.0093,  0.0189,  ...,  0.0015,  0.0106, -0.0343],
        [ 0.0032,  0.0053, -0.0073,  ..., -0.0034, -0.0049, -0.0212],
        ...,
        [ 0.0231, -0.0053, -0.0022,  ..., -0.0157, -0.0158,  0.0050],
        [ 0.0012,  0.0067, -0.0069,  ...,  0.0092,  0.0144,  0.0015],
        [ 0.0125,  0.0064,  0.0012,  ..., -0.0260, -0.0240, -0.0035]],
       device='cuda:0')

Parameter Name: base_model.model.layers.27.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0022, -0.0022,  0.0050,  ...,  0.0001,  0.0022,  0.0032],
        [-0.0019, -0.0034,  0.0003,  ..., -0.0044,  0.0071,  0.0028],
        [ 0.0132, -0.0073, -0.0115,  ..., -0.0016, -0.0024, -0.0003],
        ...,
        [-0.0021, -0.0050,  0.0114,  ..., -0.0161,  0.0108, -0.0106],
        [ 0.0033, -0.0107,  0.0019,  ..., -0.0045, -0.0004,  0.0043],
        [-0.0021, -0.0002, -0.0018,  ...,  0.0024, -0.0030,  0.0119]],
       device='cuda:0')

Parameter Name: base_model.model.layers.27.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[111],
        [109],
        [236],
        ...,
        [ 22],
        [159],
        [ 28]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.27.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0078,  0.0091, -0.0269,  ..., -0.0133,  0.0072, -0.0115],
        [ 0.0070, -0.0323, -0.0108,  ...,  0.0106,  0.0032, -0.0039],
        [ 0.0174, -0.0024,  0.0097,  ..., -0.0031, -0.0188,  0.0047],
        ...,
        [ 0.0017,  0.0064,  0.0180,  ..., -0.0253, -0.0215, -0.0094],
        [ 0.0084,  0.0139, -0.0162,  ...,  0.0021,  0.0165, -0.0164],
        [-0.0245,  0.0307,  0.0182,  ...,  0.0109,  0.0021,  0.0184]],
       device='cuda:0')

Parameter Name: base_model.model.layers.27.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0009,  0.0039, -0.0003,  ...,  0.0055, -0.0198, -0.0069],
        [-0.0067,  0.0003,  0.0108,  ...,  0.0042, -0.0129, -0.0058],
        [ 0.0117, -0.0043,  0.0012,  ...,  0.0016,  0.0099,  0.0049],
        ...,
        [ 0.0118, -0.0037,  0.0171,  ..., -0.0068, -0.0043, -0.0183],
        [ 0.0058,  0.0150, -0.0010,  ...,  0.0024,  0.0188,  0.0009],
        [-0.0114, -0.0065,  0.0147,  ...,  0.0171, -0.0085, -0.0148]],
       device='cuda:0')

Parameter Name: base_model.model.layers.27.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 36],
        [252],
        [ 21],
        ...,
        [ 86],
        [126],
        [201]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.27.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0128,  0.0298,  0.0143,  ..., -0.0010,  0.0076, -0.0120],
        [ 0.0089,  0.0052,  0.0183,  ..., -0.0005, -0.0128, -0.0117],
        [-0.0186, -0.0205, -0.0003,  ..., -0.0017, -0.0119, -0.0270],
        ...,
        [ 0.0053, -0.0089,  0.0224,  ...,  0.0099,  0.0084, -0.0068],
        [-0.0030, -0.0132, -0.0054,  ..., -0.0088, -0.0020,  0.0005],
        [-0.0030, -0.0033,  0.0143,  ...,  0.0181, -0.0013, -0.0175]],
       device='cuda:0')

Parameter Name: base_model.model.layers.27.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0092,  0.0082,  0.0031,  ..., -0.0003,  0.0070,  0.0070],
        [ 0.0128,  0.0110,  0.0268,  ..., -0.0203, -0.0108, -0.0047],
        [ 0.0007, -0.0065,  0.0008,  ...,  0.0057,  0.0145, -0.0010],
        ...,
        [ 0.0037,  0.0162,  0.0215,  ..., -0.0138, -0.0046, -0.0074],
        [ 0.0158,  0.0002,  0.0091,  ..., -0.0026,  0.0151, -0.0019],
        [-0.0168,  0.0084, -0.0049,  ..., -0.0039, -0.0048,  0.0080]],
       device='cuda:0')

Parameter Name: base_model.model.layers.27.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[228],
        [ 41],
        [222],
        ...,
        [220],
        [111],
        [209]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.27.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0037, -0.0166,  0.0171,  ..., -0.0297,  0.0212,  0.0170],
        [ 0.0243, -0.0036, -0.0181,  ...,  0.0007,  0.0217,  0.0101],
        [-0.0109,  0.0207,  0.0145,  ...,  0.0118,  0.0030, -0.0084],
        ...,
        [-0.0109,  0.0097, -0.0081,  ..., -0.0176, -0.0133,  0.0040],
        [ 0.0234,  0.0259,  0.0125,  ...,  0.0045, -0.0057, -0.0261],
        [-0.0081,  0.0129,  0.0101,  ...,  0.0044, -0.0061, -0.0065]],
       device='cuda:0')

Parameter Name: base_model.model.layers.27.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0007,  0.0003,  0.0077,  ...,  0.0063,  0.0045,  0.0030],
        [-0.0095,  0.0135,  0.0005,  ...,  0.0018,  0.0115,  0.0080],
        [-0.0107, -0.0040, -0.0066,  ..., -0.0059,  0.0067,  0.0162],
        ...,
        [ 0.0062,  0.0047, -0.0016,  ...,  0.0076,  0.0117,  0.0065],
        [ 0.0206, -0.0041, -0.0062,  ..., -0.0080, -0.0080, -0.0024],
        [-0.0070,  0.0047, -0.0056,  ...,  0.0051,  0.0145, -0.0004]],
       device='cuda:0')

Parameter Name: base_model.model.layers.27.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[125],
        [ 43],
        [122],
        ...,
        [108],
        [229],
        [225]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.27.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[-0.0046, -0.0124,  0.0124,  ...,  0.0009,  0.0016, -0.0021],
        [-0.0060,  0.0027,  0.0097,  ...,  0.0051,  0.0049, -0.0042],
        [ 0.0003, -0.0168,  0.0231,  ...,  0.0118,  0.0211,  0.0007],
        ...,
        [-0.0017, -0.0068,  0.0083,  ..., -0.0094,  0.0168,  0.0014],
        [-0.0121, -0.0094,  0.0224,  ...,  0.0093,  0.0141,  0.0119],
        [ 0.0005,  0.0004, -0.0232,  ...,  0.0012,  0.0201,  0.0002]],
       device='cuda:0')

Parameter Name: base_model.model.layers.27.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 9.6343e-03,  8.1169e-03,  6.9316e-03,  ...,  8.7864e-03,
          2.6264e-03, -7.4521e-03],
        [-2.1276e-03,  1.2478e-03, -2.4648e-03,  ...,  1.8491e-03,
         -3.1444e-03, -1.6525e-03],
        [-1.9986e-02, -1.8021e-02, -2.5736e-02,  ..., -1.8415e-02,
         -1.8179e-02,  1.3674e-02],
        ...,
        [ 5.6194e-05,  9.1578e-04,  1.1518e-03,  ...,  3.9134e-05,
          2.6869e-04,  1.8389e-03],
        [ 7.5085e-03,  4.0425e-03,  2.4290e-04,  ...,  1.3410e-03,
          5.6120e-03,  4.0512e-03],
        [-9.1183e-04, -4.5087e-03, -5.4722e-03,  ..., -4.5269e-03,
         -2.1901e-03,  1.4594e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.27.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.5430, 0.5508, 0.5508,  ..., 0.5508, 0.5508, 0.5547], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.27.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4551, 0.4453, 0.4434,  ..., 0.4512, 0.4551, 0.4492], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.28.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[154],
        [118],
        [204],
        ...,
        [216],
        [ 98],
        [125]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.28.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0282, -0.0088,  0.0184,  ...,  0.0122,  0.0027, -0.0267],
        [-0.0102,  0.0172,  0.0113,  ..., -0.0090, -0.0157, -0.0203],
        [ 0.0069, -0.0006,  0.0095,  ...,  0.0101, -0.0198, -0.0149],
        ...,
        [ 0.0006, -0.0002, -0.0138,  ...,  0.0078, -0.0047,  0.0145],
        [ 0.0087,  0.0118, -0.0058,  ...,  0.0014,  0.0017, -0.0096],
        [-0.0138,  0.0089,  0.0083,  ...,  0.0036,  0.0040,  0.0226]],
       device='cuda:0')

Parameter Name: base_model.model.layers.28.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0047,  0.0058,  0.0030,  ..., -0.0082, -0.0050,  0.0125],
        [ 0.0269, -0.0006,  0.0257,  ..., -0.0070, -0.0124, -0.0056],
        [-0.0062, -0.0189, -0.0055,  ..., -0.0007,  0.0035, -0.0025],
        ...,
        [ 0.0105, -0.0061,  0.0068,  ...,  0.0019,  0.0096, -0.0214],
        [-0.0152, -0.0101, -0.0164,  ...,  0.0100,  0.0220, -0.0063],
        [ 0.0070, -0.0075,  0.0051,  ..., -0.0161, -0.0019, -0.0073]],
       device='cuda:0')

Parameter Name: base_model.model.layers.28.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[153],
        [ 65],
        [ 84],
        ...,
        [149],
        [105],
        [254]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.28.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[198],
        [ 69],
        [154],
        ...,
        [107],
        [165],
        [ 17]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.28.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0142,  0.0059, -0.0174,  ...,  0.0130,  0.0132, -0.0010],
        [-0.0023,  0.0099, -0.0029,  ...,  0.0172, -0.0006,  0.0240],
        [-0.0096,  0.0136, -0.0077,  ...,  0.0060,  0.0258,  0.0244],
        ...,
        [ 0.0008,  0.0018, -0.0199,  ...,  0.0042,  0.0126, -0.0030],
        [ 0.0114, -0.0055,  0.0057,  ..., -0.0095, -0.0158, -0.0170],
        [ 0.0018, -0.0039, -0.0312,  ..., -0.0042,  0.0239,  0.0262]],
       device='cuda:0')

Parameter Name: base_model.model.layers.28.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0046, -0.0005, -0.0039,  ..., -0.0099,  0.0081, -0.0031],
        [ 0.0002,  0.0051,  0.0015,  ..., -0.0001,  0.0043,  0.0001],
        [ 0.0056,  0.0053,  0.0113,  ...,  0.0037,  0.0007,  0.0150],
        ...,
        [-0.0101, -0.0092, -0.0106,  ..., -0.0086,  0.0100, -0.0255],
        [ 0.0040,  0.0005, -0.0086,  ..., -0.0036,  0.0074, -0.0063],
        [ 0.0049,  0.0106,  0.0016,  ...,  0.0096, -0.0076,  0.0007]],
       device='cuda:0')

Parameter Name: base_model.model.layers.28.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[100],
        [172],
        [245],
        ...,
        [233],
        [ 92],
        [145]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.28.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-2.6432e-02,  7.1992e-03,  3.6085e-02,  ..., -1.0458e-02,
          3.8237e-03,  2.6042e-02],
        [ 1.7203e-03, -6.5899e-03,  1.2288e-02,  ..., -1.4096e-03,
         -7.3722e-03,  3.7195e-02],
        [ 1.5508e-02,  1.0060e-02, -1.6801e-02,  ..., -6.3102e-03,
          1.1136e-02,  8.1201e-03],
        ...,
        [ 3.0982e-02,  3.2986e-03, -2.7761e-02,  ...,  2.5151e-03,
         -1.4724e-02, -1.3638e-02],
        [ 1.2113e-02,  2.2393e-03, -6.2078e-03,  ..., -4.5007e-03,
         -8.6312e-03, -2.8350e-03],
        [ 4.3547e-05,  1.2484e-02,  1.2910e-02,  ..., -1.3335e-02,
          3.5638e-03,  8.2976e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.28.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 9.9408e-05, -7.8894e-03,  1.3193e-02,  ..., -2.8497e-03,
         -3.0610e-03, -1.7252e-02],
        [ 7.8044e-03, -6.4802e-03, -4.4446e-03,  ...,  1.1957e-03,
         -1.0029e-02,  5.5917e-03],
        [-2.8674e-03,  4.9703e-03,  8.0354e-03,  ..., -1.7669e-02,
         -3.5486e-03,  1.0284e-02],
        ...,
        [ 2.8061e-03,  1.0647e-02, -6.1839e-03,  ..., -1.2220e-03,
         -6.0548e-04,  1.1003e-03],
        [ 5.8894e-03,  2.1287e-03, -5.3902e-03,  ..., -5.1493e-03,
          5.9688e-03,  7.7763e-03],
        [-2.1968e-03,  1.2224e-02,  7.9108e-04,  ..., -5.8612e-03,
          7.1668e-03,  1.3034e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.28.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[150],
        [227],
        [237],
        ...,
        [126],
        [110],
        [244]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.28.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0117, -0.0183, -0.0072,  ..., -0.0012,  0.0072, -0.0127],
        [ 0.0224, -0.0194,  0.0147,  ...,  0.0017,  0.0091, -0.0043],
        [-0.0020,  0.0218,  0.0019,  ...,  0.0186,  0.0016, -0.0006],
        ...,
        [-0.0053,  0.0282, -0.0170,  ..., -0.0112,  0.0127,  0.0105],
        [-0.0282, -0.0176,  0.0064,  ..., -0.0044,  0.0150,  0.0169],
        [ 0.0187, -0.0106,  0.0197,  ..., -0.0031, -0.0104,  0.0020]],
       device='cuda:0')

Parameter Name: base_model.model.layers.28.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0098, -0.0062,  0.0163,  ...,  0.0078, -0.0048, -0.0104],
        [-0.0027, -0.0029,  0.0084,  ...,  0.0010,  0.0122, -0.0064],
        [-0.0126, -0.0068,  0.0054,  ...,  0.0090,  0.0107, -0.0073],
        ...,
        [ 0.0068,  0.0040,  0.0013,  ..., -0.0024,  0.0135, -0.0024],
        [-0.0021,  0.0004,  0.0073,  ...,  0.0071,  0.0100, -0.0071],
        [ 0.0094,  0.0057, -0.0086,  ..., -0.0086, -0.0007,  0.0086]],
       device='cuda:0')

Parameter Name: base_model.model.layers.28.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 86],
        [ 41],
        [210],
        ...,
        [109],
        [ 46],
        [110]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.28.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0197,  0.0063,  0.0011,  ...,  0.0079,  0.0044,  0.0082],
        [-0.0177, -0.0006, -0.0110,  ..., -0.0299, -0.0019,  0.0240],
        [ 0.0032, -0.0129, -0.0020,  ..., -0.0040, -0.0070,  0.0248],
        ...,
        [-0.0066, -0.0058, -0.0078,  ..., -0.0031, -0.0049,  0.0151],
        [ 0.0137, -0.0080, -0.0287,  ..., -0.0077, -0.0288, -0.0157],
        [-0.0164, -0.0044,  0.0093,  ...,  0.0010, -0.0050, -0.0097]],
       device='cuda:0')

Parameter Name: base_model.model.layers.28.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0249, -0.0001, -0.0020,  ...,  0.0014, -0.0006, -0.0178],
        [ 0.0091,  0.0068,  0.0069,  ..., -0.0030,  0.0045,  0.0136],
        [-0.0126, -0.0034,  0.0119,  ..., -0.0025,  0.0119, -0.0002],
        ...,
        [-0.0071,  0.0099, -0.0058,  ..., -0.0117, -0.0028,  0.0118],
        [ 0.0015, -0.0014, -0.0095,  ..., -0.0066,  0.0015,  0.0137],
        [-0.0036,  0.0023,  0.0091,  ...,  0.0030, -0.0056, -0.0065]],
       device='cuda:0')

Parameter Name: base_model.model.layers.28.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 98],
        [228],
        [ 97],
        ...,
        [111],
        [229],
        [ 44]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.28.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[-0.0013,  0.0034, -0.0074,  ..., -0.0246, -0.0095, -0.0157],
        [-0.0124,  0.0019,  0.0052,  ...,  0.0195,  0.0099,  0.0207],
        [ 0.0162,  0.0117, -0.0133,  ..., -0.0008,  0.0156,  0.0046],
        ...,
        [-0.0036,  0.0128,  0.0050,  ...,  0.0221,  0.0189,  0.0068],
        [ 0.0036,  0.0052,  0.0102,  ...,  0.0066,  0.0179,  0.0166],
        [ 0.0024,  0.0117, -0.0004,  ...,  0.0166,  0.0130,  0.0199]],
       device='cuda:0')

Parameter Name: base_model.model.layers.28.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0066,  0.0121, -0.0138,  ...,  0.0090,  0.0129,  0.0055],
        [-0.0067,  0.0054, -0.0085,  ...,  0.0060,  0.0086,  0.0037],
        [ 0.0065, -0.0036,  0.0052,  ..., -0.0068, -0.0041, -0.0086],
        ...,
        [ 0.0055, -0.0051,  0.0074,  ..., -0.0046, -0.0068, -0.0087],
        [ 0.0020, -0.0014,  0.0037,  ..., -0.0075, -0.0003, -0.0019],
        [-0.0003,  0.0024,  0.0014,  ..., -0.0020, -0.0032, -0.0031]],
       device='cuda:0')

Parameter Name: base_model.model.layers.28.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.5625, 0.5664, 0.5586,  ..., 0.5469, 0.5664, 0.5586], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.28.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4629, 0.4629, 0.4551,  ..., 0.4668, 0.4590, 0.4570], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.29.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[103],
        [233],
        [209],
        ...,
        [238],
        [ 87],
        [106]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.29.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 6.7984e-03,  8.2608e-03,  4.1078e-03,  ..., -1.4358e-02,
         -1.8135e-02,  1.0345e-02],
        [ 9.9082e-03, -4.7950e-03, -1.1846e-02,  ..., -1.4275e-02,
         -2.4162e-02, -4.2656e-03],
        [ 1.7679e-02,  1.6575e-02, -8.8064e-03,  ...,  2.7928e-03,
         -2.5961e-03, -1.9574e-02],
        ...,
        [-7.4893e-03,  7.3098e-03,  6.8646e-03,  ..., -2.1609e-02,
         -1.9938e-02, -1.6902e-03],
        [-1.1143e-02,  9.3024e-04,  1.8273e-02,  ...,  5.2746e-03,
         -1.0266e-02, -3.1908e-03],
        [ 2.4384e-02, -4.3089e-03, -5.8369e-03,  ..., -4.8222e-05,
          1.4635e-02,  7.6249e-03]], device='cuda:0')

Parameter Name: base_model.model.layers.29.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0062, -0.0026,  0.0048,  ..., -0.0039,  0.0045, -0.0050],
        [ 0.0004,  0.0053,  0.0002,  ...,  0.0019, -0.0015, -0.0027],
        [ 0.0039, -0.0021,  0.0004,  ...,  0.0065,  0.0025, -0.0020],
        ...,
        [ 0.0076,  0.0060, -0.0056,  ...,  0.0036,  0.0082, -0.0106],
        [-0.0096, -0.0083,  0.0086,  ..., -0.0086, -0.0098,  0.0092],
        [ 0.0102,  0.0148, -0.0108,  ...,  0.0133,  0.0130, -0.0127]],
       device='cuda:0')

Parameter Name: base_model.model.layers.29.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 63],
        [212],
        [100],
        ...,
        [ 94],
        [203],
        [193]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.29.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 97],
        [ 94],
        [188],
        ...,
        [103],
        [225],
        [244]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.29.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0121, -0.0165,  0.0226,  ...,  0.0171, -0.0138, -0.0020],
        [ 0.0040, -0.0235,  0.0093,  ..., -0.0163, -0.0018, -0.0169],
        [-0.0171, -0.0208, -0.0014,  ..., -0.0105, -0.0384, -0.0138],
        ...,
        [-0.0091,  0.0022, -0.0119,  ...,  0.0086,  0.0192,  0.0106],
        [-0.0327, -0.0055, -0.0278,  ...,  0.0056,  0.0080, -0.0031],
        [-0.0094, -0.0042, -0.0121,  ...,  0.0336,  0.0235,  0.0203]],
       device='cuda:0')

Parameter Name: base_model.model.layers.29.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0049,  0.0076,  0.0111,  ...,  0.0087, -0.0102, -0.0070],
        [-0.0031, -0.0059, -0.0045,  ..., -0.0054, -0.0032,  0.0027],
        [ 0.0022, -0.0034,  0.0013,  ...,  0.0025,  0.0054,  0.0042],
        ...,
        [-0.0109,  0.0078,  0.0078,  ...,  0.0239, -0.0075, -0.0028],
        [-0.0159,  0.0133,  0.0157,  ...,  0.0073, -0.0125, -0.0033],
        [ 0.0091,  0.0114,  0.0033,  ..., -0.0080, -0.0107, -0.0157]],
       device='cuda:0')

Parameter Name: base_model.model.layers.29.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[226],
        [ 46],
        [228],
        ...,
        [233],
        [102],
        [ 74]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.29.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0033, -0.0196, -0.0191,  ...,  0.0004, -0.0037, -0.0056],
        [-0.0043,  0.0224,  0.0110,  ..., -0.0055, -0.0128,  0.0159],
        [ 0.0272, -0.0285, -0.0169,  ...,  0.0043,  0.0229,  0.0199],
        ...,
        [ 0.0034,  0.0004, -0.0187,  ..., -0.0257,  0.0185,  0.0040],
        [-0.0209,  0.0130,  0.0003,  ...,  0.0085, -0.0120,  0.0065],
        [ 0.0037,  0.0127, -0.0126,  ...,  0.0195, -0.0031,  0.0190]],
       device='cuda:0')

Parameter Name: base_model.model.layers.29.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0015,  0.0010,  0.0018,  ...,  0.0100,  0.0149, -0.0033],
        [-0.0051,  0.0063, -0.0057,  ..., -0.0014,  0.0048, -0.0042],
        [-0.0135, -0.0176,  0.0025,  ...,  0.0087, -0.0040,  0.0028],
        ...,
        [ 0.0100,  0.0139, -0.0024,  ..., -0.0004,  0.0086,  0.0094],
        [ 0.0090,  0.0034,  0.0217,  ..., -0.0044,  0.0072, -0.0163],
        [-0.0083, -0.0158,  0.0016,  ..., -0.0111, -0.0053,  0.0128]],
       device='cuda:0')

Parameter Name: base_model.model.layers.29.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[114],
        [241],
        [ 70],
        ...,
        [215],
        [244],
        [207]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.29.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0071,  0.0072,  0.0195,  ...,  0.0179, -0.0035, -0.0111],
        [ 0.0142,  0.0022,  0.0306,  ...,  0.0276, -0.0077,  0.0302],
        [-0.0054, -0.0087, -0.0013,  ..., -0.0247,  0.0176, -0.0063],
        ...,
        [-0.0007,  0.0025, -0.0283,  ..., -0.0135, -0.0120, -0.0014],
        [-0.0078,  0.0178,  0.0021,  ..., -0.0141, -0.0218, -0.0106],
        [ 0.0035,  0.0063,  0.0311,  ...,  0.0109, -0.0016,  0.0016]],
       device='cuda:0')

Parameter Name: base_model.model.layers.29.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0022, -0.0028,  0.0106,  ..., -0.0016, -0.0003,  0.0043],
        [ 0.0024,  0.0086, -0.0051,  ...,  0.0064,  0.0010, -0.0048],
        [-0.0132,  0.0133,  0.0098,  ...,  0.0031, -0.0085,  0.0130],
        ...,
        [ 0.0089,  0.0076, -0.0128,  ..., -0.0017,  0.0117, -0.0032],
        [ 0.0060, -0.0157, -0.0028,  ...,  0.0187,  0.0150, -0.0259],
        [-0.0050,  0.0114, -0.0086,  ..., -0.0160, -0.0087,  0.0046]],
       device='cuda:0')

Parameter Name: base_model.model.layers.29.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[153],
        [109],
        [153],
        ...,
        [169],
        [206],
        [ 70]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.29.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0093, -0.0134, -0.0023,  ...,  0.0209,  0.0177,  0.0093],
        [-0.0112, -0.0043,  0.0035,  ...,  0.0196,  0.0034, -0.0131],
        [-0.0010,  0.0330,  0.0032,  ..., -0.0049,  0.0041, -0.0019],
        ...,
        [ 0.0176, -0.0192, -0.0121,  ..., -0.0101, -0.0250,  0.0107],
        [ 0.0053,  0.0056,  0.0107,  ...,  0.0027, -0.0118, -0.0001],
        [ 0.0272,  0.0087, -0.0010,  ...,  0.0094,  0.0083, -0.0076]],
       device='cuda:0')

Parameter Name: base_model.model.layers.29.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0078, -0.0156, -0.0055,  ..., -0.0037, -0.0063, -0.0036],
        [ 0.0003, -0.0152, -0.0042,  ...,  0.0019, -0.0027, -0.0062],
        [-0.0256,  0.0110,  0.0019,  ...,  0.0156,  0.0213, -0.0027],
        ...,
        [-0.0102, -0.0104, -0.0058,  ...,  0.0005, -0.0072, -0.0113],
        [ 0.0157, -0.0060,  0.0187,  ..., -0.0066, -0.0031, -0.0085],
        [ 0.0032,  0.0053,  0.0083,  ..., -0.0132,  0.0046, -0.0054]],
       device='cuda:0')

Parameter Name: base_model.model.layers.29.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 38],
        [156],
        [ 95],
        ...,
        [ 81],
        [124],
        [225]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.29.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[-0.0043,  0.0014, -0.0066,  ...,  0.0085, -0.0011,  0.0044],
        [-0.0101, -0.0053, -0.0102,  ...,  0.0114,  0.0027,  0.0060],
        [-0.0103,  0.0047,  0.0048,  ...,  0.0240, -0.0170,  0.0102],
        ...,
        [ 0.0021, -0.0090, -0.0033,  ...,  0.0119, -0.0094, -0.0028],
        [-0.0098,  0.0017, -0.0003,  ..., -0.0030, -0.0035,  0.0070],
        [-0.0014,  0.0059,  0.0003,  ..., -0.0009, -0.0042, -0.0022]],
       device='cuda:0')

Parameter Name: base_model.model.layers.29.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0123, -0.0024, -0.0117,  ..., -0.0062,  0.0096, -0.0008],
        [-0.0090, -0.0062, -0.0067,  ..., -0.0077,  0.0099,  0.0034],
        [ 0.0090,  0.0109,  0.0097,  ...,  0.0061, -0.0081, -0.0016],
        ...,
        [-0.0028,  0.0007, -0.0079,  ...,  0.0014,  0.0022, -0.0003],
        [-0.0026, -0.0010, -0.0024,  ..., -0.0045,  0.0073,  0.0056],
        [ 0.0013,  0.0002, -0.0020,  ...,  0.0018, -0.0044,  0.0012]],
       device='cuda:0')

Parameter Name: base_model.model.layers.29.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.5273, 0.5391, 0.5312,  ..., 0.5273, 0.5352, 0.5547], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.29.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4688, 0.4707, 0.4668,  ..., 0.4727, 0.4746, 0.4727], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.30.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[157],
        [153],
        [ 75],
        ...,
        [102],
        [254],
        [142]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.30.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-2.8812e-02,  9.5862e-03,  2.0855e-03,  ...,  2.3390e-02,
          1.3637e-02,  2.4067e-02],
        [-2.3741e-02,  1.6770e-02, -1.4539e-03,  ...,  2.5737e-02,
          4.3242e-03,  1.1767e-02],
        [ 9.0129e-05, -1.0323e-02,  6.7151e-04,  ...,  8.6399e-03,
          2.7575e-02,  9.1289e-03],
        ...,
        [ 1.2108e-02, -2.2508e-02, -1.3435e-02,  ..., -2.0714e-02,
          4.2848e-03,  5.7829e-03],
        [-1.8622e-02,  2.7652e-03,  2.9343e-03,  ...,  2.8156e-02,
          2.7227e-02,  1.3050e-02],
        [-5.6170e-03,  8.9095e-03,  1.4659e-03,  ...,  1.0534e-02,
          2.6937e-02,  1.8553e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.30.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0037, -0.0068, -0.0064,  ..., -0.0130,  0.0010, -0.0051],
        [ 0.0051,  0.0007, -0.0073,  ..., -0.0039,  0.0012, -0.0100],
        [ 0.0106,  0.0138,  0.0116,  ..., -0.0137,  0.0161,  0.0064],
        ...,
        [-0.0224, -0.0198, -0.0239,  ...,  0.0141, -0.0229, -0.0290],
        [ 0.0080,  0.0066,  0.0046,  ..., -0.0034,  0.0067,  0.0107],
        [ 0.0062,  0.0022,  0.0051,  ..., -0.0003,  0.0031,  0.0068]],
       device='cuda:0')

Parameter Name: base_model.model.layers.30.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[93],
        [31],
        [94],
        ...,
        [38],
        [65],
        [77]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.30.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[154],
        [ 85],
        [ 98],
        ...,
        [201],
        [238],
        [172]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.30.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0049,  0.0025,  0.0010,  ...,  0.0155, -0.0216, -0.0072],
        [-0.0258,  0.0042, -0.0044,  ...,  0.0035,  0.0003, -0.0090],
        [-0.0094,  0.0011, -0.0019,  ...,  0.0176,  0.0044, -0.0004],
        ...,
        [ 0.0007, -0.0218, -0.0035,  ..., -0.0109, -0.0014, -0.0254],
        [-0.0114,  0.0146, -0.0041,  ...,  0.0021,  0.0014,  0.0027],
        [-0.0074,  0.0298, -0.0109,  ...,  0.0110, -0.0101,  0.0127]],
       device='cuda:0')

Parameter Name: base_model.model.layers.30.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 6.2761e-03, -6.0678e-04,  1.5036e-02,  ..., -8.5713e-04,
          8.3118e-03,  1.0638e-02],
        [ 3.0845e-03,  1.6818e-03, -8.6920e-03,  ..., -4.6083e-03,
         -7.8173e-03, -2.1319e-03],
        [-1.2244e-02,  4.0059e-03, -1.0311e-02,  ..., -2.2225e-03,
         -1.2232e-02, -6.8109e-03],
        ...,
        [ 7.2080e-03,  6.4722e-03,  8.0400e-03,  ..., -1.1279e-02,
          3.7065e-03,  1.1384e-02],
        [-1.1024e-04,  7.4373e-03,  1.5438e-02,  ..., -4.8843e-03,
         -5.9238e-04,  7.0603e-03],
        [-5.1532e-03,  5.5876e-03,  3.5590e-03,  ..., -3.9129e-05,
          1.2854e-02,  1.4096e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.30.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[230],
        [239],
        [ 97],
        ...,
        [ 94],
        [ 73],
        [127]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.30.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0063, -0.0018, -0.0117,  ...,  0.0015, -0.0223, -0.0146],
        [ 0.0124, -0.0072, -0.0086,  ..., -0.0077,  0.0070,  0.0007],
        [ 0.0148,  0.0049,  0.0034,  ..., -0.0133, -0.0306,  0.0078],
        ...,
        [-0.0076,  0.0031,  0.0038,  ..., -0.0010, -0.0309, -0.0092],
        [ 0.0078,  0.0061,  0.0011,  ..., -0.0061,  0.0095,  0.0092],
        [-0.0063,  0.0040, -0.0040,  ...,  0.0077, -0.0313, -0.0077]],
       device='cuda:0')

Parameter Name: base_model.model.layers.30.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0039,  0.0043,  0.0038,  ...,  0.0146,  0.0021,  0.0086],
        [ 0.0097, -0.0018,  0.0075,  ...,  0.0116,  0.0029, -0.0011],
        [-0.0132,  0.0136, -0.0106,  ..., -0.0149,  0.0039, -0.0087],
        ...,
        [-0.0042, -0.0110, -0.0031,  ..., -0.0031,  0.0204, -0.0121],
        [ 0.0038,  0.0072,  0.0036,  ...,  0.0017, -0.0080,  0.0014],
        [ 0.0039, -0.0067,  0.0154,  ...,  0.0161,  0.0056,  0.0254]],
       device='cuda:0')

Parameter Name: base_model.model.layers.30.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[170],
        [237],
        [230],
        ...,
        [ 74],
        [153],
        [125]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.30.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0106, -0.0028, -0.0165,  ...,  0.0037,  0.0043,  0.0103],
        [ 0.0061,  0.0082,  0.0038,  ...,  0.0066, -0.0039,  0.0311],
        [ 0.0073, -0.0175, -0.0159,  ...,  0.0240, -0.0131, -0.0003],
        ...,
        [-0.0016,  0.0003,  0.0084,  ..., -0.0091, -0.0197, -0.0169],
        [-0.0061,  0.0086,  0.0286,  ..., -0.0264, -0.0316, -0.0235],
        [ 0.0092,  0.0229, -0.0060,  ...,  0.0206, -0.0148, -0.0185]],
       device='cuda:0')

Parameter Name: base_model.model.layers.30.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 1.3835e-02,  1.1668e-02, -2.3878e-03,  ..., -1.5031e-04,
         -9.9676e-03, -1.5315e-02],
        [ 6.7334e-03,  1.1010e-02,  4.8678e-03,  ...,  6.3634e-03,
         -7.7863e-03, -1.5266e-02],
        [-1.7938e-02,  4.9318e-03,  7.2455e-05,  ..., -8.1285e-03,
          1.3749e-02, -1.5920e-02],
        ...,
        [-1.7811e-02,  1.6615e-02, -6.2039e-03,  ..., -1.6557e-02,
          9.6912e-03, -4.8316e-03],
        [-1.0861e-02,  5.9506e-03,  2.7889e-03,  ..., -3.6186e-03,
          3.7390e-03,  8.4563e-04],
        [-8.9237e-03,  1.2626e-02,  4.3846e-03,  ..., -9.9401e-03,
          1.8995e-03, -1.2641e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.30.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[150],
        [110],
        [ 86],
        ...,
        [ 76],
        [ 31],
        [ 20]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.30.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0191, -0.0074,  0.0075,  ...,  0.0016, -0.0088, -0.0075],
        [ 0.0065, -0.0125, -0.0050,  ..., -0.0038, -0.0093, -0.0061],
        [-0.0180,  0.0070,  0.0288,  ..., -0.0026,  0.0084,  0.0077],
        ...,
        [ 0.0264, -0.0078, -0.0120,  ..., -0.0001, -0.0133, -0.0102],
        [-0.0020,  0.0049,  0.0078,  ...,  0.0111, -0.0064,  0.0121],
        [-0.0083, -0.0287,  0.0212,  ..., -0.0151,  0.0013, -0.0248]],
       device='cuda:0')

Parameter Name: base_model.model.layers.30.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0161, -0.0026, -0.0018,  ..., -0.0106,  0.0027, -0.0027],
        [ 0.0073,  0.0068, -0.0043,  ...,  0.0020,  0.0078,  0.0157],
        [ 0.0054, -0.0028,  0.0012,  ..., -0.0024, -0.0037, -0.0076],
        ...,
        [-0.0002,  0.0022,  0.0044,  ...,  0.0145, -0.0102,  0.0056],
        [ 0.0114,  0.0081, -0.0040,  ...,  0.0020,  0.0030, -0.0009],
        [ 0.0118, -0.0125,  0.0014,  ..., -0.0008,  0.0010, -0.0042]],
       device='cuda:0')

Parameter Name: base_model.model.layers.30.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 92],
        [162],
        [230],
        ...,
        [ 73],
        [102],
        [156]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.30.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[-0.0047, -0.0060, -0.0187,  ...,  0.0177, -0.0019,  0.0034],
        [-0.0092, -0.0162, -0.0195,  ...,  0.0034,  0.0097, -0.0094],
        [ 0.0068, -0.0009,  0.0033,  ...,  0.0036, -0.0044,  0.0002],
        ...,
        [ 0.0046,  0.0153,  0.0103,  ..., -0.0100, -0.0103, -0.0087],
        [ 0.0155,  0.0072, -0.0003,  ..., -0.0059,  0.0011, -0.0049],
        [ 0.0070, -0.0156, -0.0089,  ..., -0.0140,  0.0092,  0.0041]],
       device='cuda:0')

Parameter Name: base_model.model.layers.30.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0058,  0.0121, -0.0012,  ..., -0.0050, -0.0144, -0.0127],
        [ 0.0032,  0.0141, -0.0062,  ..., -0.0063, -0.0011,  0.0056],
        [ 0.0019, -0.0026,  0.0138,  ..., -0.0058,  0.0003,  0.0001],
        ...,
        [ 0.0038,  0.0051, -0.0031,  ..., -0.0051,  0.0036, -0.0004],
        [ 0.0060, -0.0117,  0.0003,  ...,  0.0060,  0.0038, -0.0018],
        [-0.0056,  0.0007,  0.0073,  ..., -0.0002,  0.0022, -0.0121]],
       device='cuda:0')

Parameter Name: base_model.model.layers.30.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.5742, 0.5820, 0.5625,  ..., 0.5508, 0.5625, 0.5820], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.30.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4785, 0.4883, 0.4785,  ..., 0.4805, 0.4824, 0.4785], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.31.self_attn.q_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[180],
        [ 34],
        [118],
        ...,
        [ 76],
        [162],
        [101]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.31.self_attn.q_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0055, -0.0071,  0.0038,  ..., -0.0081, -0.0106,  0.0067],
        [ 0.0014, -0.0149,  0.0018,  ..., -0.0263, -0.0110, -0.0011],
        [-0.0283, -0.0057, -0.0082,  ...,  0.0069,  0.0228, -0.0037],
        ...,
        [ 0.0185, -0.0039, -0.0061,  ..., -0.0114, -0.0209,  0.0008],
        [-0.0134,  0.0158, -0.0169,  ...,  0.0164,  0.0133, -0.0275],
        [ 0.0259, -0.0205,  0.0025,  ..., -0.0244, -0.0135,  0.0033]],
       device='cuda:0')

Parameter Name: base_model.model.layers.31.self_attn.q_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 5.6935e-03,  6.2880e-03, -4.4455e-03,  ...,  5.9461e-03,
         -6.6687e-03,  4.4087e-03],
        [ 3.9646e-03,  3.6598e-03, -3.9212e-03,  ...,  2.9634e-03,
         -4.5643e-03,  4.1782e-03],
        [-1.7511e-02, -1.4235e-02,  1.5036e-02,  ..., -1.5494e-02,
          1.6148e-02, -1.7250e-02],
        ...,
        [-6.2206e-03, -8.4596e-03,  8.3725e-03,  ..., -8.5445e-03,
          7.9941e-03, -9.5036e-03],
        [ 1.0970e-02,  1.1881e-02, -9.7942e-03,  ...,  1.1878e-02,
         -1.4690e-02,  1.1248e-02],
        [ 5.8678e-04, -2.5028e-03, -7.1798e-05,  ...,  2.0119e-04,
          4.1084e-04, -4.6854e-04]], device='cuda:0')

Parameter Name: base_model.model.layers.31.self_attn.k_proj.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[219],
        [ 82],
        [ 73],
        ...,
        [111],
        [126],
        [145]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.31.self_attn.v_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[ 74],
        [234],
        [236],
        ...,
        [157],
        [ 53],
        [227]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.31.self_attn.v_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 0.0052, -0.0115,  0.0008,  ..., -0.0117, -0.0171, -0.0044],
        [-0.0056,  0.0212, -0.0146,  ..., -0.0073,  0.0029, -0.0008],
        [-0.0058, -0.0057,  0.0079,  ...,  0.0072,  0.0002,  0.0018],
        ...,
        [-0.0122, -0.0084, -0.0120,  ..., -0.0099, -0.0114, -0.0102],
        [ 0.0036, -0.0354,  0.0006,  ..., -0.0132, -0.0161, -0.0028],
        [-0.0134, -0.0206, -0.0092,  ..., -0.0068, -0.0088, -0.0141]],
       device='cuda:0')

Parameter Name: base_model.model.layers.31.self_attn.v_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0051,  0.0032,  0.0070,  ...,  0.0074, -0.0075,  0.0054],
        [-0.0045,  0.0051, -0.0010,  ..., -0.0014,  0.0071, -0.0042],
        [-0.0058,  0.0031,  0.0036,  ...,  0.0047,  0.0022,  0.0106],
        ...,
        [-0.0076,  0.0126, -0.0004,  ..., -0.0041,  0.0033,  0.0015],
        [-0.0047,  0.0084, -0.0091,  ..., -0.0132, -0.0031, -0.0048],
        [-0.0050,  0.0053, -0.0084,  ..., -0.0017, -0.0064,  0.0057]],
       device='cuda:0')

Parameter Name: base_model.model.layers.31.self_attn.o_proj.base_layer.weight
 - Shape: torch.Size([8388608, 1])
 - Requires Grad: False
 - Values: tensor([[101],
        [158],
        [ 31],
        ...,
        [252],
        [ 66],
        [198]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.31.self_attn.o_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 2.1403e-02,  8.6634e-03,  1.1509e-02,  ..., -1.0529e-03,
          7.8138e-03,  8.7235e-03],
        [ 1.0163e-02,  1.6511e-02,  3.5121e-02,  ...,  1.6852e-02,
         -5.0569e-03, -1.5913e-02],
        [ 2.7346e-03,  1.4333e-02,  1.0725e-02,  ..., -1.8108e-02,
          8.2366e-03,  1.8243e-02],
        ...,
        [ 3.4173e-05, -1.1503e-03, -7.7232e-03,  ...,  4.2501e-03,
          1.1000e-02, -5.1939e-03],
        [ 1.4264e-03, -5.3291e-04, -7.3835e-03,  ..., -1.6799e-02,
          4.1332e-03,  1.8129e-02],
        [-1.0879e-02, -1.2446e-02, -2.0859e-02,  ..., -1.0850e-02,
          1.4056e-02,  1.7922e-04]], device='cuda:0')

Parameter Name: base_model.model.layers.31.self_attn.o_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0065,  0.0107,  0.0059,  ..., -0.0088, -0.0018, -0.0179],
        [-0.0106,  0.0065, -0.0115,  ...,  0.0272,  0.0042, -0.0104],
        [ 0.0104,  0.0107, -0.0035,  ...,  0.0044, -0.0021, -0.0041],
        ...,
        [ 0.0106,  0.0003,  0.0116,  ..., -0.0078,  0.0029, -0.0051],
        [ 0.0019, -0.0131,  0.0119,  ..., -0.0184, -0.0018,  0.0134],
        [-0.0172, -0.0118, -0.0007,  ...,  0.0105,  0.0070,  0.0170]],
       device='cuda:0')

Parameter Name: base_model.model.layers.31.mlp.gate_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[ 31],
        [ 42],
        [148],
        ...,
        [ 69],
        [255],
        [118]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.31.mlp.gate_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[ 2.2422e-03,  1.0852e-02, -1.3602e-02,  ...,  7.2325e-03,
          4.0013e-03, -6.9069e-05],
        [-5.2216e-03, -6.3792e-03,  1.7016e-02,  ...,  1.1332e-02,
         -7.9744e-03, -1.3361e-02],
        [ 1.5128e-02, -7.2071e-03, -1.5599e-02,  ..., -1.0132e-02,
          1.9479e-03,  1.6222e-02],
        ...,
        [-1.0460e-02, -1.7923e-02, -1.3522e-02,  ..., -2.9516e-02,
         -2.9497e-03,  1.2956e-02],
        [-5.9038e-03, -1.0663e-03,  2.8802e-02,  ...,  6.9587e-03,
         -1.7940e-02,  3.7230e-03],
        [-2.6157e-02, -2.0000e-02,  1.3543e-02,  ..., -2.3562e-02,
          1.0974e-02, -2.9854e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.31.mlp.gate_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[ 0.0088,  0.0084,  0.0017,  ...,  0.0092,  0.0196,  0.0073],
        [ 0.0164,  0.0050, -0.0037,  ...,  0.0109, -0.0006,  0.0134],
        [ 0.0103,  0.0004, -0.0073,  ...,  0.0084, -0.0028,  0.0082],
        ...,
        [ 0.0157,  0.0137, -0.0079,  ...,  0.0130,  0.0128,  0.0079],
        [-0.0032,  0.0021, -0.0003,  ...,  0.0003,  0.0039,  0.0026],
        [-0.0105, -0.0045, -0.0101,  ..., -0.0034, -0.0105, -0.0033]],
       device='cuda:0')

Parameter Name: base_model.model.layers.31.mlp.up_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[172],
        [ 93],
        [110],
        ...,
        [238],
        [110],
        [ 20]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.31.mlp.up_proj.lora_A.default.weight
 - Shape: torch.Size([8, 4096])
 - Requires Grad: True
 - Values: tensor([[-0.0088, -0.0234, -0.0111,  ...,  0.0218, -0.0066,  0.0184],
        [-0.0189, -0.0083, -0.0167,  ...,  0.0076,  0.0050, -0.0042],
        [-0.0068,  0.0023, -0.0255,  ...,  0.0133,  0.0072, -0.0130],
        ...,
        [-0.0074, -0.0237,  0.0144,  ..., -0.0143, -0.0228,  0.0221],
        [ 0.0234,  0.0126,  0.0019,  ..., -0.0332, -0.0087, -0.0079],
        [ 0.0133,  0.0099, -0.0016,  ..., -0.0096,  0.0058,  0.0049]],
       device='cuda:0')

Parameter Name: base_model.model.layers.31.mlp.up_proj.lora_B.default.weight
 - Shape: torch.Size([11008, 8])
 - Requires Grad: True
 - Values: tensor([[-2.4256e-03, -1.2011e-02, -1.2385e-02,  ..., -4.4138e-03,
          5.8277e-03,  4.9616e-03],
        [-9.9286e-03, -5.9867e-03,  1.8979e-03,  ..., -1.3370e-02,
         -1.2919e-03, -8.2278e-03],
        [ 4.2800e-03, -5.0256e-04,  5.7523e-03,  ..., -8.7676e-03,
          1.5235e-02, -1.7489e-03],
        ...,
        [ 3.5191e-03,  2.9966e-03,  4.9679e-03,  ...,  9.9006e-04,
          1.9041e-03, -1.6384e-03],
        [-3.5247e-03,  4.8204e-03,  1.8700e-03,  ..., -1.7524e-02,
          7.1696e-04, -9.8258e-05],
        [-4.4999e-03, -1.1225e-03, -1.8576e-03,  ...,  2.6765e-03,
          2.9903e-03,  1.0428e-02]], device='cuda:0')

Parameter Name: base_model.model.layers.31.mlp.down_proj.base_layer.weight
 - Shape: torch.Size([22544384, 1])
 - Requires Grad: False
 - Values: tensor([[154],
        [236],
        [ 33],
        ...,
        [254],
        [198],
        [ 21]], device='cuda:0', dtype=torch.uint8)

Parameter Name: base_model.model.layers.31.mlp.down_proj.lora_A.default.weight
 - Shape: torch.Size([8, 11008])
 - Requires Grad: True
 - Values: tensor([[-0.0050, -0.0038,  0.0244,  ..., -0.0009,  0.0054,  0.0174],
        [-0.0073,  0.0006, -0.0287,  ...,  0.0044, -0.0074, -0.0265],
        [ 0.0021,  0.0094,  0.0071,  ..., -0.0191, -0.0093,  0.0167],
        ...,
        [-0.0081, -0.0029, -0.0123,  ...,  0.0025,  0.0036, -0.0122],
        [ 0.0034,  0.0046, -0.0008,  ..., -0.0031,  0.0071, -0.0193],
        [ 0.0004, -0.0010,  0.0118,  ..., -0.0226, -0.0095,  0.0076]],
       device='cuda:0')

Parameter Name: base_model.model.layers.31.mlp.down_proj.lora_B.default.weight
 - Shape: torch.Size([4096, 8])
 - Requires Grad: True
 - Values: tensor([[-0.0029,  0.0009, -0.0039,  ...,  0.0051,  0.0107,  0.0004],
        [ 0.0007,  0.0049,  0.0007,  ...,  0.0057,  0.0111,  0.0078],
        [-0.0053, -0.0022, -0.0221,  ...,  0.0025, -0.0067, -0.0025],
        ...,
        [-0.0170,  0.0216, -0.0044,  ...,  0.0142,  0.0268, -0.0099],
        [-0.0155,  0.0117, -0.0100,  ...,  0.0120,  0.0019, -0.0119],
        [-0.0091,  0.0177, -0.0067,  ...,  0.0064,  0.0120, -0.0122]],
       device='cuda:0')

Parameter Name: base_model.model.layers.31.input_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4863, 0.4844, 0.4355,  ..., 0.4316, 0.4551, 0.4805], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.layers.31.post_attention_layernorm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([0.4336, 0.4375, 0.4414,  ..., 0.4238, 0.4102, 0.4277], device='cuda:0',
       dtype=torch.float16)

Parameter Name: base_model.model.norm.weight
 - Shape: torch.Size([4096])
 - Requires Grad: False
 - Values: tensor([1.8672, 1.8672, 1.8047,  ..., 1.7188, 1.8281, 1.6016], device='cuda:0',
       dtype=torch.float16)

================================================================================
self.dataset Dataset({
    features: ['query_id', 'query', 'positive_passages', 'negative_passages'],
    num_rows: 1861
})
Query ID: 26618
Query: what can cause shingles
Positive Passages: [{'docid': '76961', 'text': 'Shingles-Cause. Shingles is a reactivation of the varicella-zoster virus, a type of herpes virus that causes chickenpox. After you have had chickenpox, the virus lies inactive in your nerve roots and remains inactive until, in some people, it flares up again.', 'title': ''}]
Negative Passages: [{'docid': '542321', 'text': 'The crisis of representation that now seems so apparent after the writing of Baudrillard was also the result of a convergence of historical conditions both inside and outside of art. As a result, art’s capacity to depict the world was effected. Digging through all of my archived materials continues to be a good distraction from being productive. I stumbled upon this diatribe… but can’t figure out if I wrote this for a class or for my own geekful bliss…. Issues surrounding representation have played a key role in the development of postmodern art.', 'title': ''}, {'docid': '15196', 'text': 'The beneficial nematodes can be used to control a broad range of soil inhabiting insects and above ground insects in their soil inhabiting stage of life. More than 200 species of pest insects from 100 insect families are susceptible to these nematodes. BIOLOGICAL Control Of Pest Insects With Nematodes. Beneficial Nematodes naturally occur in soil and are used to control soil pest insects and whenever larvae or grubs are present. Like all of our products, it will not expose humans or animals to any health or environmental risks.', 'title': ''}, {'docid': '66190', 'text': "Try using our Site Search Engine to search across Iowa Workforce Development's family of Web sites. Iowa Workforce Development Offices | Office Holidays and Closures Iowa Workforce Development works to continually improve our products and services. ", 'title': ''}, {'docid': '5131', 'text': 'Average Price Range of Carpet. Wall to wall carpet, on average, ranges in price from about $3-$7 per square foot. The higher the costs, the better the carpet usually is. An average carpet price is about $4.50 per square foot. Rugs can cost as little as $1 per square foot for very cheap products. A good-quality area rug will cost $5 or more per square foot with the best rugs crafted from materials such as wool costing more than $8 per square foot. ', 'title': ''}, {'docid': '163435', 'text': 'The Shire horse is a breed of draught horse (BrE) or draft horse (AmE). The breed comes in many colours, including black, bay and grey. They are a tall breed, with mares standing 16 hands (64 inches, 163 cm) and over and stallions standing 17 hands (68 inches, 173 cm) and over. The breed has an enormous capacity for weight pulling, and Shires have held the world records for both largest overall horse and tallest horse at various times. Throughout its history, the breed has been popular for pulling brewery wagons delivering ale to customers. Smaller Shires, under 17 hands (68 inches, 173 cm), are generally preferred for working horses, while taller horses, especially those over 18.2 hands (74 inches, 188 cm), are used for show and promotional purposes. The breed is known for its easy-going temperament.', 'title': ''}, {'docid': '65848', 'text': 'The native implementation of XMLHTTP allows only HTTP, Secure Hypertext Transfer Protocol (HTTPS), and a subset of HTTP verbs in calls to XMLHttpRequest.open. In Internet Explorer 7, the XMLHTTP request can only specify URLs with the same port and protocol method as that from which the page is served.', 'title': ''}, {'docid': '304303', 'text': 'To compute the cost of direct materials put into production, just multiply the quantities for Beginning, Inputs, and Ending by the $2 cost per unit: Your calculation reveals that you put 2,100 gallons into production, for a total cost of $4,200. You can apply this formula to the quantity of units in inventory and put into production, and also to the costs of those same units. For example, suppose that a convenience store started the year with ten cans of coffee. During the year, it bought another 200', 'title': ''}, {'docid': '411377', 'text': 'Salaries. Clinical, counseling and school psychologists in the U.S. averaged $72,310 a year, or $34.77 an hour, as of 2011, according to the Bureau of Labor Statistics. The highest-paid psychologists received more than $109,470, or $52.63 an hour, while the lowest-paid earned $39,270, or $18.88. Industrial-organizational psychologists averaged $86,610, or $41.64 an hour. The highest pay for this specialty was more than $136,840, or $65.79, and the lowest was less than $38,910, or $18.71. These psychologists help businesses solve problems in management, personnel, administration, sales and marketing.', 'title': ''}, {'docid': '387408', 'text': 'SPECTRE (2015) :: James Bond 24. SPECTRE, the 24th James Bond film, will be the fourth outing for Daniel Craig as 007, and the second film to be directed by Sam Mendes. The new MI6 team of Ralph Fiennes (M), Naomie Harris (Moneypenny), Rory Kinnear (Tanner) and Ben Whishaw (Q) are all reprising their roles.', 'title': ''}, {'docid': '113194', 'text': "Bust of Aeschylus from the Capitoline Museums, Rome. Aeschylus was born in the city of Eleusis, near Athens, in 525 BC and died in 456 BC. He was a Greek dramatist, the earliest of the city's great tragic poets", 'title': ''}, {'docid': '767640', 'text': 'Yes, because chlorophyll gives foliage the green pigment needed for photosynthesis to occurr. It is needed because with it there are chloroplasts in the foliage which ab … sorb the sunlight producing oxygen for us life forms. Chlorophyll is a green pigment, that can be found in most plants. It absorbs sun light, the energy source for Photosynthesis, and is essential for plants to make food.', 'title': ''}, {'docid': '42018', 'text': 'Actually it remains very hot during whole summer period. Specifically the Average temperature in New York City in August goes 83 degree Fahrenheit (28 degrees Celsius) high and sometimes it reaches to even 100 degrees. On the other hand, the lower temperature is 69 degrees Fahrenheit (21 degrees Celsius). If you are ok with warm conditions then visit the place at that time is not even that bad. Hot, humid, sometimes oppressive are some words which can define the Average Temperature in New York City in August. The weather remains more pleasant in the last two weeks of the month compared to the first two ones.', 'title': ''}, {'docid': '384248', 'text': "The time it takes to receive final payment varies, based on when the Marine's 11060 is received by Disbursing. All final settlement pay will be issued by EFT. Marines are instructed during their pre-separations brief to keep their current direct deposit bank account open for a minimum of 6 months after separation.", 'title': ''}, {'docid': '257633', 'text': '1 bonding = the act of fastening two atoms together. 2  covalent = a type of bond that involves the sharing of electron pairs between atoms to achieve chemical stability, as in the hydrogen and oxygen atoms that make up a water molecule. 3  solvent = the substance present in the greatest amount within a solution. Terms you should know. 1 ', 'title': ''}, {'docid': '15205', 'text': "There's no compelling evidence that a pinched nerve is more likely to affect athletes in one sport more than in another. However, because the condition often involves overuse and repetitive movements, racquet sports, track and field, gymnastics, and weight lifting are activities that set the stage for pinched nerves.", 'title': ''}, {'docid': '371842', 'text': 'A strong dental plan should cover about 50 percent of root canal costs, making the out-of-pocket cost between $150 and $500. Root canals scare many people because of the expected discomfort. Some people also fear the cost, which depends on a number of factors.', 'title': ''}, {'docid': '691697', 'text': 'Allocation. Definition: An allocation is the process of shifting overhead costs to cost objects, using a rational basis of allotment. Allocations are most commonly used to assign costs to produced goods, which then appear in the financial statements of a business in either the cost of goods sold or the inventory asset. If financial statements are not to be distributed outside of an entity, then there is less need to use allocations.', 'title': ''}, {'docid': '576777', 'text': 'Aestheticism (also the Aesthetic Movement) is an art movement supporting the emphasis of aesthetic values more than social-political themes for literature, fine art, music and other arts. Predecessors of the Aesthetics included John Keats and Percy Bysshe Shelley, and some of the Pre-Raphaelites. In Britain the best representatives were Oscar Wilde and Algernon Charles Swinburne, both influenced by the French Symbolists, and James McNeill Whistler and Dante Gabriel Rossetti.', 'title': ''}, {'docid': '759677', 'text': "Groundnuts are a staple food in many developing countries. Also called peanuts, groundnuts are a protein rich tuber that grows well in semi-arid regions. There are two main types of groundnuts: the American groundnut (Arachis hypogaea), and the African groundnut, the Bambara nut (Voandzeia subterranea). Both are grown in Western Africa as a protein source. Groundnuts also contain sufficient quantities of carbohydrates and fats. Groundnuts are often grown by small farm holders and is considered a woman's crop in Western Africa. This web page provides information on groundnut production programs in Africa. It focuses on how to mobilize women agricultural groups and can be used as an intial resource on groundnuts.", 'title': ''}, {'docid': '480087', 'text': 'The Virginia Plan (also known as the Randolph Plan, after its sponsor, or the Large-State Plan) was a proposal by Virginia delegates for a bicameral legislative branch. The plan was drafted by James Madison while he waited for a quorum to assemble at the Constitutional Convention of 1787. Large states supported this plan, and smaller states generally opposed it, preferring an alternative put forward on June 15. The New Jersey Plan proposed a single-chamber legislature in which each state, regardless of size, would have one vote, as under the Articles of Confederation.', 'title': ''}]
--------------------------------------------------
self.dataset after process Dataset({
    features: ['query', 'positives', 'negatives'],
    num_rows: 1861
})
[2024-09-06 05:06:12,562] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
================================================================================
qry {'input_ids': tensor([[    1,  2346, 29901,   825,   338,  7903, 10709, 29915, 29879, 10377,
             2,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0],
        [    1,  2346, 29901,   825,   338,   385,  3158,  7037,     2,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}
================================================================================
q_reps tensor([[ 0.0009, -0.0005, -0.0116,  ...,  0.0207, -0.0030,  0.0004],
        [-0.0070, -0.0003,  0.0005,  ...,  0.0190, -0.0264,  0.0012]],
       device='cuda:0', grad_fn=<DivBackward0>)
================================================================================
qry {'input_ids': tensor([[    1,  2346, 29901,   825,   934,  4072,   947,   921,  1884,   697,
          5745,  4847,  2304,     2,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0],
        [    1,  2346, 29901,   988,   338,   330,   713,   293,  3543, 17306,
             2,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}
================================================================================
q_reps tensor([[ 0.0121, -0.0150, -0.0042,  ..., -0.0077, -0.0323,  0.0055],
        [ 0.0169, -0.0241,  0.0109,  ..., -0.0068,  0.0097,  0.0019]],
       device='cuda:0', grad_fn=<DivBackward0>)
================================================================================
qry {'input_ids': tensor([[    1,  2346, 29901, 22713, 22576,  1735,  3438,     2,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0],
        [    1,  2346, 29901,   988,   947,   278, 14453,  1061,   885,   481,
          2497, 29872,  3978,   403,     2,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}
================================================================================
q_reps tensor([[ 0.0097,  0.0122,  0.0080,  ..., -0.0036,  0.0052,  0.0055],
        [-0.0040, -0.0144,  0.0192,  ...,  0.0071,  0.0024, -0.0141]],
       device='cuda:0', grad_fn=<DivBackward0>)
================================================================================
qry {'input_ids': tensor([[    1,  2346, 29901,  3438,   310,  3300,   874,   639,  6862,  3661,
             2,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0],
        [    1,  2346, 29901,   988,   947,   286,  1025,   485,   568,  2041,
           515, 29973,     2,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}
================================================================================
q_reps tensor([[ 2.0438e-02, -3.1629e-03,  1.2080e-02,  ...,  2.5756e-05,
         -6.5826e-03, -6.1345e-03],
        [ 7.0991e-03, -9.2747e-03,  6.3936e-03,  ..., -2.4315e-03,
         -9.4047e-03,  9.5030e-04]], device='cuda:0', grad_fn=<DivBackward0>)
================================================================================
qry {'input_ids': tensor([[    1,  2346, 29901,   652,   271,  4835,  5023,  1712,     2,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0],
        [    1,  2346, 29901,   278, 25523,   310,   263, 18961,     2,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}
================================================================================
q_reps tensor([[ 5.2452e-03,  5.8292e-03,  2.3191e-02,  ...,  2.2308e-03,
          1.5202e-05,  4.2782e-03],
        [ 1.5382e-02, -2.1245e-02,  3.2616e-02,  ...,  7.1739e-03,
          4.8113e-03,  8.1021e-03]], device='cuda:0', grad_fn=<DivBackward0>)
